{
  "nodes": [
    {
      "id": "CHAP_00_SUB_1_1",
      "title": "1.1 What Operating Systems Do",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 2,
      "definition": "We begin our discussion by looking at the operating system\u2019s role in the overall computer system.",
      "key_points": [
        "The hardware\u2014the central processing unit (CPU), the memory, and the input/output (I/O) devices\u2014provides the basic computing resources for the system.",
        "The application programs\u2014such as word processors, spreadsheets, compilers, and Web browsers\u2014de\ufb01ne the ways in which these resources are used to solve users\u2019 computing problems.",
        "A computer system can be divided roughly into four components: the hardware, the operating system, the application programs, and the users (Figure 1.1).",
        "The operating system controls the hardware and coordinates its use among the various application programs for the various users.",
        "We can also view a computer system as consisting of hardware, software, and data."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_1_1",
      "title": "1.1.1 User View",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 2,
      "definition": "The user\u2019s view of the computer varies according to the interface being used.",
      "key_points": [
        "Most computer users sit in front of a PC, consisting of a monitor, keyboard, mouse, and system unit.",
        "Such a system is designed for one user"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_1_2",
      "title": "1.1.2 System View",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 3,
      "definition": "From the computer\u2019s point of view, the operating system is the program most intimately involved with the hardware.",
      "key_points": [
        "As we have seen, resource allocation is especially important where many users access the same mainframe or minicomputer.",
        "In this context, we can view an operating system as a resource allocator.",
        "A computer system has many resources that may be required to solve a problem: CPU time, memory space, \ufb01le-storage space, I/O devices, and so on.",
        "The operating system acts as the manager of these resources.",
        "Facing numerous and possibly con\ufb02icting requests for resources, the operating system must decide how to allocate them to speci\ufb01c programs and users so that it can operate the computer system ef\ufb01ciently and fairly."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_1_3",
      "title": "1.1.3 De\ufb01ning Operating Systems",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 4,
      "definition": "By now, you can probably see that the term operating system covers many roles and functions.",
      "key_points": [
        "A simple viewpoint is that it includes everything a vendor ships when you order \u201cthe operating system.\u201d The features included, however, vary greatly across systems.",
        "(Along with the kernel, there are two other types of programs: system programs, which are associated with the operating system but are not necessarily part of the kernel, and application programs, which include all programs not associated with the operation of the system.) The matter of what constitutes an operating system became increasingly important as personal computers became more widespread and operating systems grew increasingly sophisticated.",
        "Today, however, if we look at operating systems for mobile devices, we see that once again the number of features constituting the operating system"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_2",
      "title": "1.2 Computer-System Organization",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 5,
      "definition": "Before we can explore the details of how computer systems operate, we need general knowledge of the structure of a computer system.",
      "key_points": [
        "In this section, we look at several parts of this structure.",
        "The section is mostly concerned with computer-system organization, so you can skim or skip it if you already understand the concepts."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_2_1",
      "title": "1.2.1 Computer-System Operation",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 5,
      "definition": "A modern general-purpose computer system consists of one or more CPUs and a number of device controllers connected through a common bus that provides access to shared memory (Figure 1.2).",
      "key_points": [
        "To accomplish USB controller keyboard printer mouse monitor disks graphics adapter disk controller memory CPU on-line Figure 1.2 A modern computer system.",
        "Each device controller is in charge of a speci\ufb01c type of device (for example, disk drives, audio devices, or video displays).",
        "The CPU and the device controllers can execute in parallel, competing for memory cycles.",
        "To ensure orderly access to the shared memory, a memory controller synchronizes access to the memory.",
        "For a computer to start running\u2014for instance, when it is powered up or rebooted\u2014it needs to have an initial program to run."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_2_2",
      "title": "1.2.2 Storage Structure",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 7,
      "definition": "The CPU can load instructions only from memory, so any programs to run must be stored there.",
      "key_points": [
        "General-purpose computers run most of their programs from rewritable memory, called main memory (also called random-access memory, or RAM).",
        "Main memory commonly is implemented in a semiconductor technology called dynamic random-access memory (DRAM).",
        "Computers use other forms of memory as well.",
        "We have already mentioned read-only memory, ROM) and electrically erasable programmable read-only memory, EEPROM).",
        "Because ROM cannot be changed, only static programs, such as the bootstrap program described earlier, are stored there."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_2_3",
      "title": "1.2.3 I/O Structure",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 10,
      "definition": "A general-purpose computer system consists of CPUs and multiple device controllers that are connected through a common bus.",
      "key_points": [
        "The device controller, in turn, examines the contents of these registers to determine what action to take (such as \u201cread a character from the keyboard\u201d).",
        "A large portion of operating system code is dedicated to managing I/O, both because of its importance to the reliability and performance of a system and because of the varying nature of the devices.",
        "Next, we provide an overview of I/O.",
        "Each device controller is in charge of a speci\ufb01c type of device.",
        "Depending on the controller, more than one device may be attached."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_3",
      "title": "1.3 Computer-System Architecture",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 10,
      "definition": "In Section 1.2, we introduced the general structure of a typical computer system.",
      "key_points": [
        "A computer system can be organized in a number of different ways, which we"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_3_1",
      "title": "1.3.1 Single-Processor Systems",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 11,
      "definition": "Until recently, most computer systems used a single processor.",
      "key_points": [
        "On a single- processor system, there is one main CPUcapable of executing a general-purpose instruction set, including instructions from user processes.",
        "Almost all single- processor systems have other special-purpose processors as well.",
        "They may come in the form of device-speci\ufb01c processors, such as disk, keyboard, and graphics controllers; or, on mainframes, they may come in the form of more general-purpose processors, such as I/O processors that move data rapidly among the components of the system.",
        "All of these special-purpose processors run a limited instruction set and do not run user processes.",
        "For example, a disk-controller microprocessor receives a sequence of requests from the main CPU and implements its own disk queue and scheduling algorithm."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_3_2",
      "title": "1.3.2 Multiprocessor Systems",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 12,
      "definition": "Within the past several years, multiprocessor systems (also known as parallel systems or multicore systems) have begun to dominate the landscape of computing.",
      "key_points": [
        "Such systems have two or more processors in close communication, sharing the computer bus and sometimes the clock, memory, and peripheral devices.",
        "Multiprocessor systems \ufb01rst appeared prominently appeared in servers and have since migrated to desktop and laptop systems.",
        "Recently, multiple processors have appeared on mobile devices such as smartphones and tablet computers.",
        "Multiprocessor systems have three main advantages: 1.",
        "By increasing the number of processors, we expect to get more work done in less time."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_3_3",
      "title": "1.3.3 Clustered Systems",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 15,
      "definition": "Another type of multiprocessor system is a clustered system, which gathers together multiple CPUs. Clustered systems differ from the multiprocessor systems described in Section 1.3.2 in that they are composed of two or more individual systems\u2014or nodes\u2014joined together.",
      "key_points": [
        "Each node may be a single processor system or a multicore system.",
        "We should note that the de\ufb01nition of clustered is not concrete; many commercial packages wrestle to de\ufb01ne a clustered system and why one form is better than another.",
        "Such systems can supply signi\ufb01cantly greater computational power than single-processor or even SMP systems because they can run an application concurrently on all computers in the cluster.",
        "The application must have been written speci\ufb01cally to take advantage of the cluster, however."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_4",
      "title": "1.4 Operating-System Structure",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 17,
      "definition": "Now that we have discussed basic computer-system organization and archi- tecture, we are ready to talk about operating systems.",
      "key_points": [
        "One of the most important aspects of operating systems is the ability to multiprogram.",
        "This pool consists of all processes residing on disk awaiting allocation of main memory.",
        "An operating system provides the environment within which programs are executed.",
        "Internally, operating systems vary greatly in their makeup, since they are organized along many different lines.",
        "There are, however, many commonalities, which we consider in this section."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_5",
      "title": "1.5 Operating-System Operations",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 19,
      "definition": "A trap (or an exception) is a software-generated interrupt caused either by an error (for example, division by zero or invalid memory access) or by a speci\ufb01c request from a user program that an operating-system service be performed.",
      "key_points": [
        "If there are no processes to execute, no I/O devices to service, and no users to whom to respond, an operating system will sit quietly, waiting for something to happen.",
        "With sharing, many processes could be adversely affected by a bug in one program.",
        "For example, if a process gets stuck in an in\ufb01nite loop, this loop could prevent the correct operation of many other processes.",
        "Without protection against these sorts of errors, either the computer must execute only one process at a time or all output must be suspect."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_5_1",
      "title": "1.5.1 Dual-Mode and Multimode Operation",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 19,
      "definition": "In order to ensure the proper execution of the operating system, we must be able to distinguish between the execution of operating-system code and user- de\ufb01ned code.",
      "key_points": [
        "The approach taken by most computer systems is to provide hardware support that allows us to differentiate among various modes of execution."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_5_2",
      "title": "1.5.2 Timer",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 22,
      "definition": "We must ensure that the operating system maintains control over the CPU.",
      "key_points": [
        "For instance, a 10-bit counter with a 1-millisecond clock allows interrupts at intervals from millisecond to 1,024 milliseconds, in steps of 1 millisecond.",
        "We cannot allow a user program to get stuck in an in\ufb01nite loop or to fail to call system services and never return control to the operating system.",
        "To accomplish this goal, we can use a timer.",
        "A timer can be set to interrupt the computer after a speci\ufb01ed period.",
        "The period may be \ufb01xed (for example, 1/60 second) or variable (for example, from 1 millisecond to 1 second)."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_6",
      "title": "1.6 Process Management",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 22,
      "definition": "A program in execution, as mentioned, is a process.",
      "key_points": [
        "A time-shared user program such as a compiler is a process.",
        "A word-processing program being run by an individual user on a PC is a process.",
        "A system task, such as sending output to a printer, can also be a process (or at least part of one).",
        "For now, you can consider a process to be a job or a time-shared program, but later you will learn that the concept is more general.",
        "As we shall see in Chapter 3, it is possible to provide system calls that allow processes to create subprocesses to execute concurrently."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_7",
      "title": "1.7 Memory Management",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 23,
      "definition": "Main memory is a large array of bytes, ranging in size from hundreds of thousands to billions.",
      "key_points": [
        "The central processor reads instructions from main memory during the instruction-fetch cycle and both reads and writes data from main memory during the data-fetch cycle (on a von Neumann architecture).",
        "As noted earlier, the main memory is generally the only large storage device that the CPU is able to address and access directly.",
        "For example, for the CPU to process data from disk, those data must \ufb01rst be transferred to main memory by CPU-generated I/O calls."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_8",
      "title": "1.8 Storage Management",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 24,
      "definition": "To make the computer system convenient for users, the operating system provides a uniform, logical view of information storage.",
      "key_points": [
        "The operating system abstracts from the physical properties of its storage devices to de\ufb01ne a logical storage unit, the \ufb01le.",
        "The operating system maps \ufb01les onto physical media and accesses these \ufb01les via the storage devices."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_8_1",
      "title": "1.8.1 File-System Management",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 24,
      "definition": "File management is one of the most visible components of an operating system.",
      "key_points": [
        "Computers can store information on several different types of physical media.",
        "Magnetic disk, optical disk, and magnetic tape are the most common.",
        "Each of these media has its own characteristics and physical organization.",
        "Each medium is controlled by a device, such as a disk drive or tape drive, that also has its own unique characteristics.",
        "These properties include access speed, capacity, data-transfer rate, and access method (sequential or random)."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_8_2",
      "title": "1.8.2 Mass-Storage Management",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 25,
      "definition": "As we have already seen, because main memory is too small to accommodate all data and programs, and because the data that it holds are lost when power is lost, the computer system must provide secondary storage to back up main memory.",
      "key_points": [
        "Most programs\u2014including compilers, assemblers, word processors, editors, and formatters\u2014are stored on a disk until loaded into memory.",
        "They then use the disk as both the source and destination of their processing.",
        "Some of the functions that operating systems can provide include mounting and unmounting media in devices, allocating and freeing the devices for exclusive use by processes, and migrating data from secondary to tertiary storage."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_8_3",
      "title": "1.8.3 Caching",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 25,
      "definition": "Caching is an important principle of computer systems.",
      "key_points": [
        "Information is normally kept in some storage system (such as main memory).",
        "As it is used, it is copied into a faster storage system\u2014the cache\u2014on a"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_8_4",
      "title": "1.8.4 I/O Systems",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 27,
      "definition": "One of the purposes of an operating system is to hide the peculiarities of speci\ufb01c hardware devices from the user.",
      "key_points": [
        "For example, in UNIX, the peculiarities of I/O"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_9",
      "title": "1.9 Protection and Security",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 28,
      "definition": "If a computer system has multiple users and allows the concurrent execution of multiple processes, then access to data must be regulated.",
      "key_points": [
        "For that purpose, mechanisms ensure that \ufb01les, memory segments, CPU, and other resources can be operated on by only those processes that have gained proper authoriza- tion from the operating system.",
        "For example, memory-addressing hardware ensures that a process can execute only within its own address space.",
        "The timer ensures that no process can gain control of the CPU without eventually relinquishing control.",
        "Protection, then, is any mechanism for controlling the access of processes or users to the resources de\ufb01ned by a computer system."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_10",
      "title": "1.10 Kernel Data Structures",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 29,
      "definition": "We turn next to a topic central to operating-system implementation: the way data are structured in the system.",
      "key_points": [
        "In this section, we brie\ufb02y describe several fundamental data structures used extensively in operating systems.",
        "Readers who require further details on these structures, as well as others, should consult the bibliography at the end of the chapter."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_10_1",
      "title": "1.10.1 Lists, Stacks, and Queues",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 29,
      "definition": "An array is a simple data structure in which each element can be accessed directly.",
      "key_points": [
        "For example, main memory is constructed as an array.",
        "If the data item being stored is larger than one byte, then multiple bytes can be allocated to the item, and the item is addressed as item number \u00d7 item size.",
        "But what about storing an item whose size may vary?",
        "And what about removing an item if the relative positions of the remaining items must be preserved?",
        "In such situations, arrays give way to other data structures."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_10_2",
      "title": "1.10.2 Trees",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 31,
      "definition": "A tree is a data structure that can be used to represent data hierarchically.",
      "key_points": [
        "Data values in a tree structure are linked through parent\u2013child relationships.",
        "In a general tree, a parent may have an unlimited number of children.",
        "In a binary tree, a parent may have at most two children, which we term the left child and the right child.",
        "A binary search tree additionally requires an ordering between the parent\u2019s two children in which le f t child <= right child.",
        "Figure 1.16 provides an example of a binary search tree."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_10_3",
      "title": "1.10.3 Hash Functions and Maps",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 31,
      "definition": "A hash function takes data as its input, performs a numeric operation on this data, and returns a numeric value.",
      "key_points": [
        "This numeric value can then be used as an index into a table (typically an array) to quickly retrieve the data.",
        "Whereas searching for a data item through a list of size n can require up to O(n) comparisons in the worst case, using a hash function for retrieving data from table can be as good as O(1) in the worst case, depending on implementation details.",
        "Because of this performance, hash functions are used extensively in operating systems.",
        "35 42 14 Figure 1.16 Binary search tree."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_10_4",
      "title": "1.10.4 Bitmaps",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 32,
      "definition": "A bitmap is a string of n binary digits that can be used to represent the status of n items.",
      "key_points": [
        "For example, suppose we have several resources, and the availability of each resource is indicated by the value of a binary digit: 0 means that the resource is available, while 1 indicates that it is unavailable (or vice-versa).",
        "The value of the ith position in the bitmap is associated with the ith resource.",
        "As an example, consider the bitmap shown below: 0 1 0 1 1 1 0 1 Resources 2, 4, 5, 6, and 8 are unavailable; resources 0, 1, 3, and 7 are available.",
        "The power of bitmaps becomes apparent when we consider their space ef\ufb01ciency.",
        "If we were to use an eight-bit Boolean value instead of a single bit, the resulting data structure would be eight times larger."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_11",
      "title": "1.11 Computing Environments",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 33,
      "definition": "So far, we have brie\ufb02y described several aspects of computer systems and the operating systems that manage them.",
      "key_points": [
        "We turn now to a discussion of how operating systems are used in a variety of computing environments."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_11_1",
      "title": "1.11.1 Traditional Computing",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 33,
      "definition": "As computing has matured, the lines separating many of the traditional com- puting environments have blurred.",
      "key_points": [
        "Batch systems processed jobs in bulk, with predetermined input from \ufb01les or other data sources.",
        "Consider the \u201ctypical of\ufb01ce environment.\u201d Just a few years ago, this environment consisted of PCs connected to a network, with servers providing \ufb01le and print services.",
        "Remote access was awkward, and portability was achieved by use of laptop computers.",
        "Terminals attached to mainframes were prevalent at many companies as well, with even fewer remote access and portability options.",
        "The current trend is toward providing more ways to access these computing environments."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_11_2",
      "title": "1.11.2 Mobile Computing",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 34,
      "definition": "Mobile computing refers to computing on handheld smartphones and tablet computers.",
      "key_points": [
        "These devices share the distinguishing physical features of being portable and lightweight.",
        "Over the past few years, however, features on mobile devices have become so rich that the distinction in functionality between, say, a consumer laptop and a tablet computer may be dif\ufb01cult to discern.",
        "In fact, we might argue that the features of a contemporary mobile device allow it to provide functionality that is either unavailable or impractical on a desktop or laptop computer.",
        "Many developers are now designing applications that take advantage of the unique features of mobile devices, such as global positioning system (GPS) chips, accelerometers, and gyroscopes.",
        "In several computer games that employ accelerometers, players interface with the system not by using a mouse or a keyboard but rather by tilting, rotating, and shaking the mobile device! Perhaps more a practical use of these features is found in augmented-reality applications, which overlay information on a display of the current environment."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_11_3",
      "title": "1.11.3 Distributed Systems",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 35,
      "definition": "A distributed system is a collection of physically separate, possibly heteroge- neous, computer systems that are networked to provide users with access to the various resources that the system maintains.",
      "key_points": [
        "Access to a shared resource increases computation speed, functionality, data availability, and reliability.",
        "Some operating systems generalize network access as a form of \ufb01le access, with the details of networking contained in the network interface\u2019s device driver.",
        "Others make users speci\ufb01cally invoke network functions.",
        "Generally, systems contain a mix of the two modes\u2014for example FTP and NFS.",
        "The protocols that create a distributed system can greatly affect that system\u2019s utility and popularity."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_11_4",
      "title": "1.11.4 Client\u2013Server Computing",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 36,
      "definition": "As PCs have become faster, more powerful, and cheaper, designers have shifted away from centralized system architecture.",
      "key_points": [
        "Terminals connected to centralized systems are now being supplanted by PCs and mobile devices.",
        "Correspond- ingly, user-interface functionality once handled directly by centralized systems is increasingly being handled by PCs, quite often through a web interface.",
        "As a result, many of today\u2019s systems act as server systems to satisfy requests generated by client systems.",
        "This form of specialized distributed system, called a client\u2013server system, has the general structure depicted in Figure 1.18.",
        "Server systems can be broadly categorized as compute servers and \ufb01le servers: \u2022 The compute-server system provides an interface to which a client can send a request to perform an action (for example, read data)."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_11_5",
      "title": "1.11.5 Peer-to-Peer Computing",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 37,
      "definition": "In a client-server system, the server is a bottleneck; but in a peer-to-peer system, services can be provided by several nodes distributed throughout the network.",
      "key_points": [
        "Peer-to-peer systems offer an advantage over traditional client-server systems.",
        "In this model, clients and servers are not distinguished from one another.",
        "Instead, all nodes within the system are considered peers, and each may act as either a client or a server, depending on whether it is requesting or providing a service.",
        "To participate in a peer-to-peer system, a node must \ufb01rst join the network of peers.",
        "Once a node has joined the network, it can begin providing services to\u2014and requesting services from\u2014other nodes in the network."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_11_6",
      "title": "1.11.6 Virtualization",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 38,
      "definition": "Virtualization is a technology that allows operating systems to run as appli- cations within other operating systems.",
      "key_points": [
        "At \ufb01rst blush, there seems to be little reason for such functionality.",
        "But the virtualization industry is vast and growing, which is a testament to its utility and importance.",
        "Broadly speaking, virtualization is one member of a class of software that also includes emulation.",
        "Emulation is used when the source CPU type is different from the target CPU type.",
        "For example, when Apple switched from the IBM Power CPU to the Intel x86 CPU for its desktop and laptop computers, it included an emulation facility called \u201cRosetta,\u201d which allowed applications compiled for the IBM CPU to run on the Intel CPU."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_11_7",
      "title": "1.11.7 Cloud Computing",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 39,
      "definition": "Cloud computing is a type of computing that delivers computing, storage, and even applications as a service across a network.",
      "key_points": [
        "In some ways, it\u2019s a logical extension of virtualization, because it uses virtualization as a base for its functionality.",
        "For example, the Amazon Elastic Compute Cloud (EC2) facility has thousands of servers, millions of virtual machines, and petabytes of storage available for use by anyone on the Internet.",
        "Users pay per month based on how much of those resources they use.",
        "There are actually many types of cloud computing, including the following: \u2022 Public cloud\u2014a cloud available via the Internet to anyone willing to pay for the services"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_11_8",
      "title": "1.11.8 Real-Time Embedded Systems",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 41,
      "definition": "Embedded computers are the most prevalent form of computers in existence.",
      "key_points": [
        "The systems they run on are usually primitive, and so the operating systems provide limited features.",
        "A real-time system is used when rigid time requirements have been placed on the operation of a processor or the \ufb02ow of data; thus, it is often used as a control device in a dedicated application.",
        "Processing must be done within the de\ufb01ned constraints, or the system will fail."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_12",
      "title": "1.12 Open-Source Operating Systems",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 41,
      "definition": "We noted at the beginning of this chapter that the study of operating systems has been made easier by the availability of a vast number of open-source",
      "key_points": []
    },
    {
      "id": "CHAP_00_SUB_1_12_1",
      "title": "1.12.1 History",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 42,
      "definition": "In the early days of modern computing (that is, the 1950s), a great deal of software was available in open-source format.",
      "key_points": [
        "The original hackers (computer enthusiasts) at MIT\u2019s Tech Model Railroad Club left their programs in drawers for others to work on.",
        "\u201cHomebrew\u201d user groups exchanged code during their meetings.",
        "Later, company-speci\ufb01c user groups, such as Digital Equipment Corporation\u2019s DEC, accepted contributions of source-code programs, collected them onto tapes, and distributed the tapes to interested members.",
        "Computer and software companies eventually sought to limit the use of their software to authorized computers and paying customers.",
        "Releasing only the binary \ufb01les compiled from the source code, rather than the source code itself, helped them to achieve this goal, as well as protecting their code and their ideas from their competitors."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_12_2",
      "title": "1.12.2 Linux",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 43,
      "definition": "As an example of an open-source operating system, consider GNU/Linux.",
      "key_points": [
        "The GNU project produced many UNIX-compatible tools, including compilers, editors, and utilities, but never released a kernel.",
        "In 1991, a student in Finland, Linus Torvalds, released a rudimentary UNIX-like kernel using the GNU compilers and tools and invited contributions worldwide.",
        "The advent of the Internet meant that anyone interested could download the source code, modify it, and submit changes to Torvalds.",
        "Releasing updates once a week allowed this so-called Linux operating system to grow rapidly, enhanced by several thousand programmers.",
        "The resulting GNU/Linux operating system has spawned hundreds of unique distributions, or custom builds, of the system."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_12_3",
      "title": "1.12.3 BSD UNIX",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 44,
      "definition": "BSD UNIX has a longer and more complicated history than Linux.",
      "key_points": [
        "It started in as a derivative of AT&T\u2019s UNIX.",
        "Releases from the University of California at Berkeley (UCB) came in source and binary form, but they were not open- source because a license from AT&T was required.",
        "BSD UNIX\u2019s development was slowed by a lawsuit by AT&T, but eventually a fully functional, open-source version, 4.4BSD-lite, was released in 1994.",
        "Just as with Linux, there are many distributions of BSD UNIX, including FreeBSD, NetBSD, OpenBSD, and Dragon\ufb02yBSD.",
        "To explore the source code of FreeBSD, simply download the virtual machine image of the version of interest and boot it within VMware, as described above for Linux."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_12_4",
      "title": "1.12.4 Solaris",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 44,
      "definition": "Solaris is the commercial UNIX-based operating system of Sun Microsystems.",
      "key_points": [
        "Several groups interested in using OpenSolaris have started from that base and expanded its features.",
        "Their working set is Project Illumos, which has expanded from the OpenSolaris base to include more features and to be the basis for several products.",
        "Originally, Sun\u2019s SunOS operating system was based on BSD UNIX.",
        "Sun moved to AT&T\u2019s System V UNIX as its base in 1991.",
        "In 2005, Sun open-sourced most of the Solaris code as the OpenSolaris project."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_12_5",
      "title": "1.12.5 Open-Source Systems as Learning Tools",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 44,
      "definition": "The free software movement is driving legions of programmers to create thousands of open-source projects, including operating systems.",
      "key_points": [
        "Sites like http://freshmeat.net/ and http://distrowatch.com/ provide portals to many of these projects.",
        "As we stated earlier, open-source projects enable students to use source code as a learning tool.",
        "They can modify programs and test them,"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_13",
      "title": "1.13 Summary",
      "label": "Topic",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 45,
      "definition": "An operating system is software that manages the computer hardware, as well as providing an environment for application programs to run.",
      "key_points": [
        "Main memory is the only large storage area that the processor can access directly.",
        "Single-processor systems have only one processor, while multiprocessor systems contain two or more processors that share physical memory and peripheral devices.",
        "The most common multiprocessor design is symmetric multiprocessing (or SMP), where all processors are considered peers and run independently of one another.",
        "Clustered systems are a specialized form of multiprocessor systems and consist of multiple computer systems connected by a local-area network."
      ]
    },
    {
      "id": "CHAP_00_SUB_1_1",
      "title": "1.1 What are the three main purposes of an operating system?",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 47,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_2",
      "title": "1.2 We have stressed the need for an operating system to make ef\ufb01cient use",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 47,
      "definition": "of the computing hardware. When is it appropriate for the operating system to forsake this principle and to \u201cwaste\u201d resources? Why is such a system not really wasteful?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_3",
      "title": "1.3 What is the main dif\ufb01culty that a programmer must overcome in writing",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 47,
      "definition": "an operating system for a real-time environment?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_4",
      "title": "1.4 Keeping in mind the various de\ufb01nitions of operating system, consider",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 47,
      "definition": "whether the operating system should include applications such as web browsers and mail programs. Argue both that it should and that it should not, and support your answers.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_5",
      "title": "1.5 How does the distinction between kernel mode and user mode function",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 48,
      "definition": "as a rudimentary form of protection (security) system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_6",
      "title": "1.6 Which of the following instructions should be privileged?",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 48,
      "definition": "a. Set value of timer. b. Read the clock. c. Clear memory. d. Issue a trap instruction. e. Turn off interrupts. f. Modify entries in device-status table. g. Switch from user to kernel mode. h. Access I/O device.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_7",
      "title": "1.7 Some early computers protected the operating system by placing it in",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 48,
      "definition": "a memory partition that could not be modi\ufb01ed by either the user job or the operating system itself. Describe two dif\ufb01culties that you think could arise with such a scheme.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_8",
      "title": "1.8 Some CPUs provide for more than two modes of operation. What are",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 48,
      "definition": "two possible uses of these multiple modes?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_9",
      "title": "1.9 Timers could be used to compute the current time. Provide a short",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 48,
      "definition": "description of how this could be accomplished.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_10",
      "title": "1.10 Give two reasons why caches are useful. What problems do they solve?",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 48,
      "definition": "What problems do they cause? If a cache can be made as large as the device for which it is caching (for instance, a cache as large as a disk), why not make it that large and eliminate the device?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_11",
      "title": "1.11 Distinguish between the client\u2013server and peer-to-peer models of",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 48,
      "definition": "distributed systems. Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_12",
      "title": "1.12 In a multiprogramming and time-sharing environment, several users",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 48,
      "definition": "share the system simultaneously. This situation can result in various security problems. a. What are two such problems? b. Can we ensure the same degree of security in a time-shared machine as in a dedicated machine? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_13",
      "title": "1.13 The issue of resource utilization shows up in different forms in different",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 48,
      "definition": "types of operating systems. List what resources must be managed carefully in the following settings: a. Mainframe or minicomputer systems b. Workstations connected to servers c. Mobile computers",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_14",
      "title": "1.14 Under what circumstances would a user be better off using a time-",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "sharing system than a PC or a single-user workstation?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_15",
      "title": "1.15 Describe the differences between symmetric and asymmetric multipro-",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "cessing. What are three advantages and one disadvantage of multipro- cessor systems?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_16",
      "title": "1.16 How do clustered systems differ from multiprocessor systems? What is",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "required for two machines belonging to a cluster to cooperate to provide a highly available service?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_17",
      "title": "1.17 Consider a computing cluster consisting of two nodes running a",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "database. Describe two ways in which the cluster software can manage access to the data on the disk. Discuss the bene\ufb01ts and disadvantages of each.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_18",
      "title": "1.18 How are network computers different from traditional personal com-",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "puters? Describe some usage scenarios in which it is advantageous to use network computers.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_19",
      "title": "1.19 What is the purpose of interrupts? How does an interrupt differ from a",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "trap? Can traps be generated intentionally by a user program? If so, for what purpose?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_20",
      "title": "1.20 Direct memory access is used for high-speed I/O devices in order to",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "avoid increasing the CPU\u2019s execution load. a. How does the CPU interface with the device to coordinate the transfer? b. How does the CPU know when the memory operations are com- plete? c. The CPU is allowed to execute other programs while the DMA controller is transferring data. Does this process interfere with the execution of the user programs? If so, describe what forms of interference are caused.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_21",
      "title": "1.21 Some computer systems do not provide a privileged mode of operation",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "in hardware. Is it possible to construct a secure operating system for these computer systems? Give arguments both that it is and that it is not possible.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_22",
      "title": "1.22 Many SMP systems have different levels of caches; one level is local to",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "each processing core, and another level is shared among all processing cores. Why are caching systems designed this way?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_23",
      "title": "1.23 Consider an SMP system similar to the one shown in Figure 1.6. Illustrate",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "with an example how data residing in memory could in fact have a different value in each of the local caches.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_24",
      "title": "1.24 Discuss, with examples, how the problem of maintaining coherence of",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 49,
      "definition": "cached data manifests itself in the following processing environments: a. Single-processor systems b. Multiprocessor systems c. Distributed systems",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_25",
      "title": "1.25 Describe a mechanism for enforcing memory protection in order to",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 50,
      "definition": "prevent a program from modifying the memory associated with other programs.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_26",
      "title": "1.26 Which network con\ufb01guration\u2014LAN or WAN\u2014would best suit the",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 50,
      "definition": "following environments? a. A campus student union b. Several campus locations across a statewide university system c. A neighborhood",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_27",
      "title": "1.27 Describe some of the challenges of designing operating systems for",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 50,
      "definition": "mobile devices compared with designing operating systems for tradi- tional PCs.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_28",
      "title": "1.28 What are some advantages of peer-to-peer systems over client-server",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 50,
      "definition": "systems?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_29",
      "title": "1.29 Describe some distributed applications that would be appropriate for a",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 50,
      "definition": "peer-to-peer system.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00_SUB_1_30",
      "title": "1.30 Identify several advantages and several disadvantages of open-source",
      "label": "Exercise",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 50,
      "definition": "operating systems. Include the types of people who would \ufb01nd each aspect to be an advantage or a disadvantage. Bibliographical Notes [Brookshear (2012)] provides an overview of computer science in general. Thorough coverage of data structures can be found in [Cormen et al. (2009)]. [Russinovich and Solomon (2009)] give an overview of Microsoft Windows and covers considerable technical detail about the system internals and components. [McDougall and Mauro (2007)] cover the internals of the Solari",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_00",
      "title": "Chapter 1 Introduction",
      "label": "Chapter",
      "file_source": "01_Chapter 1 Introduction.pdf",
      "page": 1,
      "definition": "1 C H A P T E R Introduction An operating system is a program that manages a computer\u2019s hardware.",
      "key_points": [
        "It also provides a basis for application programs and acts as an intermediary between the computer user and the computer hardware.",
        "An amazing aspect of operating systems is how they vary in accomplishing these tasks.",
        "Mainframe operating systems are designed primarily to optimize utilization of hardware.",
        "1.1 What Operating Systems Do: We begin our discussion by looking at the operating system\u2019s role in the overall...",
        "1.1.1 User View: The user\u2019s view of the computer varies according to the interface being used....",
        "1.1.2 System View: From the computer\u2019s point of view, the operating system is the program most inti...",
        "1.1.3 De\ufb01ning Operating Systems: By now, you can probably see that the term operating system covers many roles an...",
        "1.2 Computer-System Organization: Before we can explore the details of how computer systems operate, we need gener..."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_1",
      "title": "2.1 Operating-System Services",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 1,
      "definition": "An operating system provides an environment for the execution of programs.",
      "key_points": [
        "It provides certain services to programs and to the users of those programs.",
        "The speci\ufb01c services provided, of course, differ from one operating system to another, but we can identify common classes.",
        "These operating system services are provided for the convenience of the programmer, to make the programming"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_2",
      "title": "2.2 User and Operating-System Interface",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 4,
      "definition": "We mentioned earlier that there are several ways for users to interface with the operating system.",
      "key_points": [
        "Here, we discuss two fundamental approaches.",
        "One provides a command-line interface, or command interpreter, that allows users to directly enter commands to be performed by the operating system.",
        "The other allows users to interface with the operating system via a graphical user interface, or GUI."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_2_1",
      "title": "2.2.1 Command Interpreters",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 4,
      "definition": "Some operating systems include the command interpreter in the kernel.",
      "key_points": [
        "Others, such as Windows and UNIX, treat the command interpreter as a special program that is running when a job is initiated or when a user \ufb01rst logs on (on interactive systems).",
        "On systems with multiple command interpreters to choose from, the interpreters are known as shells.",
        "For example, on UNIX and Linux systems, a user may choose among several different shells, including the Bourne shell, C shell, Bourne-Again shell, Korn shell, and others.",
        "Third-party shells and free user-written shells are also available.",
        "Most shells provide similar functionality, and a user\u2019s choice of which shell to use is generally based on personal preference."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_2_2",
      "title": "2.2.2 Graphical User Interfaces",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 5,
      "definition": "A second strategy for interfacing with the operating system is through a user- friendly graphical user interface, or GUI.",
      "key_points": [
        "Here, rather than entering commands directly via a command-line interface, users employ a mouse-based window- and-menu system characterized by a desktop metaphor.",
        "The user moves the mouse to position its pointer on images, or icons, on the screen (the desktop) that represent programs, \ufb01les, directories, and system functions.",
        "Depending on the mouse pointer\u2019s location, clicking a button on the mouse can invoke a program, select a \ufb01le or directory\u2014known as a folder\u2014or pull down a menu that contains commands.",
        "Graphical user interfaces \ufb01rst appeared due in part to research taking place in the early 1970s at Xerox PARC research facility.",
        "The \ufb01rst GUI appeared on the Xerox Alto computer in 1973."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_2_3",
      "title": "2.2.3 Choice of Interface",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 7,
      "definition": "The choice of whether to use a command-line or GUI interface is mostly one of personal preference.",
      "key_points": [
        "For example, if a frequent task requires a set of command-line steps, those steps can be recorded into a \ufb01le, and that \ufb01le can be run just like a program.",
        "System administrators who manage computers and power users who have deep knowledge of a system frequently use the command-line interface.",
        "For them, it is more ef\ufb01cient, giving them faster access to the activities they need to perform.",
        "Indeed, on some systems, only a subset of system functions is available via the GUI, leaving the less common tasks to those who are command-line knowledgeable.",
        "Further, command- line interfaces usually make repetitive tasks easier, in part because they have their own programmability."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_3",
      "title": "2.3 System Calls",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 8,
      "definition": "System calls provide an interface to the services made available by an operating system.",
      "key_points": [
        "In an interactive system, this approach will require a sequence of system calls, \ufb01rst to write a prompting message on the screen and then to read from the keyboard the characters that de\ufb01ne the two \ufb01les.",
        "These calls are generally available as routines written in C and C++, although certain low-level tasks (for example, tasks where hardware must be accessed directly) may have to be written using assembly-language instructions.",
        "Before we discuss how an operating system makes system calls available, let\u2019s \ufb01rst use an example to illustrate how system calls are used: writing a simple program to read data from one \ufb01le and copy them to another \ufb01le.",
        "The \ufb01rst input that the program will need is the names of the two \ufb01les: the input \ufb01le and the output \ufb01le.",
        "These names can be speci\ufb01ed in many ways, depending on the operating-system design."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_4",
      "title": "2.4 Types of System Calls",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 12,
      "definition": "System calls can be grouped roughly into six major categories: process control, \ufb01le manipulation, device manipulation, information maintenance, communications, and protection.",
      "key_points": [
        "In Sections 2.4.1 through 2.4.6, we brie\ufb02y discuss the types of system calls that may be provided by an operating system.",
        "Most of these system calls support, or are supported by, concepts and functions that are discussed in later chapters.",
        "Figure 2.8 summarizes the types of system calls normally provided by an operating system.",
        "As mentioned, in this text, we normally refer to the system calls by generic names.",
        "Throughout the text, however, we provide examples of the actual counterparts to the system calls for Windows, UNIX, and Linux systems."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_4_1",
      "title": "2.4.1 Process Control",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 12,
      "definition": "A running program needs to be able to halt its execution either normally (end()) or abnormally (abort()).",
      "key_points": [
        "If a system call is made to terminate the currently running program abnormally, or if the program runs into a problem and causes an error trap, a dump of memory is sometimes taken and an error message generated.",
        "The dump is written to disk and may be examined by a debugger\u2014a system program designed to aid the programmer in \ufb01nding and correcting errors, or bugs\u2014to determine the cause of the problem.",
        "Under either normal or abnormal circumstances, the operating system must transfer control to the invoking command interpreter.",
        "The command interpreter then reads the next command.",
        "In an interactive system, the command interpreter simply continues with the next command; it is assumed that the user will issue an appropriate command to respond to any error."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_4_2",
      "title": "2.4.2 File Management",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 17,
      "definition": "The \ufb01le system is discussed in more detail in Chapters 11 and 12.",
      "key_points": [
        "We can, however, identify several common system calls dealing with \ufb01les.",
        "We \ufb01rst need to be able to create() and delete() \ufb01les.",
        "Either system call requires the name of the \ufb01le and perhaps some of the \ufb01le\u2019s attributes.",
        "Once the \ufb01le is created, we need to open() it and to use it.",
        "We may also read(), write(), or reposition() (rewind or skip to the end of the \ufb01le, for example)."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_4_3",
      "title": "2.4.3 Device Management",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 17,
      "definition": "A process may need several resources to execute\u2014main memory, disk drives, access to \ufb01les, and so on.",
      "key_points": [
        "If the resources are available, they can be granted, and control can be returned to the user process.",
        "Otherwise, the process will have to wait until suf\ufb01cient resources are available.",
        "The various resources controlled by the operating system can be thought of as devices.",
        "Some of these devices are physical devices (for example, disk drives), while others can be thought of as abstract or virtual devices (for example, \ufb01les).",
        "A system with multiple users may require us to \ufb01rst request() a device, to ensure exclusive use of it."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_4_4",
      "title": "2.4.4 Information Maintenance",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 18,
      "definition": "Many system calls exist simply for the purpose of transferring information between the user program and the operating system.",
      "key_points": [
        "Even microprocessors provide a CPU mode known as single step, in which a trap is executed by the CPU after every instruction.",
        "In addition, the operating system keeps information about all its processes, and system calls are used to access this information.",
        "Generally, calls are also used to reset the process information (get process attributes() and set process attributes())."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_4_5",
      "title": "2.4.5 Communication",
      "label": "Topic",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 18,
      "definition": "There are two common models of interprocess communication: the message- passing model and the shared-memory model.",
      "key_points": [
        "In the message-passing model, the communicating processes exchange messages with one another to transfer information.",
        "Messages can be exchanged between the processes either directly or indirectly through a common mailbox.",
        "The name of the other communicator must be known, be it another process on the same system or a process on another computer connected by a communications network."
      ]
    },
    {
      "id": "CHAP_01_SUB_2_4_6",
      "title": "2.4.6 Protection",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 19,
      "definition": "Protection provides a mechanism for controlling access to the resources provided by a computer system. Historically, protection was a concern only on multiprogrammed computer systems with several users. However, with the advent of networking and the Internet, all computer systems, from servers to mobile handheld devices, must be concerned with protection. Typically, system calls providing protection include set permission() and get permission(), which manipulate the permission settings of resour",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_5",
      "title": "2.5 System Programs",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 20,
      "definition": "Another aspect of a modern system is its collection of system programs. Recall Figure 1.1, which depicted the logical computer hierarchy. At the lowest level is hardware. Next is the operating system, then the system programs, and \ufb01nally the application programs. System programs, also known as system utilities, provide a convenient environment for program development and execution. Some of them are simply user interfaces to system calls. Others are considerably more complex. They can be divided ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_6",
      "title": "2.6 Operating-System Design and Implementation",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 21,
      "definition": "In this section, we discuss problems we face in designing and implementing an operating system. There are, of course, no complete solutions to such problems, but there are approaches that have proved successful.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_6_1",
      "title": "2.6.1 Design Goals",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 21,
      "definition": "The \ufb01rst problem in designing a system is to de\ufb01ne goals and speci\ufb01cations. At the highest level, the design of the system will be affected by the choice of hardware and the type of system: batch, time sharing, single user, multiuser, distributed, real time, or general purpose. Beyond this highest design level, the requirements may be much harder to specify. The requirements can, however, be divided into two basic groups: user goals and system goals. Users want certain obvious properties in a sy",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_6_2",
      "title": "2.6.2 Mechanisms and Policies",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 22,
      "definition": "One important principle is the separation of policy from mechanism. Mecha- nisms determine how to do something; policies determine what will be done. For example, the timer construct (see Section 1.5.2) is a mechanism for ensuring CPU protection, but deciding how long the timer is to be set for a particular user is a policy decision. The separation of policy and mechanism is important for \ufb02exibility. Policies are likely to change across places or over time. In the worst case, each change in poli",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_6_3",
      "title": "2.6.3 Implementation",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 22,
      "definition": "Once an operating system is designed, it must be implemented. Because operating systems are collections of many programs, written by many people over a long period of time, it is dif\ufb01cult to make general statements about how they are implemented.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_7",
      "title": "2.7 Operating-System Structure",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 24,
      "definition": "A system as large and complex as a modern operating system must be engineered carefully if it is to function properly and be modi\ufb01ed easily. A common approach is to partition the task into small components, or modules, rather than have one monolithic system. Each of these modules should be a well-de\ufb01ned portion of the system, with carefully de\ufb01ned inputs, outputs, and functions. We have already discussed brie\ufb02y in Chapter 1 the common components of operating systems. In this section, we discuss ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_7_1",
      "title": "2.7.1 Simple Structure",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 24,
      "definition": "Many operating systems do not have well-de\ufb01ned structures. Frequently, such systems started as small, simple, and limited systems and then grew beyond their original scope. MS-DOS is an example of such a system. It was originally designed and implemented by a few people who had no idea that it would become so popular. It was written to provide the most functionality in the least space, so it was not carefully divided into modules. Figure 2.11 shows its structure. In MS-DOS, the interfaces and le",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_7_2",
      "title": "2.7.2 Layered Approach",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 25,
      "definition": "With proper hardware support, operating systems can be broken into pieces that are smaller and more appropriate than those allowed by the original MS-DOS and UNIX systems. The operating system can then retain much greater control over the computer and over the applications that make use of that computer. Implementers have more freedom in changing the inner workings of the system and in creating modular operating systems. Under a top- down approach, the overall functionality and features are dete",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_7_3",
      "title": "2.7.3 Microkernels",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 27,
      "definition": "We have already seen that as UNIX expanded, the kernel became large and dif\ufb01cult to manage. In the mid-1980s, researchers at Carnegie Mellon University developed an operating system called Mach that modularized the kernel using the microkernel approach. This method structures the operating system by removing all nonessential components from the kernel and implementing them as system and user-level programs. The result is a smaller kernel. There is little consensus regarding which services should",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_7_4",
      "title": "2.7.4 Modules",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 28,
      "definition": "Perhaps the best current methodology for operating-system design involves using loadable kernel modules. Here, the kernel has a set of core components and links in additional services via modules, either at boot time or during run time. This type of design is common in modern implementations of UNIX, such as Solaris, Linux, and Mac OS X, as well as Windows. The idea of the design is for the kernel to provide core services while other services are implemented dynamically, as the kernel is running",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_7_5",
      "title": "2.7.5 Hybrid Systems",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 29,
      "definition": "In practice, very few operating systems adopt a single, strictly de\ufb01ned structure. Instead, they combine different structures, resulting in hybrid systems that address performance, security, and usability issues. For example, both Linux and Solaris are monolithic, because having the operating system in a single address space provides very ef\ufb01cient performance. However, they are also modular, so that new functionality can be dynamically added to the kernel. Windows is largely monolithic as well (",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_8",
      "title": "2.8 Operating-System Debugging",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 32,
      "definition": "We have mentioned debugging frequently in this chapter. Here, we take a closer look. Broadly, debugging is the activity of \ufb01nding and \ufb01xing errors in a system, both in hardware and in software. Performance problems are considered bugs, so debugging can also include performance tuning, which seeks to improve performance by removing processing bottlenecks. In this section, we explore debugging process and kernel errors and performance problems. Hardware debugging is outside the scope of this text.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_8_1",
      "title": "2.8.1 Failure Analysis",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 32,
      "definition": "If a process fails, most operating systems write the error information to a log \ufb01le to alert system operators or users that the problem occurred. The operating system can also take a core dump\u2014a capture of the memory of the process\u2014 and store it in a \ufb01le for later analysis. (Memory was referred to as the \u201ccore\u201d in the early days of computing.) Running programs and core dumps can be probed by a debugger, which allows a programmer to explore the code and memory of a process. Debugging user-level p",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_8_2",
      "title": "2.8.2 Performance Tuning",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 33,
      "definition": "We mentioned earlier that performance tuning seeks to improve performance by removing processing bottlenecks. To identify bottlenecks, we must be able to monitor system performance. Thus, the operating system must have some means of computing and displaying measures of system behavior. In a number of systems, the operating system does this by producing trace listings of system behavior. All interesting events are logged with their time and important parameters and are written to a \ufb01le. Later, an",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_8_3",
      "title": "2.8.3 DTrace",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 33,
      "definition": "DTrace is a facility that dynamically adds probes to a running system, both in user processes and in the kernel. These probes can be queried via the D programming language to determine an astonishing amount about the kernel, the system state, and process activities. For example, Figure 2.20 follows an application as it executes a system call (ioctl()) and shows the functional calls within the kernel as they execute to perform the system call. Lines ending with \u201cU\u201d are executed in user mode, and ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_9",
      "title": "2.9 Operating-System Generation",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 37,
      "definition": "It is possible to design, code, and implement an operating system speci\ufb01cally for one machine at one site. More commonly, however, operating systems are designed to run on any of a class of machines at a variety of sites with a variety of peripheral con\ufb01gurations. The system must then be con\ufb01gured or generated for each speci\ufb01c computer site, a process sometimes known as system generation SYSGEN. The operating system is normally distributed on disk, on CD-ROM or DVD-ROM, or as an \u201cISO\u201d image, whi",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_10",
      "title": "2.10 System Boot",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 38,
      "definition": "After an operating system is generated, it must be made available for use by the hardware. But how does the hardware know where the kernel is or how to load that kernel? The procedure of starting a computer by loading the kernel is known as booting the system. On most computer systems, a small piece of code known as the bootstrap program or bootstrap loader locates the kernel, loads it into main memory, and starts its execution. Some computer systems, such as PCs, use a two-step process in which",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_11",
      "title": "2.11 Summary",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 39,
      "definition": "Operating systems provide a number of services. At the lowest level, system calls allow a running program to make requests from the operating system directly. At a higher level, the command interpreter or shell provides a mechanism for a user to issue a request without writing a program. Commands may come from \ufb01les during batch-mode execution or directly from a terminal or desktop GUI when in an interactive or time-shared mode. System programs are provided to satisfy many common user requests.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_1",
      "title": "2.1 What is the purpose of system calls?",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 40,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_2",
      "title": "2.2 What are the \ufb01ve major activities of an operating system with regard to",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 40,
      "definition": "process management?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_3",
      "title": "2.3 What are the three major activities of an operating system with regard",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 40,
      "definition": "to memory management?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_4",
      "title": "2.4 What are the three major activities of an operating system with regard",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 40,
      "definition": "to secondary-storage management?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_5",
      "title": "2.5 What is the purpose of the command interpreter? Why is it usually",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 40,
      "definition": "separate from the kernel?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_6",
      "title": "2.6 What system calls have to be executed by a command interpreter or shell",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "in order to start a new process?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_7",
      "title": "2.7 What is the purpose of system programs?",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_8",
      "title": "2.8 What is the main advantage of the layered approach to system design?",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "What are the disadvantages of the layered approach?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_9",
      "title": "2.9 List \ufb01ve services provided by an operating system, and explain how each",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "creates convenience for users. In which cases would it be impossible for user-level programs to provide these services? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_10",
      "title": "2.10 Why do some systems store the operating system in \ufb01rmware, while",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "others store it on disk?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_11",
      "title": "2.11 How could a system be designed to allow a choice of operating systems",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "from which to boot? What would the bootstrap program need to do? Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_12",
      "title": "2.12 The services and functions provided by an operating system can be",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "divided into two main categories. Brie\ufb02y describe the two categories, and discuss how they differ.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_13",
      "title": "2.13 Describe three general methods for passing parameters to the operating",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "system.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_14",
      "title": "2.14 Describe how you could obtain a statistical pro\ufb01le of the amount of time",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "spent by a program executing different sections of its code. Discuss the importance of obtaining such a statistical pro\ufb01le.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_15",
      "title": "2.15 What are the \ufb01ve major activities of an operating system with regard to",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "\ufb01le management?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_16",
      "title": "2.16 What are the advantages and disadvantages of using the same system-",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "call interface for manipulating both \ufb01les and devices?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_17",
      "title": "2.17 Would it be possible for the user to develop a new command interpreter",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "using the system-call interface provided by the operating system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_18",
      "title": "2.18 What are the two models of interprocess communication? What are the",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "strengths and weaknesses of the two approaches?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_19",
      "title": "2.19 Why is the separation of mechanism and policy desirable?",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_20",
      "title": "2.20 It is sometimes dif\ufb01cult to achieve a layered approach if two components",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "of the operating system are dependent on each other. Identify a scenario in which it is unclear how to layer two system components that require tight coupling of their functionalities.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_21",
      "title": "2.21 What is the main advantage of the microkernel approach to system",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "design? How do user programs and system services interact in a microkernel architecture? What are the disadvantages of using the microkernel approach?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_22",
      "title": "2.22 What are the advantages of using loadable kernel modules?",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 41,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_23",
      "title": "2.23 How are iOS and Android similar? How are they different?",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 42,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_24",
      "title": "2.24 Explain why Java programs running on Android systems do not use the",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 42,
      "definition": "standard Java API and virtual machine.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_25",
      "title": "2.25 The experimental Synthesis operating system has an assembler incor-",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 42,
      "definition": "porated in the kernel. To optimize system-call performance, the kernel assembles routines within kernel space to minimize the path that the system call must take through the kernel. This approach is the antithesis of the layered approach, in which the path through the kernel is extended to make building the operating system easier. Discuss the pros and cons of the Synthesis approach to kernel design and system-performance optimization. Programming Problems",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01_SUB_2_26",
      "title": "2.26 In Section 2.3, we described a program that copies the contents of one \ufb01le",
      "label": "Exercise",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 42,
      "definition": "to a destination \ufb01le. This program works by \ufb01rst prompting the user for the name of the source and destination \ufb01les. Write this program using either the Windows or POSIX API. Be sure to include all necessary error checking, including ensuring that the source \ufb01le exists. Once you have correctly designed and tested the program, if you used a system that supports it, run the program using a utility that traces system calls. Linux systems provide the strace utility, and Solaris and Mac OS X systems ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_01",
      "title": "Chapter 2 Operating-System Structures",
      "label": "Chapter",
      "file_source": "02_Chapter 2 Operating-System Structures.pdf",
      "page": 1,
      "definition": "The design of a new operating system is a major task.",
      "key_points": [
        "It is important that the goals of the system be well de\ufb01ned before the design begins.",
        "CHAPTER OBJECTIVES \u2022 To describe the services an operating system provides to users, processes, and other systems.",
        "2.1 Operating-System Services An operating system provides an environment for the execution of programs.",
        "2.1 Operating-System Services: An operating system provides an environment for the execution of programs....",
        "2.2 User and Operating-System Interface: We mentioned earlier that there are several ways for users to interface with the...",
        "2.2.1 Command Interpreters: Some operating systems include the command interpreter in the kernel....",
        "2.2.2 Graphical User Interfaces: A second strategy for interfacing with the operating system is through a user- f...",
        "2.2.3 Choice of Interface: The choice of whether to use a command-line or GUI interface is mostly one of pe..."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_1",
      "title": "3.1 Process Concept",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 1,
      "definition": "A question that arises in discussing operating systems involves what to call all the CPU activities.",
      "key_points": [
        "A batch system executes jobs, whereas a time-shared"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_1_1",
      "title": "3.1.1 The Process",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 2,
      "definition": "Informally, as mentioned earlier, a process is a program in execution.",
      "key_points": [
        "A process is more than the program code, which is sometimes known as the text section.",
        "It also includes the current activity, as represented by the value of the program counter and the contents of the processor\u2019s registers.",
        "A process generally also includes the process stack, which contains temporary data (such as function parameters, return addresses, and local variables), and a data section, which contains global variables.",
        "A process may also include a heap, which is memory that is dynamically allocated during process run time.",
        "The structure of a process in memory is shown in Figure 3.1. We emphasize that a program by itself is not a process."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_1_2",
      "title": "3.1.2 Process State",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 3,
      "definition": "As a process executes, it changes state.",
      "key_points": [
        "The state of a process is de\ufb01ned in part by the current activity of that process.",
        "A process may be in one of the following states: \u2022 New.",
        "The process is being created.",
        "The process is waiting for some event to occur (such as an I/O completion or reception of a signal).",
        "The process is waiting to be assigned to a processor."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_1_3",
      "title": "3.1.3 Process Control Block",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 3,
      "definition": "Each process is represented in the operating system by a process control block (PCB)\u2014also called a task control block.",
      "key_points": [
        "A PCBis shown in Figure 3.3. It contains many pieces of information associated with a speci\ufb01c process, including these:"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_1_4",
      "title": "3.1.4 Threads",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 5,
      "definition": "The process model discussed so far has implied that a process is a program that performs a single thread of execution.",
      "key_points": [
        "For example, when a process is running a word-processor program, a single thread of instructions is being executed.",
        "This single thread of control allows the process to perform only one task at a time.",
        "The user cannot simultaneously type in characters and run the spell checker within the same process, for example.",
        "Most modern operating systems have extended the process concept to allow a process to have multiple threads of execution and thus to perform more than one task at a time.",
        "This feature is especially bene\ufb01cial on multicore systems, where multiple threads can run in parallel."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_2",
      "title": "3.2 Process Scheduling",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 6,
      "definition": "The objective of multiprogramming is to have some process running at all times, to maximize CPU utilization.",
      "key_points": [
        "The objective of time sharing is to switch the CPU among processes so frequently that users can interact with each program"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_2_1",
      "title": "3.2.1 Scheduling Queues",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 7,
      "definition": "As processes enter the system, they are put into a job queue, which consists of all processes in the system.",
      "key_points": [
        "The processes that are residing in main memory and are ready and waiting to execute are kept on a list called the ready queue.",
        "When a process is allocated the CPU, it executes for a while and eventually quits, is interrupted, or waits for the occurrence of a particular event, such as the completion of an I/O request.",
        "Suppose the process makes an I/O request to a shared device, such as a disk.",
        "Since there are many processes in the system, the disk may be busy with the I/O request of some other process.",
        "The process therefore may have to wait for the disk."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_2_2",
      "title": "3.2.2 Schedulers",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 8,
      "definition": "A process migrates among the various scheduling queues throughout its lifetime.",
      "key_points": [
        "The operating system must select, for scheduling purposes, processes from these queues in some fashion.",
        "The selection process is carried out by the appropriate scheduler.",
        "Often, in a batch system, more processes are submitted than can be executed immediately.",
        "These processes are spooled to a mass-storage device (typically a disk), where they are kept for later execution.",
        "The long-term scheduler, or job scheduler, selects processes from this pool and loads them into memory for"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_2_3",
      "title": "3.2.3 Context Switch",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 10,
      "definition": "As mentioned in Section 1.2.1, interrupts cause the operating system to change a CPU from its current task and to run a kernel routine.",
      "key_points": [
        "When an interrupt occurs, the system needs to save the current context of the process running on the CPU so that it can restore that context when its processing is done, essentially suspending the process and then resuming it.",
        "The context is represented in the PCB of the process.",
        "It includes the value of the CPU registers, the process state (see Figure 3.2), and memory-management information.",
        "Switching the CPU to another process requires performing a state save of the current process and a state restore of a different process.",
        "When a context switch occurs, the kernel saves the context of the old process in its PCB and loads the saved context of the new process scheduled to run."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_3",
      "title": "3.3 Operations on Processes",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 11,
      "definition": "The processes in most systems can execute concurrently, and they may be created and deleted dynamically.",
      "key_points": [
        "Thus, these systems must provide a mechanism for process creation and termination.",
        "In this section, we explore the mechanisms involved in creating processes and illustrate process creation on UNIX and Windows systems."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_3_1",
      "title": "3.3.1 Process Creation",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 12,
      "definition": "During the course of execution, a process may create several new processes.",
      "key_points": [
        "As mentioned earlier, the creating process is called a parent process, and the new processes are called the children of that process.",
        "Each of these new processes may in turn create other processes, forming a tree of processes.",
        "Most operating systems (including UNIX, Linux, and Windows) identify processes according to a unique process identi\ufb01er (or pid), which is typically an integer number.",
        "The pid provides a unique value for each process in the system, and it can be used as an index to access various attributes of a process within the kernel.",
        "Figure 3.8 illustrates a typical process tree for the Linux operating system, showing the name of each process and its pid."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_3_2",
      "title": "3.3.2 Process Termination",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 16,
      "definition": "A process terminates when it \ufb01nishes executing its \ufb01nal statement and asks the operating system to delete it by using the exit() system call.",
      "key_points": [
        "At that point, the process may return a status value (typically an integer) to its parent process (via the wait() system call).",
        "All the resources of the process\u2014including physical and virtual memory, open \ufb01les, and I/O buffers\u2014are deallocated by the operating system.",
        "A process can cause the termination of another process via an appropriate system call (for example, TerminateProcess() in Windows)."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_4",
      "title": "3.4 Interprocess Communication",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 18,
      "definition": "Clearly, any process that shares data with other processes is a cooperating process.",
      "key_points": [
        "Processes executing concurrently in the operating system may be either independent processes or cooperating processes.",
        "A process is independent if it cannot affect or be affected by the other processes executing in the system.",
        "Any process that does not share data with any other process is independent.",
        "A process is cooperating if it can affect or be affected by the other processes executing in the system.",
        "There are several reasons for providing an environment that allows process cooperation: \u2022 Information sharing."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_4_1",
      "title": "3.4.1 Shared-Memory Systems",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 20,
      "definition": "Interprocess communication using shared memory requires communicating processes to establish a region of shared memory.",
      "key_points": [
        "Typically, a shared-memory region resides in the address space of the process creating the shared-memory segment.",
        "Other processes that wish to communicate using this shared-memory segment must attach it to their address space.",
        "Recall that, normally, the operating system tries to prevent one process from accessing another process\u2019s memory.",
        "Shared memory requires that two or more processes agree to remove this restriction.",
        "The form of the data and the location are determined by these processes and are not under the operating system\u2019s control."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_4_2",
      "title": "3.4.2 Message-Passing Systems",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 22,
      "definition": "Another way to achieve the same effect is for the operating system to provide the means for cooperating processes to communicate with each other via a message-passing facility.",
      "key_points": [
        "In Section 3.4.1, we showed how cooperating processes can communicate in a shared-memory environment.",
        "The scheme requires that these processes share a region of memory and that the code for accessing and manipulating the shared memory be written explicitly by the application programmer.",
        "Message passing provides a mechanism to allow processes to communicate and to synchronize their actions without sharing the same address space.",
        "It is particularly useful in a distributed environment, where the communicating processes may reside on different computers connected by a network.",
        "A message-passing facility provides at least two operations: send(message) receive(message) Messages sent by a process can be either \ufb01xed or variable in size."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_5",
      "title": "3.5 Examples of IPC Systems",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 26,
      "definition": "In this section, we explore three different IPC systems.",
      "key_points": [
        "We \ufb01rst cover the POSIX API forshared memoryand thendiscussmessage passinginthe Machoperating system.",
        "We conclude with Windows, which interestingly uses shared memory as a mechanism for providing certain types of message passing."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_5_1",
      "title": "3.5.1 An Example: POSIX Shared Memory",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 26,
      "definition": "Several IPC mechanisms are available for POSIX systems, including shared memory and message passing.",
      "key_points": [
        "A process must \ufb01rst create message next consumed; while (true) { receive(next consumed); /* consume the item in next consumed */ } Figure 3.16 The consumer process using message passing.",
        "Here, we explore the POSIX API for shared memory.",
        "POSIX shared memory is organized using memory-mapped \ufb01les, which associate the region of shared memory with a \ufb01le."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_5_2",
      "title": "3.5.2 An Example: Mach",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 27,
      "definition": "As an example of message passing, we next consider the Mach operating system.",
      "key_points": [
        "The Mach kernel supports the creation and destruction of multiple tasks, which are similar to processes but have multiple threads of control and fewer associated resources.",
        "You may recall that we introduced Mach in Chapter 2 as part of the Mac OS X operating system.",
        "Most communication in Mach\u2014 including all intertask information\u2014is carried out by messages.",
        "Messages are sent to and received from mailboxes, called ports in Mach."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_5_3",
      "title": "3.5.3 An Example: Windows",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 31,
      "definition": "The Windows operating system is an example of modern design that employs modularity to increase functionality and decrease the time needed to imple- ment new features.",
      "key_points": [
        "It is used for communication between two processes on the same machine.",
        "(Remote procedure calls are covered in detail in Section 3.6.2.) Like Mach, Windows uses a port object to establish and maintain a connection between two processes.",
        "Server processes publish connection-port objects that are visible to all processes.",
        "For small messages (up to 256 bytes), the port\u2019s message queue is used as intermediate storage, and the messages are copied from one process to the other.",
        "When the amount of data is too large to \ufb01t into a section object, an API is available that allows server processes to read and write directly into the address space of a client."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_6",
      "title": "3.6 Communication in Client\u2013Server Systems",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 32,
      "definition": "In Section 3.4, we described how processes can communicate using shared memory and message passing.",
      "key_points": [
        "These techniques can be used for communica- tion in client\u2013server systems (Section 1.11.4) as well.",
        "In this section, we explore three other strategies for communication in client\u2013server systems: sockets, remote procedure calls (RPCs), and pipes."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_6_1",
      "title": "3.6.1 Sockets",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 32,
      "definition": "A socket is de\ufb01ned as an endpoint for communication.",
      "key_points": [
        "A pair of processes communicating over a network employs a pair of sockets\u2014one for each process.",
        "When a client process initiates a request for a connection, it is assigned a port by its host computer.",
        "The packets traveling between the hosts are delivered to the appropriate process based on the destination port number.",
        "Therefore, if another process also on host X wished to establish another connection with the same web server, it would be assigned a port number greater than 1024 and not equal to 1625."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_6_2",
      "title": "3.6.2 Remote Procedure Calls",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 34,
      "definition": "One of the most common forms of remote service is the RPC paradigm, which we discussed brie\ufb02y in Section 3.5.2. The RPC was designed as a way to",
      "key_points": []
    },
    {
      "id": "CHAP_02_SUB_3_6_3",
      "title": "3.6.3 Pipes",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 38,
      "definition": "A pipe acts as a conduit allowing two processes to communicate.",
      "key_points": [
        "They typically provide one of the simpler ways for processes to communicate with one another, although they also have some limitations.",
        "Must a relationship (such as parent\u2013child) exist between the communi- cating processes?",
        "Can the pipes communicate over a network, or must the communicating processes reside on the same machine?",
        "3.6.3.1 Ordinary Pipes Ordinary pipes allow two processes to communicate in standard producer\u2013 consumer fashion: the producer writes to one end of the pipe (the write-end) and the consumer reads from the other end (the read-end).",
        "In both program examples, one process writes the message Greetings to the pipe, while the other process reads this message from the pipe."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_7",
      "title": "3.7 Summary",
      "label": "Topic",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 43,
      "definition": "A process is a program in execution.",
      "key_points": [
        "As a process executes, it changes state.",
        "The state of a process is de\ufb01ned by that process\u2019s current activity.",
        "Each process may be in one of the following states: new, ready, running, waiting, or terminated."
      ]
    },
    {
      "id": "CHAP_02_SUB_3_1",
      "title": "3.1 Using the program shown in Figure 3.30, explain what the output will",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 45,
      "definition": "be at LINE A.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_2",
      "title": "3.2 Including the initial parent process, how many processes are created by",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 45,
      "definition": "the program shown in Figure 3.31?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_3",
      "title": "3.3 Original versions of Apple\u2019s mobile iOS operating system provided no",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 46,
      "definition": "means of concurrent processing. Discuss three major complications that concurrent processing adds to an operating system.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_4",
      "title": "3.4 The Sun UltraSPARC processor has multiple register sets. Describe what",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 46,
      "definition": "happens when a context switch occurs if the new context is already loaded into one of the register sets. What happens if the new context is in memory rather than in a register set and all the register sets are in use?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_5",
      "title": "3.5 When a process creates a new process using the fork() operation, which",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 46,
      "definition": "of the following states is shared between the parent process and the child process? a. Stack b. Heap c. Shared memory segments",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_6",
      "title": "3.6 Consider the \u201cexactly once\u201dsemantic with respect to the RPC mechanism.",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 46,
      "definition": "Does the algorithm for implementing this semantic execute correctly even if the ACK message sent back to the client is lost due to a network problem? Describe the sequence of messages, and discuss whether \u201cexactly once\u201d is still preserved.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_7",
      "title": "3.7 Assume that a distributed system is susceptible to server failure. What",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 46,
      "definition": "mechanisms would be required to guarantee the \u201cexactly once\u201d semantic for execution of RPCs? Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_8",
      "title": "3.8 Describe the differences among short-term, medium-term, and long-",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 46,
      "definition": "term scheduling.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_9",
      "title": "3.9 Describe the actions taken by a kernel to context-switch between",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 47,
      "definition": "processes.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_10",
      "title": "3.10 Construct a process tree similar to Figure 3.8. To obtain process infor-",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 47,
      "definition": "mation for the UNIX or Linux system, use the command ps -ael. #include <sys/types.h> #include <stdio.h> #include <unistd.h> int main() { pid t pid; /* fork a child process */ pid = fork(); if (pid < 0) { /* error occurred */ fprintf(stderr, \"Fork Failed\"); return 1; } else if (pid == 0) { /* child process */ execlp(\"/bin/ls\",\"ls\",NULL); printf(\"LINE J\"); } else { /* parent process */ /* parent will wait for the child to complete */ wait(NULL); printf(\"Child Complete\"); } return 0; } Figure 3.33 ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_11",
      "title": "3.11 Explain the role of the init process on UNIX and Linux systems in regard",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 48,
      "definition": "to process termination.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_12",
      "title": "3.12 Including the initial parent process, how many processes are created by",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 48,
      "definition": "the program shown in Figure 3.32?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_13",
      "title": "3.13 Explain the circumstances under which which the line of code marked",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 48,
      "definition": "printf(\"LINE J\") in Figure 3.33 will be reached.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_14",
      "title": "3.14 Using the program in Figure 3.34, identify the values of pid at lines A, B,",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 48,
      "definition": "C, and D. (Assume that the actual pids of the parent and child are 2600 and 2603, respectively.) #include <sys/types.h> #include <stdio.h> #include <unistd.h> int main() { pid t pid, pid1; /* fork a child process */ pid = fork(); if (pid < 0) { /* error occurred */ fprintf(stderr, \"Fork Failed\"); return 1; } else if (pid == 0) { /* child process */ pid1 = getpid(); printf(\"child: pid = %d\",pid); /* A */ printf(\"child: pid1 = %d\",pid1); /* B */ } else { /* parent process */ pid1 = getpid(); print",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_15",
      "title": "3.15 Give an example of a situation in which ordinary pipes are more suitable",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 49,
      "definition": "than named pipes and an example of a situation in which named pipes are more suitable than ordinary pipes.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_16",
      "title": "3.16 Consider the RPC mechanism. Describe the undesirable consequences",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 49,
      "definition": "that could arise from not enforcing either the \u201cat most once\u201d or \u201cexactly once\u201d semantic. Describe possible uses for a mechanism that has neither of these guarantees.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_17",
      "title": "3.17 Using the program shown in Figure 3.35, explain what the output will",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 49,
      "definition": "be at lines X and Y.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_18",
      "title": "3.18 What are the bene\ufb01ts and the disadvantages of each of the following?",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 49,
      "definition": "Consider both the system level and the programmer level. a. Synchronous and asynchronous communication b. Automatic and explicit buffering c. Send by copy and send by reference d. Fixed-sized and variable-sized messages",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_19",
      "title": "3.19 Using either a UNIX or a Linux system, write a C program that forks",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 50,
      "definition": "a child process that ultimately becomes a zombie process. This zombie process must remain in the system for at least 10 seconds. Process states can be obtained from the command ps -l The process states are shown below the S column; processes with a state of Z are zombies. The process identi\ufb01er (pid) of the child process is listed in the PID column, and that of the parent is listed in the PPID column. Perhaps the easiest way to determine that the child process is indeed a zombie is to run the pro",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_20",
      "title": "3.20 An operating system\u2019s pid manager is responsible for managing process",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 50,
      "definition": "identi\ufb01ers. When a process is \ufb01rst created, it is assigned a unique pid by the pid manager. The pid is returned to the pid manager when the process completes execution, and the manager may later reassign this pid. Process identi\ufb01ers are discussed more fully in Section 3.3.1. What is most important here is to recognize that process identi\ufb01ers must be unique; no two active processes can have the same pid. Use the following constants to identify the range of possible pid values: #define MIN PID 300",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_21",
      "title": "3.21 The Collatz conjecture concerns what happens when we take any",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 51,
      "definition": "positive integer n and apply the following algorithm: n = ! n/2, if n is even \u00d7 n + 1, if n is odd The conjecture states that when this algorithm is continually applied, all positive integers will eventually reach 1. For example, if n = 35, the sequence is 35, 106, 53, 160, 80, 40, 20, 10, 5, 16, 8, 4, 2, 1 Write a C program using the fork() system call that generates this sequence in the child process. The starting number will be provided from the command line. For example, if 8 is passed as a ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_22",
      "title": "3.22 In Exercise 3.21, the child process must output the sequence of numbers",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 51,
      "definition": "generated from the algorithm speci\ufb01ed by the Collatz conjecture because the parent and child have their own copies of the data. Another approach to designing this program is to establish a shared-memory object between the parent and child processes. This technique allows the child to write the contents of the sequence to the shared-memory object. The parent can then output the sequence when the child completes. Because the memory is shared, any changes the child makes will be re\ufb02ected in the par",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_23",
      "title": "3.23 Section 3.6.1 describes port numbers below 1024 as being well known\u2014",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 51,
      "definition": "that is, they provide standard services. Port 17 is known as the quote-of-",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_24",
      "title": "3.24 A haiku is a three-line poem in which the \ufb01rst line contains \ufb01ve syllables,",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 52,
      "definition": "the second line contains seven syllables, and the third line contains \ufb01ve syllables. Write a haiku server that listens to port 5575. When a client connects to this port, the server responds with a haiku. The date client shown in Figure 3.22 can be used to read the quotes returned by your haiku server.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_25",
      "title": "3.25 An echo server echoes back whatever it receives from a client. For",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 52,
      "definition": "example, if a client sends the server the string Hello there!, the server will respond with Hello there! Write an echo server using the Java networking API described in Section 3.6.1. This server will wait for a client connection using the accept() method. When a client connection is received, the server will loop, performing the following steps: \u2022 Read data from the socket into a buffer. \u2022 Write the contents of the buffer back to the client. The server will break out of the loop only when it ha",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_26",
      "title": "3.26 Design a program using ordinary pipes in which one process sends a",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 52,
      "definition": "string message to a second process, and the second process reverses the case of each character in the message and sends it back to the \ufb01rst process. For example, if the \ufb01rst process sends the messageHi There, the second process will return hI tHERE. This will require using two pipes, one for sending the original message from the \ufb01rst to the second process and the other for sending the modi\ufb01ed message from the second to the \ufb01rst process. You can write this program using either UNIX or Windows pip",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02_SUB_3_27",
      "title": "3.27 Design a \ufb01le-copying program named filecopy using ordinary pipes.",
      "label": "Exercise",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 52,
      "definition": "This program will be passed two parameters: the name of the \ufb01le to be",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_02",
      "title": "Chapter 3 Processes",
      "label": "Chapter",
      "file_source": "03_Chapter 3 Processes.pdf",
      "page": 1,
      "definition": "This evolution required \ufb01rmer control and more compartmentalization of the various pro- grams; and these needs resulted in the notion of a process, which is a program in execution.",
      "key_points": [
        "3 C H A P T E R Processes Early computers allowed only one program to be executed at a time.",
        "A process is the unit of work in a modern time-sharing system.",
        "A system therefore consists of a collection of processes: operating- system processes executing system code and user processes executing user code.",
        "3.1 Process Concept: A question that arises in discussing operating systems involves what to call all...",
        "3.1.1 The Process: Informally, as mentioned earlier, a process is a program in execution....",
        "3.1.2 Process State: As a process executes, it changes state....",
        "3.1.3 Process Control Block: Each process is represented in the operating system by a process control block (...",
        "3.1.4 Threads: The process model discussed so far has implied that a process is a program that ..."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_1",
      "title": "4.1 Overview",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 1,
      "definition": "A thread is a basic unit of CPU utilization; it comprises a thread ID, a program counter, a register set, and a stack.",
      "key_points": [
        "It shares with other threads belonging to the same process its code section, data section, and other operating-system resources, such as open \ufb01les and signals.",
        "A traditional (or heavyweight) process has a single thread of control.",
        "If a process has multiple threads of control, it can perform more than one task at a time.",
        "Figure 4.1 illustrates the difference between a traditional single-threaded process and a multithreaded process."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_1_1",
      "title": "4.1.1 Motivation",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 1,
      "definition": "Most software applications that run on modern computers are multithreaded.",
      "key_points": [
        "An application typically is implemented as a separate process with several"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_1_2",
      "title": "4.1.2 Bene\ufb01ts",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 3,
      "definition": "The bene\ufb01ts of multithreaded programming can be broken down into four major categories: 1.",
      "key_points": [
        "Processes can only share resources through techniques such as shared memory and message passing.",
        "However, threads share the memory and the resources of the process to which they belong by default.",
        "Allocating memory and resources for process creation is costly.",
        "Because threads share the resources of the process to which they belong, it is more economical to create and context-switch threads.",
        "Empirically gauging the difference in overhead can be dif\ufb01cult, but in general it is signi\ufb01cantly more time consuming to create and manage processes than threads."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_2",
      "title": "4.2 Multicore Programming",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 4,
      "definition": "Earlier in the history of computer design, in response to the need for more computing performance, single-CPU systems evolved into multi-CPU systems.",
      "key_points": [
        "Each core appears as a separate processor to the operating system (Section 1.3.2).",
        "Whether the cores appear across CPU chips or within CPU chips, we call these systems multicore or multiprocessor systems.",
        "On a system with a single computing core, concurrency merely means that the execution of the threads will be interleaved over time (Figure 4.3), because the processing core is capable of executing only one thread at a time.",
        "Before the advent of SMP and multicore architectures, most com- puter systems had only a single processor.",
        "CPU schedulers were designed to provide the illusion of parallelism by rapidly switching between processes in T1 T3 T1 T3 T1 core 1 T2 T4 T2 T4 T2 core 2 time \u2026 \u2026 Figure 4.4 Parallel execution on a multicore system."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_2_1",
      "title": "4.2.1 Programming Challenges",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 5,
      "definition": "The trend towards multicore systems continues to place pressure on system designers and application programmers to make better use of the multiple computing cores.",
      "key_points": [
        "Designers of operating systems must write scheduling algorithms that use multiple processing cores to allow the parallel execution shown in Figure 4.4. For application programmers, the challenge is to modify existing programs as well as design new programs that are multithreaded.",
        "In general, \ufb01ve areas present challenges in programming for multicore systems:"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_2_2",
      "title": "4.2.2 Types of Parallelism",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 6,
      "definition": "In general, there are two types of parallelism: data parallelism and task parallelism.",
      "key_points": [
        "Data parallelism focuses on distributing subsets of the same data across multiple computing cores and performing the same operation on each core.",
        "Consider, for example, summing the contents of an array of size N.",
        "On a single-core system, one thread would simply sum the elements [0] .",
        "On a dual-core system, however, thread A, running on core 0, could sum the elements [0] .",
        "[N/2 \u22121] while thread B, running on core 1, could sum the elements [N/2] ."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_3",
      "title": "4.3 Multithreading Models",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 7,
      "definition": "Our discussion so far has treated threads in a generic sense.",
      "key_points": [
        "However, support for threads may be provided either at the user level, for user threads, or by the kernel, for kernel threads.",
        "User threads are supported above the kernel and are managed without kernel support, whereas kernel threads are supported and managed directly by the operating system.",
        "Virtually all contemporary operating systems\u2014including Windows, Linux, Mac OS X, and Solaris\u2014 support kernel threads.",
        "Ultimately, a relationship must exist between user threads and kernel threads.",
        "In this section, we look at three common ways of establishing such a relationship: the many-to-one model, the one-to-one model, and the many-to- many model."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_3_1",
      "title": "4.3.1 Many-to-One Model",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 7,
      "definition": "The many-to-one model (Figure 4.5) maps many user-level threads to one kernel thread.",
      "key_points": [
        "However, the entire process will block if a thread makes a blocking system call.",
        "However, very few systems continue to use the model because of its inability to take advantage of multiple processing cores.",
        "Thread management is done by the thread library in user space, so it is ef\ufb01cient (we discuss thread libraries in Section 4.4).",
        "Also, because only one thread can access the kernel at a time, multiple threads are unable to run in parallel on multicore systems.",
        "Green threads\u2014a thread library available for Solaris systems and adopted in early versions of Java\u2014used the many-to-one model."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_3_2",
      "title": "4.3.2 One-to-One Model",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 8,
      "definition": "The one-to-one model (Figure 4.6) maps each user thread to a kernel thread.",
      "key_points": [
        "It also allows multiple threads to run in parallel on multiprocessors.",
        "It provides more concurrency than the many-to-one model by allowing another thread to run when a thread makes a blocking system call.",
        "The only drawback to this model is that creating a user thread requires creating the corresponding kernel thread.",
        "Because the overhead of creating kernel threads can burden the performance of an application, most implementations of this model restrict the number of threads supported by the system.",
        "Linux, along with the family of Windows operating systems, implement the one-to-one model."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_3_3",
      "title": "4.3.3 Many-to-Many Model",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 8,
      "definition": "The many-to-many model (Figure 4.7) multiplexes many user-level threads to a smaller or equal number of kernel threads.",
      "key_points": [
        "The number of kernel threads may be speci\ufb01c to either a particular application or a particular machine (an application may be allocated more kernel threads on a multiprocessor than on a single processor).",
        "Let\u2019s consider the effect of this design on concurrency.",
        "Whereas the many- to-one model allows the developer to create as many user threads as she wishes, it does not result in true concurrency, because the kernel can schedule only one thread at a time.",
        "The one-to-one model allows greater concurrency, but the developer has to be careful not to create too many threads within an application (and in some instances may be limited in the number of threads she can user thread kernel thread k k k Figure 4.7 Many-to-many model."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_4",
      "title": "4.4 Thread Libraries",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 9,
      "definition": "This means that invoking a function in the library results in a local function call in user space and not a system call.",
      "key_points": [
        "There are two primary ways of implementing a thread library.",
        "The \ufb01rst approach is to provide a library entirely in user space with no kernel support.",
        "All code and data structures for the library exist in user space.",
        "The second approach is to implement a kernel-level library supported directly by the operating system.",
        "In this case, code and data structures for the library exist in kernel space."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_4_1",
      "title": "4.4.1 Pthreads",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 10,
      "definition": "Pthreads refers to the POSIX standard (IEEE 1003.1c) de\ufb01ning an API for thread creation and synchronization.",
      "key_points": [
        "This is a speci\ufb01cation for thread behavior, not an implementation.",
        "Operating-system designers may implement the speci\ufb01cation in any way they wish.",
        "Numerous systems implement the Pthreads speci\ufb01cation; most are UNIX-type systems, including Linux, Mac OS X, and Solaris.",
        "Although Windows doesn\u2019t support Pthreads natively, some third- party implementations for Windows are available.",
        "The C program shown in Figure 4.9 demonstrates the basic Pthreads API for constructing a multithreaded program that calculates the summation of a non- negative integer in a separate thread."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_4_2",
      "title": "4.4.2 Windows Threads",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 12,
      "definition": "The technique for creating threads using the Windows thread library is similar to the Pthreads technique in several ways.",
      "key_points": [
        "We illustrate the Windows thread API in the C program shown in Figure 4.11.",
        "Notice that we must include the windows.h header \ufb01le when using the Windows API.",
        "Just as in the Pthreads version shown in Figure 4.9, data shared by the separate threads\u2014in this case, Sum\u2014are declared globally (the DWORD data type is an unsigned 32-bit integer).",
        "We also de\ufb01ne the Summation() function that is to be performed in a separate thread.",
        "This function is passed a pointer to a void, which Windows de\ufb01nes as LPVOID."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_4_3",
      "title": "4.4.3 Java Threads",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 14,
      "definition": "Threads are the fundamental model of program execution in a Java program, and the Java language and its API provide a rich set of features for the creation and management of threads.",
      "key_points": [
        "All Java programs comprise at least a single thread of control\u2014even a simple Java program consisting of only a main() method runs as a single thread in the JVM.",
        "Java threads are available on any system that provides a JVM including Windows, Linux, and Mac OS X.",
        "The Java thread API is available for Android applications as well.",
        "There are two techniques for creating threads in a Java program.",
        "One approach is to create a new class that is derived from the Thread class and to override its run() method."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_5",
      "title": "4.5 Implicit Threading",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 15,
      "definition": "With the continued growth of multicore processing, applications containing hundreds\u2014or even thousands\u2014of threads are looming on the horizon.",
      "key_points": [
        "Designing such applications is not a trivial undertaking: programmers must addressnotonlythe challengesoutlined inSection4.2but additional dif\ufb01culties as well.",
        "These dif\ufb01culties, which relate to program correctness, are covered in Chapters 5 and 7.",
        "One way to address these dif\ufb01culties and better support the design of multithreaded applications is to transfer the creation and management of"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_5_1",
      "title": "4.5.1 Thread Pools",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 17,
      "definition": "In Section 4.1, we described a multithreaded web server.",
      "key_points": [
        "Whereas creating a separate thread is certainly superior to creating a separate process, a multithreaded server nonetheless has potential problems.",
        "The general idea behind a thread pool is to create a number of threads at process startup and place them into a pool, where they sit and wait for work.",
        "In this situation, whenever the server receives a request, it creates a separate thread to service the request.",
        "The \ufb01rst issue concerns the amount of time required to create the thread, together with the fact that the thread will be discarded once it has completed its work.",
        "The second issue is more troublesome."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_5_2",
      "title": "4.5.2 OpenMP",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 19,
      "definition": "OpenMP is a set of compiler directives as well as an API for programs written in C, C++, or FORTRAN that provides support for parallel programming in shared-memory environments.",
      "key_points": [
        "The following C program illustrates a compiler directive above the parallel region containing the printf() statement: #include <omp.h> #include <stdio.h> int main(int argc, char *argv[]) { /* sequential code */ #pragma omp parallel { printf(\"I am a parallel region.\"); } /* sequential code */ return 0; } When OpenMP encounters the directive #pragma omp parallel it creates as many threads are there are processing cores in the system.",
        "OpenMP identi\ufb01es parallel regions as blocks of code that may run in parallel.",
        "Application developers insert compiler directives into their code at parallel regions, and these directives instruct the OpenMP run-time library to execute the region in parallel.",
        "Thus, for a dual-core system, two threads are created, for a quad-core system, four are created; and so forth.",
        "All the threads then simultaneously execute the parallel region."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_5_3",
      "title": "4.5.3 Grand Central Dispatch",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 20,
      "definition": "Grand Central Dispatch (GCD)\u2014a technology for Apple\u2019s Mac OS X and iOS operating systems\u2014is a combination of extensions to the C language, an API, and a run-time library that allows application developers to identify sections of code to run in parallel.",
      "key_points": [
        "Each process has its own serial queue (known as its main queue).",
        "Developers can create additional serial queues that are local to particular processes.",
        "Like OpenMP, GCD manages most of the details of threading.",
        "GCD identi\ufb01es extensions to the C and C++ languages known as blocks.",
        "A block is simply a self-contained unit of work."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_5_4",
      "title": "4.5.4 Other Approaches",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 21,
      "definition": "Thread pools, OpenMP, and Grand Central Dispatch are just a few of many emerging technologies for managing multithreaded applications.",
      "key_points": [
        "Other com- mercial approaches include parallel and concurrent libraries, such as Intel\u2019s Threading Building Blocks (TBB) and several products from Microsoft.",
        "The Java language and API have seen signi\ufb01cant movement toward supporting concur- rent programming as well.",
        "A notable example is the java.util.concurrent package, which supports implicit thread creation and management."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_6",
      "title": "4.6 Threading Issues",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 21,
      "definition": "In this section, we discuss some of the issues to consider in designing multithreaded programs.",
      "key_points": []
    },
    {
      "id": "CHAP_03_SUB_4_6_1",
      "title": "4.6.1 The fork() and exec() System Calls",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 21,
      "definition": "In Chapter 3, we described how the fork() system call is used to create a separate, duplicate process.",
      "key_points": [
        "If one thread in a program calls fork(), does the new process duplicate all threads, or is the new process single-threaded?",
        "That is, if a thread invokes the exec() system call, the program speci\ufb01ed in the parameter to exec() will replace the entire process\u2014including all threads.",
        "If exec() is called immediately after forking, then duplicating all threads is unnecessary, as the program speci\ufb01ed in the parameters to exec() will replace the process.",
        "If, however, the separate process does not call exec() after forking, the separate process should duplicate all threads."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_6_2",
      "title": "4.6.2 Signal Handling",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 21,
      "definition": "A signal is used in UNIX systems to notify a process that a particular event has occurred.",
      "key_points": [
        "A signal may be received either synchronously or asynchronously,"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_6_3",
      "title": "4.6.3 Thread Cancellation",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 23,
      "definition": "Thread cancellation involves terminating a thread before it has completed.",
      "key_points": [
        "For example, if multiple threads are concurrently searching through a database and one thread returns the result, the remaining threads might be canceled.",
        "Another situation might occur when a user presses a button on a web browser that stops a web page from loading any further.",
        "Often, a web page loads using several threads\u2014each image is loaded in a separate thread.",
        "When a user presses the stop button on the browser, all threads loading the page are canceled.",
        "A thread that is to be canceled is often referred to as the target thread."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_6_4",
      "title": "4.6.4 Thread-Local Storage",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 25,
      "definition": "Threads belonging to a process share the data of the process.",
      "key_points": [
        "We will call such data thread-local storage (or TLS.) For example, in a transaction-processing system, we might service each transaction in a separate thread.",
        "Indeed, this data sharing provides one of the bene\ufb01ts of multithreaded programming.",
        "However, in some circumstances, each thread might need its own copy of certain data.",
        "Furthermore, each transaction might be assigned a unique identi\ufb01er.",
        "To associate each thread with its unique identi\ufb01er, we could use thread-local storage."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_6_5",
      "title": "4.6.5 Scheduler Activations",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 25,
      "definition": "A \ufb01nal issue to be considered with multithreaded programs concerns com- munication between the kernel and the thread library, which may be required by the many-to-many and two-level models discussed in Section 4.3.3. Such coordination allows the number of kernel threads to be dynamically adjusted to help ensure the best performance.",
      "key_points": [
        "This data structure\u2014typically known as a lightweight process, or LWP\u2014is shown in Figure 4.13.",
        "To the user-thread library, the LWP appears to be a virtual processor on which the application can schedule a user thread to run.",
        "Each LWP is attached to a kernel thread, and it is kernel threads that the LWP user thread kernel thread k lightweight process Figure 4.13 Lightweight process (LWP)."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_7",
      "title": "4.7 Operating-System Examples",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 26,
      "definition": "At this point, we have examined a number of concepts and issues related to threads.",
      "key_points": [
        "We conclude the chapter by exploring how threads are implemented in Windows and Linux systems."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_7_1",
      "title": "4.7.1 Windows Threads",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 26,
      "definition": "Windows implements the Windows API, which is the primary API for the family of Microsoft operating systems (Windows 98, NT, 2000, and XP, as well as Windows 7).",
      "key_points": [
        "A Windows application runs as a separate process, and each process may contain one or more threads.",
        "Indeed, much of what is mentioned in this section applies to this entire family of operating systems.",
        "The Windows API for creating threads is covered in"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_7_2",
      "title": "4.7.2 Linux Threads",
      "label": "Topic",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 27,
      "definition": "Linux provides the fork() system call with the traditional functionality of duplicating a process, as described in Chapter 3.",
      "key_points": [
        "However, Linux does not distinguish between processes and threads.",
        "In fact, Linux uses the term task \u2014rather than process or thread\u2014 when referring to a \ufb02ow of control within a program.",
        "Linux also provides the ability to create threads using the clone() system call.",
        "When clone() is invoked, it is passed a set of \ufb02ags that determine how much sharing is to take place between the parent and child tasks.",
        "Some of these \ufb02ags are listed in Figure 4.15."
      ]
    },
    {
      "id": "CHAP_03_SUB_4_8",
      "title": "4.8 Summary",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 29,
      "definition": "A thread is a \ufb02ow of control within a process. A multithreaded process contains several different \ufb02ows of control within the same address space. The bene\ufb01ts of multithreading include increased responsiveness to the user, resource sharing within the process, economy, and scalability factors, such as more ef\ufb01cient use of multiple processing cores. User-level threads are threads that are visible to the programmer and are unknown to the kernel. The operating-system kernel supports and manages kernel",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_1",
      "title": "4.1 Provide two programming examples in which multithreading provides",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 29,
      "definition": "better performance than a single-threaded solution.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_2",
      "title": "4.2 What are two differences between user-level threads and kernel-level",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 29,
      "definition": "threads? Under what circumstances is one type better than the other?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_3",
      "title": "4.3 Describe the actions taken by a kernel to context-switch between kernel-",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 29,
      "definition": "level threads.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_4",
      "title": "4.4 What resources are used when a thread is created? How do they differ",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 29,
      "definition": "from those used when a process is created?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_5",
      "title": "4.5 Assume that an operating system maps user-level threads to the kernel",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 30,
      "definition": "using the many-to-many model and that the mapping is done through LWPs. Furthermore, the system allows developers to create real-time threads for use in real-time systems. Is it necessary to bind a real-time thread to an LWP? Explain. Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_6",
      "title": "4.6 Provide two programming examples in which multithreading does not",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 30,
      "definition": "provide better performance than a single-threaded solution.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_7",
      "title": "4.7 Under what circumstances does a multithreaded solution using multi-",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 30,
      "definition": "ple kernel threads provide better performance than a single-threaded solution on a single-processor system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_8",
      "title": "4.8 Which of the following components of program state are shared across",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 30,
      "definition": "threads in a multithreaded process? a. Register values b. Heap memory c. Global variables d. Stack memory",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_9",
      "title": "4.9 Can a multithreaded solution using multiple user-level threads achieve",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 30,
      "definition": "better performance on a multiprocessor system than on a single- processor system? Explain.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_10",
      "title": "4.10 In Chapter 3, we discussed Google\u2019s Chrome browser and its practice",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 30,
      "definition": "of opening each new website in a separate process. Would the same bene\ufb01ts have been achieved if instead Chrome had been designed to open each new website in a separate thread? Explain.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_11",
      "title": "4.11 Is it possible to have concurrency but not parallelism? Explain.",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 30,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_12",
      "title": "4.12 Using Amdahl\u2019s Law, calculate the speedup gain of an application that",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 30,
      "definition": "has a 60 percent parallel component for (a) two processing cores and (b) four processing cores.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_13",
      "title": "4.13 Determine if the following problems exhibit task or data parallelism:",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 30,
      "definition": "\u2022 The multithreaded statistical program described in Exercise 4.21 \u2022 The multithreaded Sudoku validator described in Project 1 in this chapter \u2022 The multithreaded sorting program described in Project 2 in this chapter \u2022 The multithreaded web server described in Section 4.1",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_14",
      "title": "4.14 A system with two dual-core processors has four processors available",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 30,
      "definition": "for scheduling. A CPU-intensive application is running on this system. All input is performed at program start-up, when a single \ufb01le must be opened. Similarly, all output is performed just before the program",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_15",
      "title": "4.15 Consider the following code segment:",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 31,
      "definition": "pid t pid; pid = fork(); if (pid == 0) { /* child process */ fork(); thread create( . . .); } fork(); a. How many unique processes are created? b. How many unique threads are created?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_16",
      "title": "4.16 As described in Section 4.7.2, Linux does not distinguish between",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 31,
      "definition": "processes and threads. Instead, Linux treats both in the same way, allowing a task to be more akin to a process or a thread depending on the set of \ufb02ags passed to the clone() system call. However, other operating systems, such as Windows, treat processes and threads differently. Typically, such systems use a notation in which the data structure for a process contains pointers to the separate threads belonging to the process. Contrast these two approaches for modeling processes and threads within",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_17",
      "title": "4.17 The program shown in Figure 4.16 uses the Pthreads API. What would",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 31,
      "definition": "be the output from the program at LINE C and LINE P?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_18",
      "title": "4.18 Consider a multicore system and a multithreaded program written",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 31,
      "definition": "using the many-to-many threading model. Let the number of user-level threads in the program be greater than the number of processing cores in the system. Discuss the performance implications of the following scenarios. a. The number of kernel threads allocated to the program is less than the number of processing cores. b. The number of kernel threads allocated to the program is equal to the number of processing cores. c. The number of kernel threads allocated to the program is greater than the n",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_19",
      "title": "4.19 Pthreads provides an API for managing thread cancellation. The",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 32,
      "definition": "pthread setcancelstate() function is used to set the cancellation state. Its prototype appears as follows: pthread setcancelstate(int state, int *oldstate) The two possible values for the state are PTHREAD CANCEL ENABLE and PTHREAD CANCEL DISABLE. Using the code segment shown in Figure 4.17, provide examples of two operations that would be suitable to perform between the calls to disable and enable thread cancellation.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_20",
      "title": "4.20 Modify programming problem Exercise 3.20 from Chapter 3, which asks",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 33,
      "definition": "you to design a pid manager. This modi\ufb01cation will consist of writing a multithreaded program that tests your solution to Exercise 3.20. You will create a number of threads\u2014for example, 100\u2014and each thread will request a pid, sleep for a random period of time, and then release the pid. (Sleeping for a random period of time approximates the typical pid usage in which a pid is assigned to a new process, the process executes and then terminates, and the pid is released on the process\u2019s termination.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_21",
      "title": "4.21 Write a multithreaded program that calculates various statistical values",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 33,
      "definition": "for a list of numbers. This program will be passed a series of numbers on the command line and will then create three separate worker threads. One thread will determine the average of the numbers, the second will determine the maximum value, and the third will determine the minimum value. For example, suppose your program is passed the integers 81 78 95 79 72 85 The program will report The average value is 82 The minimum value is 72 The maximum value is 95 The variables representing the average,",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_22",
      "title": "4.22 An interesting way of calculating ! is to use a technique known as Monte",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 33,
      "definition": "Carlo, which involves randomization. This technique works as follows: Suppose you have a circle inscribed within a square, as shown in Figure",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_23",
      "title": "4.23 Repeat Exercise 4.22, but instead of using a separate thread to generate",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 34,
      "definition": "random points, use OpenMP to parallelize the generation of points. Be careful not to place the calculcation of ! in the parallel region, since you want to calculcate ! only once.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_24",
      "title": "4.24 Write a multithreaded program that outputs prime numbers. This",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 34,
      "definition": "program should work as follows: The user will run the program and will enter a number on the command line. The program will then create a separate thread that outputs all the prime numbers less than or equal to the number entered by the user.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_25",
      "title": "4.25 Modify the socket-based date server (Figure 3.21) in Chapter 3 so that",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 34,
      "definition": "the server services each client request in a separate thread.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_26",
      "title": "4.26 The Fibonacci sequence is the series of numbers 0, 1, 1, 2, 3, 5, 8, ....",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 35,
      "definition": "Formally, it can be expressed as: f ib0 = 0 f ib1 = 1 f ibn = f ibn\u22121 + f ibn\u22122 Write a multithreaded program that generates the Fibonacci sequence. This program should work as follows: On the command line, the user will enter the number of Fibonacci numbers that the program is to generate. The program will then create a separate thread that will generate the Fibonacci numbers, placing the sequence in data that can be shared by the threads (an array is probably the most convenient data structure",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03_SUB_4_27",
      "title": "4.27 Exercise 3.25 in Chapter 3 involves designing an echo server using the",
      "label": "Exercise",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 35,
      "definition": "Java threading API. This server is single-threaded, meaning that the server cannot respond to concurrent echo clients until the current client exits. Modify the solution to Exercise 3.25 so that the echo server services each client in a separate request. Programming Projects Project 1\u2014Sudoku Solution Validator A Sudoku puzzle uses a 9 \u00d7 9 grid in which each column and row, as well as each of the nine 3 \u00d7 3 subgrids, must contain all of the digits 1 \u00b7 \u00b7 \u00b7 9. Figure 4.19 presents an example of a v",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_03",
      "title": "Chapter 4 Threads",
      "label": "Chapter",
      "file_source": "04_Chapter 4 Threads.pdf",
      "page": 1,
      "definition": "4 C H A P T E R Threads The process model introduced in Chapter 3 assumed that a process was an executing program with a single thread of control.",
      "key_points": [
        "Virtually all modern operating systems, however, provide features enabling a process to contain multiple threads of control.",
        "4.1 Overview A thread is a basic unit of CPU utilization; it comprises a thread ID, a program counter, a register set, and a stack.",
        "It shares with other threads belonging to the same process its code section, data section, and other operating-system resources, such as open \ufb01les and signals.",
        "4.1 Overview: A thread is a basic unit of CPU utilization; it comprises a thread ID, a program...",
        "4.1.1 Motivation: Most software applications that run on modern computers are multithreaded....",
        "4.1.2 Bene\ufb01ts: The bene\ufb01ts of multithreaded programming can be broken down into four major cate...",
        "4.2 Multicore Programming: Earlier in the history of computer design, in response to the need for more comp...",
        "4.2.1 Programming Challenges: The trend towards multicore systems continues to place pressure on system design..."
      ]
    },
    {
      "id": "CHAP_04_SUB_5_1",
      "title": "5.1 Background",
      "label": "Topic",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 1,
      "definition": "This means that one process may only partially complete execution before another process is scheduled.",
      "key_points": [
        "We\u2019ve already seen that processes can execute concurrently or in parallel.",
        "Section 3.2.2 introduced the role of process scheduling and described how the CPU scheduler switches rapidly between processes to provide concurrent execution.",
        "In fact, a process may be interrupted at any point in its instruction stream, and the processing core may be assigned to execute instructions of another process.",
        "Additionally, Section 4.2 introduced parallel execution, in which two instruction streams (representing different processes) execute simultaneously on separate processing cores."
      ]
    },
    {
      "id": "CHAP_04_SUB_5_2",
      "title": "5.2 The Critical-Section Problem",
      "label": "Topic",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 4,
      "definition": "We begin our consideration of process synchronization by discussing the so- called critical-section problem.",
      "key_points": [
        "Consider a system consisting of n processes {P0, P1, ..., Pn\u22121}.",
        "Each process has a segment of code, called a critical section, in which the process may be changing common variables, updating a table, writing a \ufb01le, and so on.",
        "The important feature of the system is that, when one process is executing in its critical section, no other process is allowed to execute in its critical section.",
        "That is, no two processes are executing in their critical sections at the same time.",
        "The critical-section problem is to design a protocol that the processes can use to cooperate."
      ]
    },
    {
      "id": "CHAP_04_SUB_5_3",
      "title": "5.3 Peterson\u2019s Solution",
      "label": "Topic",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 5,
      "definition": "Next, we illustrate a classic software-based solution to the critical-section problem known as Peterson\u2019s solution.",
      "key_points": [
        "Because of the way modern computer architectures perform basic machine-language instructions, such as load and store, there are no guarantees that Peterson\u2019s solution will work correctly on such architectures.",
        "However, we present the solution because it provides a good algorithmic description of solving the critical-section problem and illustrates some of the complexities involved in designing software that addresses the requirements of mutual exclusion, progress, and bounded waiting."
      ]
    },
    {
      "id": "CHAP_04_SUB_5_4",
      "title": "5.4 Synchronization Hardware",
      "label": "Topic",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 7,
      "definition": "We have just described one software-based solution to the critical-section problem.",
      "key_points": [
        "Hardware features can make any programming task easier and improve system ef\ufb01ciency.",
        "The critical-section problem could be solved simply in a single-processor environment if we could prevent interrupts from occurring while a shared variable was being modi\ufb01ed.",
        "However, as mentioned, software-based solutions such as Peterson\u2019s are not guaranteed to work on modern computer architectures.",
        "In the following discussions, we explore several more solutions to the critical-section problem using techniques ranging from hardware to software-based APIs available to both kernel developers and application programmers.",
        "All these solutions are based on the premise of locking \u2014that is, protecting critical regions through the use of locks."
      ]
    },
    {
      "id": "CHAP_04_SUB_5_5",
      "title": "5.5 Mutex Locks",
      "label": "Topic",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 10,
      "definition": "The hardware-based solutions to the critical-section problem presented in Section 5.4 are complicated as well as generally inaccessible to application programmers.",
      "key_points": [
        "That is, a process must acquire the lock before entering a critical section; it releases the lock when it exits the critical section.",
        "A process that attempts to acquire an unavailable lock is blocked until the lock is released.",
        "Instead, operating-systems designers build software tools to solve the critical-section problem.",
        "The simplest of these tools is the mutex lock.",
        "(In fact, the term mutex is short for mutual exclusion.) We use the mutex lock to protect critical regions and thus prevent race conditions."
      ]
    },
    {
      "id": "CHAP_04_SUB_5_6",
      "title": "5.6 Semaphores",
      "label": "Topic",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 11,
      "definition": "Mutex locks, as we mentioned earlier, are generally considered the simplest of synchronization tools.",
      "key_points": [
        "In this section, we examine a more robust tool that can"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_6_1",
      "title": "5.6.1 Semaphore Usage",
      "label": "Topic",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 12,
      "definition": "Operating systems often distinguish between counting and binary semaphores.",
      "key_points": [
        "Each process that wishes to use a resource performs a wait() operation on the semaphore (thereby decrementing the count).",
        "When a process releases a resource, it performs a signal() operation (incrementing the count).",
        "After that, processes that wish to use a resource will block until the count becomes greater than 0.",
        "For example, consider two concurrently running processes: P1 with a statement S1 and P2 with a statement S2.",
        "In process P1, we insert the statements"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_6_2",
      "title": "5.6.2 Semaphore Implementation",
      "label": "Topic",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 13,
      "definition": "Recall that the implementation of mutex locks discussed in Section 5.5 suffers from busy waiting.",
      "key_points": [
        "To overcome the need for busy waiting, we can modify the de\ufb01nition of the wait() and signal() operations as follows: When a process executes the wait() operation and \ufb01nds that the semaphore value is not positive, it must wait.",
        "However, rather than engaging in busy waiting, the process can block itself.",
        "The block operation places a process into a waiting queue associated with the semaphore, and the state of the process is switched to the waiting state.",
        "Then control is transferred to the CPU scheduler, which selects another process to execute.",
        "A process that is blocked, waiting on a semaphore S, should be restarted when some other process executes a signal() operation."
      ]
    },
    {
      "id": "CHAP_04_SUB_5_6_3",
      "title": "5.6.3 Deadlocks and Starvation",
      "label": "Topic",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 15,
      "definition": "The implementation of a semaphore with a waiting queue may result in a situation where two or more processes are waiting inde\ufb01nitely for an event that can be caused only by one of the waiting processes.",
      "key_points": [
        "When such a state is reached, these processes are said to be deadlocked.",
        "To illustrate this, consider a system consisting of two processes, P0 and P1, each accessing two semaphores, S and Q, set to the value 1: P0 P1 wait(S); wait(Q); wait(Q); wait(S); .",
        "We say that a set of processes is in a deadlocked state when every process in the set is waiting for an event that can be caused only by another process in the set.",
        "Another problem related to deadlocks is inde\ufb01nite blocking or starvation, a situation in which processes wait inde\ufb01nitely within the semaphore.",
        "Inde\ufb01- nite blocking may occur if we remove processes from the list associated with a semaphore in LIFO (last-in, \ufb01rst-out) order."
      ]
    },
    {
      "id": "CHAP_04_SUB_5_6_4",
      "title": "5.6.4 Priority Inversion",
      "label": "Topic",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 15,
      "definition": "A scheduling challenge arises when a higher-priority process needs to read or modify kernel data that are currently being accessed by a lower-priority process\u2014or a chain of lower-priority processes.",
      "key_points": [
        "Since kernel data are typically protected with a lock, the higher-priority process will have to wait for a lower-priority one to \ufb01nish with the resource.",
        "The situation becomes more complicated if the lower-priority process is preempted in favor of another process with a higher priority.",
        "As an example, assume we have three processes\u2014L, M, and H \u2014whose priorities follow the order L < M < H.",
        "Assume that process H requires"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_7",
      "title": "5.7 Classic Problems of Synchronization",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 17,
      "definition": "In this section, we present a number of synchronization problems as examples of a large class of concurrency-control problems. These problems are used for testing nearly every newly proposed synchronization scheme. In our solutions to the problems, we use semaphores for synchronization, since that is the traditional way to present such solutions. However, actual implementations of these solutions could use mutex locks in place of binary semaphores.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_7_1",
      "title": "5.7.1 The Bounded-Buffer Problem",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 17,
      "definition": "The bounded-buffer problem was introduced in Section 5.1; it is commonly used to illustrate the power of synchronization primitives. Here, we present a general structure of this scheme without committing ourselves to any particular implementation. We provide a related programming project in the exercises at the end of the chapter. In our problem, the producer and consumer processes share the following data structures: int n; semaphore mutex = 1; semaphore empty = n; semaphore full = 0 We assume ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_7_2",
      "title": "5.7.2 The Readers\u2013Writers Problem",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 18,
      "definition": "Suppose that a database is to be shared among several concurrent processes. Some of these processes may want only to read the database, whereas others may want to update (that is, to read and write) the database. We distinguish between these two types of processes by referring to the former as readers and to the latter as writers. Obviously, if two readers access the shared data simultaneously, no adverse effects will result. However, if a writer and some other process (either a reader or a writ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_7_3",
      "title": "5.7.3 The Dining-Philosophers Problem",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 20,
      "definition": "Consider \ufb01ve philosophers who spend their lives thinking and eating. The philosophers share a circular table surrounded by \ufb01ve chairs, each belonging to one philosopher. In the center of the table is a bowl of rice, and the table is laid with \ufb01ve single chopsticks (Figure 5.13). When a philosopher thinks, she does not interact with her colleagues. From time to time, a philosopher gets hungry and tries to pick up the two chopsticks that are closest to her (the chopsticks that are between her and ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_8",
      "title": "5.8 Monitors",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 21,
      "definition": "Although semaphores provide a convenient and effective mechanism for process synchronization, using them incorrectly can result in timing errors that are dif\ufb01cult to detect, since these errors happen only if particular execution sequences take place and these sequences do not always occur. We have seen an example of such errors in the use of counters in our solution to the producer\u2013consumer problem (Section 5.1). In that example, the timing problem happened only rarely, and even then the counter",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_8_1",
      "title": "5.8.1 Monitor Usage",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 23,
      "definition": "An abstract data type\u2014or ADT\u2014encapsulates data with a set of functions to operate on that data that are independent of any speci\ufb01c implementation of the ADT. A monitor type is an ADT that includes a set of programmer- de\ufb01ned operations that are provided with mutual exclusion within the monitor. The monitor type also declares the variables whose values de\ufb01ne the state of an instance of that type, along with the bodies of functions that operate on those variables. The syntax of a monitor type is s",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_8_2",
      "title": "5.8.2 Dining-Philosophers Solution Using Monitors",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 25,
      "definition": "Next, we illustrate monitor concepts by presenting a deadlock-free solution to the dining-philosophers problem. This solution imposes the restriction that a philosopher may pick up her chopsticks only if both of them are available. To code this solution, we need to distinguish among three states in which we may \ufb01nd a philosopher. For this purpose, we introduce the following data structure: enum {THINKING, HUNGRY, EATING} state[5]; Philosopher i can set the variable state[i] = EATING only if her ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_8_3",
      "title": "5.8.3 Implementing a Monitor Using Semaphores",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 27,
      "definition": "We now consider a possible implementation of the monitor mechanism using semaphores. For each monitor, a semaphore mutex (initialized to 1) is provided. A process must execute wait(mutex) before entering the monitor and must execute signal(mutex) after leaving the monitor. Since a signaling process must wait until the resumed process either leaves or waits, an additional semaphore, next, is introduced, initialized to 0. The signaling processes can use next to suspend themselves. An integer varia",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_8_4",
      "title": "5.8.4 Resuming Processes within a Monitor",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 28,
      "definition": "We turn now to the subject of process-resumption order within a monitor. If several processes are suspended on condition x, and an x.signal() operation is executed by some process, then how do we determine which of the suspended processes should be resumed next? One simple solution is to use a \ufb01rst-come, \ufb01rst-served (FCFS) ordering, so that the process that has been waiting the longest is resumed \ufb01rst. In many circumstances, however, such a simple scheduling scheme is not adequate. For this purp",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_9",
      "title": "5.9 Synchronization Examples",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 30,
      "definition": "We next describe the synchronization mechanisms provided by the Windows, Linux, and Solaris operating systems, as well as the Pthreads API. We have chosen these three operating systems because they provide good examples of different approaches to synchronizing the kernel, and we have included the",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_9_1",
      "title": "5.9.1 Synchronization in Windows",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 31,
      "definition": "The Windows operating system is a multithreaded kernel that provides support for real-time applications and multiple processors. When the Windows kernel accesses a global resource on a single-processor system, it temporarily masks interrupts for all interrupt handlers that may also access the global resource. On a multiprocessor system, Windows protects access to global resources using spinlocks, although the kernel uses spinlocks only to protect short code segments. Furthermore, for reasons of ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_9_2",
      "title": "5.9.2 Synchronization in Linux",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 32,
      "definition": "Prior to Version 2.6, Linux was a nonpreemptive kernel, meaning that a process running in kernel mode could not be preempted\u2014even if a higher-priority process became available to run. Now, however, the Linux kernel is fully preemptive, so a task can be preempted when it is running in the kernel. Linux provides several different mechanisms for synchronization in the kernel. As most computer architectures provide instructions for atomic ver- sions of simple math operations, the simplest synchroniz",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_9_3",
      "title": "5.9.3 Synchronization in Solaris",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 33,
      "definition": "To control access to critical sections, Solaris provides adaptive mutex locks, condition variables, semaphores, reader\u2013writer locks, and turnstiles. Solaris implements semaphores and condition variables essentially as they are pre- sented in Sections 5.6 and 5.7 In this section, we describe adaptive mutex locks, reader\u2013writer locks, and turnstiles. An adaptive mutex protects access to every critical data item. On a multiprocessor system, an adaptive mutex starts as a standard semaphore implement",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_9_4",
      "title": "5.9.4 Pthreads Synchronization",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 35,
      "definition": "Although the locking mechanisms used in Solaris are available to user-level threads as well as kernel threads, basically the synchronization methods discussed thus far pertain to synchronization within the kernel. In contrast, the Pthreads API is available for programmers at the user level and is not part of any particular kernel. This API provides mutex locks, condition variables, and read\u2013write locks for thread synchronization. Mutex locks represent the fundamental synchronization technique us",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_10",
      "title": "5.10 Alternative Approaches",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 36,
      "definition": "With the emergence of multicore systems has come increased pressure to develop multithreaded applications that take advantage of multiple processing",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_10_1",
      "title": "5.10.1 Transactional Memory",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 37,
      "definition": "Quite often in computer science, ideas from one area of study can be used to solve problems in other areas. The concept of transactional memory originated in database theory, for example, yet it provides a strategy for process synchronization. A memory transaction is a sequence of memory read\u2013write operations that are atomic. If all operations in a transaction are completed, the memory transaction is committed. Otherwise, the operations must be aborted and rolled back. The bene\ufb01ts of transaction",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_10_2",
      "title": "5.10.2 OpenMP",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 38,
      "definition": "In Section 4.5.2, we provided an overview of OpenMP and its support of parallel programming in a shared-memory environment. Recall that OpenMP includes a set of compiler directives and an API. Any code following the compiler directive #pragma omp parallel is identi\ufb01ed as a parallel region and is performed by a number of threads equal to the number of processing cores in the system. The advantage of OpenMP (and similar tools) is that thread creation and management are handled by the OpenMP librar",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_10_3",
      "title": "5.10.3 Functional Programming Languages",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 39,
      "definition": "Most well-known programming languages\u2014such as C, C++, Java, and C#\u2014 are known as imperative (or procedural) languages. Imperative languages are used for implementing algorithms that are state-based. In these languages, the \ufb02ow of the algorithm is crucial to its correct operation, and state is represented with variables and other data structures. Of course, program state is mutable, as variables may be assigned different values over time. With the current emphasis on concurrent and parallel progr",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_11",
      "title": "5.11 Summary",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 40,
      "definition": "Given a collection of cooperating sequential processes that share data, mutual exclusion must be provided to ensure that a critical section of code is used by only one process or thread at a time. Typically, computer hardware provides several operations that ensure mutual exclusion. However, such hardware- based solutions are too complicated for most developers to use. Mutex locks and semaphores overcome this obstacle. Both tools can be used to solve various synchronization problems and can be i",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_1",
      "title": "5.1 In Section 5.4, we mentioned that disabling interrupts frequently can",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 40,
      "definition": "affect the system\u2019s clock. Explain why this can occur and how such effects can be minimized.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_2",
      "title": "5.2 Explain why Windows, Linux, and Solaris implement multiple locking",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 40,
      "definition": "mechanisms. Describe the circumstances under which they use spin- locks, mutex locks, semaphores, adaptive mutex locks, and condition variables. In each case, explain why the mechanism is needed.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_3",
      "title": "5.3 What is the meaning of the term busy waiting? What other kinds of",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 41,
      "definition": "waiting are there in an operating system? Can busy waiting be avoided altogether? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_4",
      "title": "5.4 Explain why spinlocks are not appropriate for single-processor systems",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 41,
      "definition": "yet are often used in multiprocessor systems.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_5",
      "title": "5.5 Show that, if the wait() and signal() semaphore operations are not",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 41,
      "definition": "executed atomically, then mutual exclusion may be violated.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_6",
      "title": "5.6 Illustrate how a binary semaphore can be used to implement mutual",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 41,
      "definition": "exclusion among n processes. Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_7",
      "title": "5.7 Race conditions are possible in many computer systems. Consider a",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 41,
      "definition": "banking system that maintains an account balance with two functions: deposit(amount) and withdraw(amount). These two functions are passed the amount that is to be deposited or withdrawn from the bank account balance. Assume that a husband and wife share a bank account. Concurrently, the husband calls the withdraw() function and the wife calls deposit(). Describe how a race condition is possible and what might be done to prevent the race condition from occurring.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_8",
      "title": "5.8 The \ufb01rst known correct software solution to the critical-section problem",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 41,
      "definition": "for two processes was developed by Dekker. The two processes, P0 and P1, share the following variables: boolean flag[2]; /* initially false */ int turn; The structure of process Pi (i == 0 or 1) is shown in Figure 5.21. The other process is Pj (j == 1 or 0). Prove that the algorithm satis\ufb01es all three requirements for the critical-section problem.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_9",
      "title": "5.9 The \ufb01rst known correct software solution to the critical-section problem",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 41,
      "definition": "for n processes with a lower bound on waiting of n \u22121 turns was presented by Eisenberg and McGuire. The processes share the following variables: enum pstate {idle, want in, in cs}; pstate flag[n]; int turn; All the elements of flag are initially idle. The initial value of turn is immaterial (between 0 and n-1). The structure of process Pi is shown in Figure 5.22. Prove that the algorithm satis\ufb01es all three requirements for the critical-section problem.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_10",
      "title": "5.10 Explain why implementing synchronization primitives by disabling",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 41,
      "definition": "interrupts is not appropriate in a single-processor system if the syn- chronization primitives are to be used in user-level programs.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_11",
      "title": "5.11 Explain why interrupts are not appropriate for implementing synchro-",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 42,
      "definition": "nization primitives in multiprocessor systems.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_12",
      "title": "5.12 The Linux kernel has a policy that a process cannot hold a spinlock while",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 42,
      "definition": "attempting to acquire a semaphore. Explain why this policy is in place.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_13",
      "title": "5.13 Describe two kernel data structures in which race conditions are possible.",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 42,
      "definition": "Be sure to include a description of how a race condition can occur.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_14",
      "title": "5.14 Describe how the compare and swap() instruction can be used to pro-",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 42,
      "definition": "vide mutual exclusion that satis\ufb01es the bounded-waiting requirement.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_15",
      "title": "5.15 Consider how to implement a mutex lock using an atomic hardware",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 42,
      "definition": "instruction. Assume that the following structure de\ufb01ning the mutex lock is available: typedef struct { int available; } lock; (available == 0) indicates that the lock is available, and a value of 1 indicates that the lock is unavailable. Using this struct, illustrate how the following functions can be implemented using the test and set() and compare and swap() instructions: \u2022 void acquire(lock *mutex) \u2022 void release(lock *mutex) Be sure to include any initialization that may be necessary.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_16",
      "title": "5.16 The implementation of mutex locks provided in Section 5.5 suffers from",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 43,
      "definition": "busy waiting. Describe what changes would be necessary so that a process waiting to acquire a mutex lock would be blocked and placed into a waiting queue until the lock became available.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_17",
      "title": "5.17 Assume that a system has multiple processing cores. For each of the",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 43,
      "definition": "following scenarios, describe which is a better locking mechanism\u2014a spinlock or a mutex lock where waiting processes sleep while waiting for the lock to become available: \u2022 The lock is to be held for a short duration. \u2022 The lock is to be held for a long duration. \u2022 A thread may be put to sleep while holding the lock.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_18",
      "title": "5.18 Assume that a context switch takes T time. Suggest an upper bound",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 44,
      "definition": "(in terms of T) for holding a spinlock. If the spinlock is held for any longer, a mutex lock (where waiting threads are put to sleep) is a better alternative.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_19",
      "title": "5.19 A multithreaded web server wishes to keep track of the number",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 44,
      "definition": "of requests it services (known as hits). Consider the two following strategies to prevent a race condition on the variable hits. The \ufb01rst strategy is to use a basic mutex lock when updating hits: int hits; mutex lock hit lock; hit lock.acquire(); hits++; hit lock.release(); A second strategy is to use an atomic integer: atomic t hits; atomic inc(&hits); Explain which of these two strategies is more ef\ufb01cient.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_20",
      "title": "5.20 Consider the code example for allocating and releasing processes shown",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 44,
      "definition": "in Figure 5.23.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_21",
      "title": "5.21 Servers can be designed to limit the number of open connections. For",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 45,
      "definition": "example, a server may wish to have only N socket connections at any point in time. As soon as N connections are made, the server will not accept another incoming connection until an existing connection is released. Explain how semaphores can be used by a server to limit the number of concurrent connections.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_22",
      "title": "5.22 Windows Vista provides a lightweight synchronization tool called slim",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 45,
      "definition": "reader\u2013writer locks. Whereas most implementations of reader\u2013writer locks favor either readers or writers, or perhaps order waiting threads using a FIFO policy, slim reader\u2013writer locks favor neither readers nor writers, nor are waiting threads ordered in a FIFO queue. Explain the bene\ufb01ts of providing such a synchronization tool.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_23",
      "title": "5.23 Show how to implement the wait() and signal() semaphore oper-",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 45,
      "definition": "ations in multiprocessor environments using the test and set() instruction. The solution should exhibit minimal busy waiting.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_24",
      "title": "5.24 Exercise 4.26 requires the parent thread to wait for the child thread to",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 45,
      "definition": "\ufb01nish its execution before printing out the computed values. If we let the parent thread access the Fibonacci numbers as soon as they have been computed by the child thread\u2014rather than waiting for the child thread to terminate\u2014what changes would be necessary to the solution for this exercise? Implement your modi\ufb01ed solution.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_25",
      "title": "5.25 Demonstrate that monitors and semaphores are equivalent insofar",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 45,
      "definition": "as they can be used to implement solutions to the same types of synchronization problems.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_26",
      "title": "5.26 Design an algorithm for a bounded-buffer monitor in which the buffers",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 45,
      "definition": "(portions) are embedded within the monitor itself.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_27",
      "title": "5.27 The strict mutual exclusion within a monitor makes the bounded-buffer",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 45,
      "definition": "monitor of Exercise 5.26 mainly suitable for small portions. a. Explain why this is true. b. Design a new scheme that is suitable for larger portions.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_28",
      "title": "5.28 Discuss the tradeoff between fairness and throughput of operations",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 45,
      "definition": "in the readers\u2013writers problem. Propose a method for solving the readers\u2013writers problem without causing starvation.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_29",
      "title": "5.29 How does the signal() operation associated with monitors differ from",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 46,
      "definition": "the corresponding operation de\ufb01ned for semaphores?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_30",
      "title": "5.30 Suppose the signal() statement can appear only as the last statement",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 46,
      "definition": "in a monitor function. Suggest how the implementation described in Section 5.8 can be simpli\ufb01ed in this situation.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_31",
      "title": "5.31 Consider a system consisting of processes P1, P2, ..., Pn, each of which has",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 46,
      "definition": "a unique priority number. Write a monitor that allocates three identical printers to these processes, using the priority numbers for deciding the order of allocation.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_32",
      "title": "5.32 A \ufb01le is to be shared among different processes, each of which has",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 46,
      "definition": "a unique number. The \ufb01le can be accessed simultaneously by several processes, subject to the following constraint: the sum of all unique numbers associated with all the processes currently accessing the \ufb01le must be less than n. Write a monitor to coordinate access to the \ufb01le.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_33",
      "title": "5.33 When a signal is performed on a condition inside a monitor, the signaling",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 46,
      "definition": "process can either continue its execution or transfer control to the process that is signaled. How would the solution to the preceding exercise differ with these two different ways in which signaling can be performed?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_34",
      "title": "5.34 Suppose we replace the wait() and signal() operations of moni-",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 46,
      "definition": "tors with a single construct await(B), where B is a general Boolean expression that causes the process executing it to wait until B becomes true. a. Write a monitor using this scheme to implement the readers\u2013 writers problem. b. Explain why, in general, this construct cannot be implemented ef\ufb01ciently. c. What restrictions need to be put on the await statement so that it can be implemented ef\ufb01ciently? (Hint: Restrict the generality of B; see [Kessels (1977)].)",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_35",
      "title": "5.35 Design an algorithm for a monitor that implements an alarm clock that",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 46,
      "definition": "enables a calling program to delay itself for a speci\ufb01ed number of time units (ticks). You may assume the existence of a real hardware clock that invokes a function tick() in your monitor at regular intervals. Programming Problems",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_36",
      "title": "5.36 Programming Exercise 3.20 required you to design a PID manager that",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 46,
      "definition": "allocated a unique process identi\ufb01er to each process. Exercise 4.20 required you to modify your solution to Exercise 3.20 by writing a program that created a number of threads that requested and released process identi\ufb01ers. Now modify your solution to Exercise 4.20 by ensuring that the data structure used to represent the availability of process identi\ufb01ers is safe from race conditions. Use Pthreads mutex locks, described in Section 5.9.4.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_37",
      "title": "5.37 Assume that a \ufb01nite number of resources of a single resource type must",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 47,
      "definition": "be managed. Processes may ask for a number of these resources and will return them once \ufb01nished. As an example, many commercial software packages provide a given number of licenses, indicating the number of applications that may run concurrently. When the application is started, the license count is decremented. When the application is terminated, the license count is incremented. If all licenses are in use, requests to start the application are denied. Such requests will only be granted when an",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_38",
      "title": "5.38 The decrease count() function in the previous exercise currently",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 48,
      "definition": "returns 0 if suf\ufb01cient resources are available and \u22121 otherwise. This leads to awkward programming for a process that wishes to obtain a number of resources: while (decrease count(count) == -1) ; Rewrite the resource-manager code segment using a monitor and condition variables so that the decrease count() function suspends the process until suf\ufb01cient resources are available. This will allow a process to invoke decrease count() by simply calling decrease count(count); The process will return from",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_39",
      "title": "5.39 Exercise 4.22 asked you to design a multithreaded program that esti-",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 48,
      "definition": "mated ! using the Monte Carlo technique. In that exercise, you were asked to create a single thread that generated random points, storing the result in a global variable. Once that thread exited, the parent thread performed the calcuation that estimated the value of !. Modify that program so that you create several threads, each of which generates random points and determines if the points fall within the circle. Each thread will have to update the global count of all points that fall within the",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_40",
      "title": "5.40 Exercise 4.23 asked you to design a program using OpenMP that",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 48,
      "definition": "estimated ! using the Monte Carlo technique. Examine your solution to that program looking for any possible race conditions. If you identify a race condition, protect against it using the strategy outlined in Section 5.10.2.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04_SUB_5_41",
      "title": "5.41 A barrier is a tool for synchronizing the activity of a number of threads.",
      "label": "Exercise",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 48,
      "definition": "When a thread reaches a barrier point, it cannot proceed until all other threads have reached this point as well. When the last thread reaches the barrier point, all threads are released and can resume concurrent execution. Assume that the barrier is initialized to N\u2014the number of threads that must wait at the barrier point: init(N); Each thread then performs some work until it reaches the barrier point:",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_04",
      "title": "Chapter 5 Process Synchronization",
      "label": "Chapter",
      "file_source": "05_Chapter 5 Process Synchronization.pdf",
      "page": 1,
      "definition": "5 C H A P T E R Process Synchronization A cooperating process is one that can affect or be affected by other processes executing in the system.",
      "key_points": [
        "Cooperating processes can either directly share a logical address space (that is, both code and data) or be allowed to share data only through \ufb01les or messages.",
        "In this chapter, we discuss various mechanisms to ensure the orderly execution of cooperating processes that share a logical address space, so that data consistency is maintained.",
        "\u2022 To examine several classical process-synchronization problems.",
        "5.1 Background: This means that one process may only partially complete execution before another...",
        "5.2 The Critical-Section Problem: We begin our consideration of process synchronization by discussing the so- call...",
        "5.3 Peterson\u2019s Solution: Next, we illustrate a classic software-based solution to the critical-section pr...",
        "5.4 Synchronization Hardware: We have just described one software-based solution to the critical-section probl...",
        "5.5 Mutex Locks: The hardware-based solutions to the critical-section problem presented in Sectio..."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_1",
      "title": "6.1 Basic Concepts",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 1,
      "definition": "In a single-processor system, only one process can run at a time.",
      "key_points": [
        "The objective of multiprogramming is to have some process running at all times, to maximize CPU utilization.",
        "A process is executed until it must wait, typically for the completion of some I/O request.",
        "Several processes are kept in memory at one time."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_1_1",
      "title": "6.1.1 CPU\u2013I/O Burst Cycle",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 2,
      "definition": "The success of CPU scheduling depends on an observed property of processes: process execution consists of a cycle of CPU execution and I/O wait.",
      "key_points": [
        "Processes alternate between these two states.",
        "Process execution begins with a CPU burst.",
        "Although they vary greatly from process to process and from computer to computer, they tend to have a frequency curve similar to that shown in Figure 6.2. The curve is generally characterized as exponential or hyperexponential, with a large number of short CPU bursts and a small number of long CPU bursts."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_1_2",
      "title": "6.1.2 CPU Scheduler",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 3,
      "definition": "Whenever the CPU becomes idle, the operating system must select one of the processes in the ready queue to be executed.",
      "key_points": [
        "The selection process is carried out by the short-term scheduler, or CPU scheduler.",
        "The scheduler selects a process from the processes in memory that are ready to execute and allocates the CPU to that process.",
        "Note that the ready queue is not necessarily a \ufb01rst-in, \ufb01rst-out (FIFO) queue.",
        "Conceptually, however, all the processes in the ready queue are lined up waiting for a chance to run on the CPU.",
        "The records in the queues are generally process control blocks (PCBs) of the processes."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_1_3",
      "title": "6.1.3 Preemptive Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 3,
      "definition": "CPU-scheduling decisions may take place under the following four circum- stances: 1.",
      "key_points": [
        "When a process switches from the running state to the waiting state (for example, as the result of an I/O request or an invocation of wait() for the termination of a child process)"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_1_4",
      "title": "6.1.4 Dispatcher",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 5,
      "definition": "Another component involved in the CPU-scheduling function is the dispatcher.",
      "key_points": [
        "The dispatcher is the module that gives control of the CPUto the process selected by the short-term scheduler.",
        "This function involves the following: \u2022 Switching context \u2022 Switching to user mode \u2022 Jumping to the proper location in the user program to restart that program The dispatcher should be as fast as possible, since it is invoked during every process switch.",
        "The time it takes for the dispatcher to stop one process and start another running is known as the dispatch latency."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_2",
      "title": "6.2 Scheduling Criteria",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 5,
      "definition": "Different CPU-scheduling algorithms have different properties, and the choice of a particular algorithm may favor one class of processes over another.",
      "key_points": [
        "If the CPU is busy executing processes, then work is being done.",
        "One measure of work is the number of processes that are completed per time unit, called throughput.",
        "For long processes, this rate may be one process per hour; for short transactions, it may be ten processes per second.",
        "From the point of view of a particular process, the important criterion is how long it takes to execute that process.",
        "The interval from the time of submission of a process to the time of completion is the turnaround time."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_3",
      "title": "6.3 Scheduling Algorithms",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 6,
      "definition": "CPU schedulingdealswiththe problemofdecidingwhichofthe processesinthe readyqueue istobe allocated the CPU.",
      "key_points": [
        "There are manydifferent CPU-scheduling algorithms.",
        "In this section, we describe several of them."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_3_1",
      "title": "6.3.1 First-Come, First-Served Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 6,
      "definition": "By far the simplest CPU-scheduling algorithm is the \ufb01rst-come, \ufb01rst-served (FCFS) scheduling algorithm.",
      "key_points": [
        "With this scheme, the process that requests the CPU \ufb01rst is allocated the CPU \ufb01rst.",
        "When a process enters the ready queue, its PCB is linked onto the tail of the queue.",
        "When the CPU is free, it is allocated to the process at the head of the queue.",
        "The running process is then removed from the queue.",
        "Consider the following set of processes that arrive at time 0, with the length of the CPU burst given in milliseconds: Process Burst Time P1 P2 P3"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_3_2",
      "title": "6.3.2 Shortest-Job-First Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 7,
      "definition": "A differentapproachto CPU schedulingisthe shortest-job-\ufb01rst (SJF)scheduling algorithm.",
      "key_points": [
        "This algorithm associates with each process the length of the process\u2019s next CPU burst.",
        "When the CPU is available, it is assigned to the"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_3_3",
      "title": "6.3.3 Priority Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 10,
      "definition": "The SJF algorithm is a special case of the general priority-scheduling algorithm.",
      "key_points": [
        "A priority is associated with each process, and the CPUis allocated to the process with the highest priority.",
        "Equal-priority processes are scheduled in FCFS order.",
        "Note that we discuss scheduling in terms of high priority and low priority.",
        "As an example, consider the following set of processes, assumed to have arrived at time 0 in the order P1, P2, \u00b7 \u00b7 \u00b7, P5, with the length of the CPU burst given in milliseconds: Process Burst Time Priority P1 3 P2 1 P3 4 P4 5 P5 2"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_3_4",
      "title": "6.3.4 Round-Robin Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 11,
      "definition": "The round-robin (RR) scheduling algorithm is designed especially for time- sharing systems.",
      "key_points": [
        "It is similar to FCFS scheduling, but preemption is added to enable the system to switch between processes.",
        "A small unit of time, called a time quantum or time slice, is de\ufb01ned.",
        "A time quantum is generally from 10 to 100 milliseconds in length.",
        "The ready queue is treated as a circular queue."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_3_5",
      "title": "6.3.5 Multilevel Queue Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 13,
      "definition": "Another class of scheduling algorithms has been created for situations in which processes are easily classi\ufb01ed into different groups.",
      "key_points": []
    },
    {
      "id": "CHAP_05_SUB_6_3_6",
      "title": "6.3.6 Multilevel Feedback Queue Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 15,
      "definition": "Normally, when the multilevel queue scheduling algorithm is used, processes are permanently assigned to a queue when they enter the system.",
      "key_points": [
        "If there are separate queues for foreground and background processes, for example, processes do not move from one queue to the other, since processes do not change their foreground or background nature.",
        "This setup has the advantage of low scheduling overhead, but it is in\ufb02exible.",
        "The multilevel feedback queue scheduling algorithm, in contrast, allows a process to move between queues.",
        "The idea is to separate processes according to the characteristics of their CPU bursts.",
        "If a process uses too much CPU time, it will be moved to a lower-priority queue."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_4",
      "title": "6.4 Thread Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 17,
      "definition": "In Chapter 4, we introduced threads to the process model, distinguishing between user-level and kernel-level threads.",
      "key_points": [
        "On operating systems that support them, it is kernel-level threads\u2014not processes\u2014that are being scheduled by the operating system.",
        "To run on a CPU, user-level threads must ultimately be mapped to an associated kernel-level thread, although this mapping may be indirect and may use a lightweight process (LWP).",
        "User-level threads are managed by a thread library, and the kernel is unaware of them.",
        "In this section, we explore scheduling issues involving user-level and kernel-level threads and offer speci\ufb01c examples of scheduling for Pthreads."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_4_1",
      "title": "6.4.1 Contention Scope",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 17,
      "definition": "One distinction between user-level and kernel-level threads lies in how they are scheduled.",
      "key_points": [
        "This scheme is known as process- contention scope (PCS), since competition for the CPU takes place among threads belonging to the same process.",
        "It is important to note that PCS will typically preempt the thread currently running in favor of a higher-priority thread; however, there is no guarantee of time slicing (Section 6.3.4) among threads of equal priority.",
        "On systems implementing the many-to-one (Section 4.3.1) and many-to-many (Section 4.3.3) models, the thread library schedules user-level threads to run on an available LWP.",
        "(When we say the thread library schedules user threads onto available LWPs, we do not mean that the threads are actually running on a CPU.",
        "That would require the operating system to schedule the kernel thread onto a physical CPU.) To decide which kernel-level thread to schedule onto a CPU, the kernel uses system-contention scope (SCS)."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_4_2",
      "title": "6.4.2 Pthread Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 17,
      "definition": "We provided a sample POSIX Pthread program in Section 4.4.1, along with an introduction to thread creation with Pthreads.",
      "key_points": [
        "Pthreads identi\ufb01es the following contention scope values: \u2022 PTHREAD SCOPE PROCESS schedules threads using PCS scheduling.",
        "Now, we highlight the POSIX Pthread API that allows specifying PCS or SCS during thread creation.",
        "\u2022 PTHREAD SCOPE SYSTEM schedules threads using SCS scheduling."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_5",
      "title": "6.5 Multiple-Processor Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 18,
      "definition": "Our discussion thus far has focused on the problems of scheduling the CPU in a system with a single processor.",
      "key_points": [
        "Many possibilities have been tried; and as we saw with single- processor CPU scheduling, there is no one best solution.",
        "Here, we discuss several concerns in multiprocessor scheduling.",
        "We concentrate on systems in which the processors are identical\u2014homogeneous \u2014in terms of their functionality.",
        "We can then use any available processor to run any process in the queue.",
        "Note, however, that even with homogeneous multiprocessors, there are sometimes limitations on scheduling."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_5_1",
      "title": "6.5.1 Approaches to Multiple-Processor Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 18,
      "definition": "One approach to CPU scheduling in a multiprocessor system has all scheduling decisions, I/O processing, and other system activities handled by a single processor\u2014the master server.",
      "key_points": [
        "The other processors execute only user code.",
        "This asymmetric multiprocessing is simple because only one processor accesses the system data structures, reducing the need for data sharing."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_5_2",
      "title": "6.5.2 Processor Af\ufb01nity",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 20,
      "definition": "Consider what happens to cache memory when a process has been running on a speci\ufb01c processor.",
      "key_points": [
        "The data most recently accessed by the process populate the cache for the processor.",
        "As a result, successive memory accesses by the process are often satis\ufb01ed in cache memory.",
        "Now consider what happens if the process migrates to another processor.",
        "The contents of cache memory must be invalidated for the \ufb01rst processor, and the cache for the second processor must be repopulated.",
        "Because of the high cost of invalidating and repopulating caches, most SMP systems try to avoid migration of processes from one processor to another and instead attempt to keep a process running on the same processor."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_5_3",
      "title": "6.5.3 Load Balancing",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 20,
      "definition": "On SMP systems, it is important to keep the workload balanced among all processors to fully utilize the bene\ufb01ts of having more than one processor.",
      "key_points": []
    },
    {
      "id": "CHAP_05_SUB_6_5_4",
      "title": "6.5.4 Multicore Processors",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 21,
      "definition": "Traditionally, SMP systems have allowed several threads to run concurrently by providing multiple physical processors.",
      "key_points": [
        "However, a recent practice in computer"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_6",
      "title": "6.6 Real-Time CPU Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 23,
      "definition": "CPU scheduling for real-time operating systems involves special issues.",
      "key_points": [
        "Soft real-time systems provide no guarantee as to when a critical real-time process will be scheduled.",
        "They guarantee only that the process will be given preference over noncritical processes.",
        "In this section, we explore several issues related to process scheduling in both soft and hard real-time operating systems."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_6_1",
      "title": "6.6.1 Minimizing Latency",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 23,
      "definition": "Consider the event-driven nature of a real-time system.",
      "key_points": [
        "The system is typically waiting for an event in real time to occur.",
        "Events may arise either in software \u2014as when a timer expires\u2014or in hardware\u2014as when a remote-controlled vehicle detects that it is approaching an obstruction.",
        "When an event occurs, the system must respond to and service it as quickly as possible.",
        "We refer to event latency as the amount of time that elapses from when an event occurs to when it is serviced (Figure 6.12).",
        "Usually, different events have different latency requirements."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_6_2",
      "title": "6.6.2 Priority-Based Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 25,
      "definition": "The most important feature of a real-time operating system is to respond immediately to a real-time process as soon as that process requires the CPU.",
      "key_points": []
    },
    {
      "id": "CHAP_05_SUB_6_6_3",
      "title": "6.6.3 Rate-Monotonic Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 27,
      "definition": "The rate-monotonic scheduling algorithm schedules periodic tasks using a static priority policy with preemption.",
      "key_points": [
        "If a lower-priority process is running and a higher-priority process becomes available to run, it will preempt the lower-priorityprocess.",
        "Furthermore, rate-monotonic scheduling assumes that the processing time of a periodic process is the same for each CPU burst.",
        "That is, every time a process acquires the CPU, the duration of its CPU burst is the same.",
        "We have two processes, P1 and P2.",
        "The processing times are t1 = 20 for P1 and t2 = 35 for P2."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_6_4",
      "title": "6.6.4 Earliest-Deadline-First Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 28,
      "definition": "Earliest-deadline-\ufb01rst (EDF) scheduling dynamically assigns priorities accord- ing to deadline.",
      "key_points": [
        "Under the EDF policy, when a process becomes runnable, it must announce its deadline requirements to the system.",
        "Priorities may have to be adjusted to re\ufb02ect the deadline of the newly runnable process.",
        "Note how this differs from rate-monotonic scheduling, where priorities are \ufb01xed."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_6_5",
      "title": "6.6.5 Proportional Share Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 29,
      "definition": "Proportional share schedulers operate by allocating T shares among all applications.",
      "key_points": [
        "An application can receive N shares of time, thus ensuring that the application will have N/T of the total processor time.",
        "As an example, assume that a total of T = 100 shares is to be divided among three processes, A, B, and C.",
        "This scheme ensures that A will have 50 percent of total processor time, B will have 15 percent, and C will have 20 percent."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_6_6",
      "title": "6.6.6 POSIX Real-Time Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 30,
      "definition": "The POSIX standard also provides extensions for real-time computing\u2014 POSIX.1b.",
      "key_points": [
        "Here, we cover some of the POSIX API related to scheduling real-time threads.",
        "POSIX de\ufb01nes two scheduling classes for real-time threads: \u2022 SCHED FIFO \u2022 SCHED RR SCHED FIFO schedules threads according to a \ufb01rst-come, \ufb01rst-served policy using a FIFO queue as outlined in Section 6.3.1. However, there is no time slicing amongthreadsofequal priority.",
        "Therefore, the highest-priorityreal-time thread at the front of the FIFO queue will be granted the CPU until it terminates or blocks.",
        "SCHED RR uses a round-robin policy.",
        "It is similar to SCHED FIFO except that it provides time slicing among threads of equal priority."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_7",
      "title": "6.7 Operating-System Examples",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 30,
      "definition": "We turn next to a description of the scheduling policies of the Linux, Windows, and Solaris operating systems.",
      "key_points": [
        "It is important to note that we use the term process scheduling in a general sense here.",
        "In fact, we are describing the scheduling of kernel threads with Solaris and Windows systems and of tasks with the Linux scheduler."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_7_1",
      "title": "6.7.1 Example: Linux Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 30,
      "definition": "Process scheduling in Linux has had an interesting history.",
      "key_points": [
        "Prior to Version 2.5, the Linux kernel ran a variation of the traditional UNIX scheduling algorithm."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_7_2",
      "title": "6.7.2 Example: Windows Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 34,
      "definition": "Windows schedules threads using a priority-based, preemptive scheduling algorithm.",
      "key_points": [
        "The Windows API identi\ufb01es the following six priority classes to which a process can belong: \u2022 IDLE PRIORITY CLASS \u2022 BELOW NORMAL PRIORITY CLASS \u2022 NORMAL PRIORITY CLASS \u2022 ABOVE NORMAL PRIORITY CLASS",
        "The Windows scheduler ensures that the highest-priority thread will always run.",
        "The portion of the Windows kernel that handles scheduling is called the dispatcher.",
        "A thread selected to run by the dispatcher will run until it is preempted by a higher-priority thread, until it terminates, until its time quantum ends, or until it calls a blocking system call, such as for I/O.",
        "If a higher-priority real-time thread becomes ready while a lower-priority thread is running, the lower-priority thread will be preempted."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_7_3",
      "title": "6.7.3 Example: Solaris Scheduling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 37,
      "definition": "Solaris uses priority-based thread scheduling.",
      "key_points": [
        "The default scheduling class for a process is time sharing.",
        "Interactive processes typically have a higher priority; CPU-bound processes, a lower priority.",
        "This scheduling policy gives good response time for interactive processes and good throughput for CPU-bound processes."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_8",
      "title": "6.8 Algorithm Evaluation",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 40,
      "definition": "How do we select a CPU-scheduling algorithm for a particular system?",
      "key_points": [
        "As we saw in Section 6.3, there are many scheduling algorithms, each with its own parameters.",
        "As a result, selecting an algorithm can be dif\ufb01cult.",
        "The \ufb01rst problem is de\ufb01ning the criteria to be used in selecting an algorithm.",
        "As we saw in Section 6.2, criteria are often de\ufb01ned in terms of CPU utilization, response time, or throughput.",
        "To select an algorithm, we must \ufb01rst de\ufb01ne the relative importance of these elements."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_8_1",
      "title": "6.8.1 Deterministic Modeling",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 40,
      "definition": "One major class of evaluation methods is analytic evaluation.",
      "key_points": [
        "All \ufb01ve processes arrive at time 0, in the order given, with the length of the CPU burst given in milliseconds: Process Burst Time P1 P2 P3 P4 P5 Consider the FCFS, SJF, and RR (quantum = 10 milliseconds) scheduling algorithms for this set of processes.",
        "For the FCFS algorithm, we would execute the processes as P2 P5 P3 P4 P1 39 42 10",
        "Analytic evaluation uses the given algorithm and the system workload to produce a formula or number to evaluate the performance of the algorithm for that workload.",
        "Deterministic modeling is one type of analytic evaluation.",
        "This method takesaparticularpredetermined workload and de\ufb01nesthe performance ofeach algorithm for that workload."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_8_2",
      "title": "6.8.2 Queueing Models",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 41,
      "definition": "The result is a mathematical formula describing the probability of a particular CPU burst.",
      "key_points": [
        "On many systems, the processes that are run vary from day to day, so there is no static set of processes (or times) to use for deterministic modeling.",
        "Similarly, we can describe the distribution of times when processes arrive in the system (the arrival-time distribution).",
        "What can be determined, however, is the distribution of CPU and I/O bursts.",
        "These distributions can be measured and then approximated or simply estimated.",
        "Commonly, this distribution is exponential and is described by its mean."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_8_3",
      "title": "6.8.3 Simulations",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 42,
      "definition": "To get a more accurate evaluation of scheduling algorithms, we can use simulations.",
      "key_points": [
        "As this variable\u2019s value is increased, the simulator modi\ufb01es the system state to re\ufb02ect the activities of the devices, the processes, and the scheduler.",
        "The most common method uses a random-number generator that is programmed to generate processes, CPU burst times, arrivals, departures, and so on, according to probability distributions.",
        "Running simulations involves programming a model of the computer system.",
        "Software data structures represent the major components of the system.",
        "The simulator has a variable representing a clock."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_8_4",
      "title": "6.8.4 Implementation",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 43,
      "definition": "Even a simulation is of limited accuracy.",
      "key_points": [
        "Most users are not interested in building a better operating system; they merely want to get their processes executed and use their results.",
        "The only completely accurate way to evaluate a scheduling algorithm is to code it up, put it in the operating system, and see how it works.",
        "This approach puts the actual algorithm in the real system for evaluation under real operating conditions.",
        "The major dif\ufb01culty with this approach is the high cost.",
        "The expense is incurred not only in coding the algorithm and modifying the operating system to support it (along with its required data structures) but also in the reaction of the users to a constantly changing operating system."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_9",
      "title": "6.9 Summary",
      "label": "Topic",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 44,
      "definition": "CPU scheduling is the task of selecting a waiting process from the ready queue and allocating the CPU to it.",
      "key_points": [
        "The CPU is allocated to the selected process by the dispatcher.",
        "First-come, \ufb01rst-served (FCFS) scheduling is the simplest scheduling algo- rithm, but it can cause short processes to wait for very long processes.",
        "The SJF algorithm is a special case of the general priority scheduling algorithm, which simply allocates the CPU to the highest-priority process.",
        "RR scheduling allocates the CPU to the \ufb01rst process in the ready queue for q time units, where q is the time quantum.",
        "After q time units, if the process has not relinquished the CPU, it is preempted, and the process is put at the tail of the ready queue."
      ]
    },
    {
      "id": "CHAP_05_SUB_6_1",
      "title": "6.1 A CPU-scheduling algorithm determines an order for the execution",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 45,
      "definition": "of its scheduled processes. Given n processes to be scheduled on one processor, how many different schedules are possible? Give a formula in terms of n.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_2",
      "title": "6.2 Explain the difference between preemptive and nonpreemptive schedul-",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 46,
      "definition": "ing.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_3",
      "title": "6.3 Suppose that the following processes arrive for execution at the times",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 46,
      "definition": "indicated. Each process will run for the amount of time listed. In answering the questions, use nonpreemptive scheduling, and base all decisions on the information you have at the time the decision must be made. Process Arrival Time Burst Time P1 0.0 P2 0.4 P3 1.0 a. What is the average turnaround time for these processes with the FCFS scheduling algorithm? b. What is the average turnaround time for these processes with the SJF scheduling algorithm? c. The SJF algorithm is supposed to improve pe",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_4",
      "title": "6.4 What advantage is there in having different time-quantum sizes at",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 46,
      "definition": "different levels of a multilevel queueing system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_5",
      "title": "6.5 Many CPU-scheduling algorithms are parameterized. For example, the",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 46,
      "definition": "RR algorithm requires a parameter to indicate the time slice. Multilevel feedback queues require parameters to de\ufb01ne the number of queues, the scheduling algorithm for each queue, the criteria used to move processes between queues, and so on. These algorithms are thus really sets of algorithms (for example, the set of RR algorithms for all time slices, and so on). One set of algorithms may include another (for example, the FCFSalgorithm is the RR algorithm with an in\ufb01nite time quantum). What (if",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_6",
      "title": "6.6 Suppose that a scheduling algorithm (at the level of short-term CPU",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 46,
      "definition": "scheduling) favors those processes that have used the least processor",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_7",
      "title": "6.7 Distinguish between PCS and SCS scheduling.",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 47,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_8",
      "title": "6.8 Assume that an operating system maps user-level threads to the kernel",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 47,
      "definition": "using the many-to-many model and that the mapping is done through the use of LWPs. Furthermore, the system allows program developers to create real-time threads. Is it necessary to bind a real-time thread to an LWP?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_9",
      "title": "6.9 The traditional UNIX scheduler enforces an inverse relationship between",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 47,
      "definition": "priority numbers and priorities: the higher the number, the lower the priority. The scheduler recalculates process priorities once per second using the following function: Priority = (recent CPU usage / 2) + base where base = 60 and recent CPU usage refers to a value indicating how often a process has used the CPU since priorities were last recalculated. Assume that recent CPU usage is 40 for process P1, 18 for process P2, and 10 for process P3. What will be the new priorities for these three pr",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_10",
      "title": "6.10 Why is it important for the scheduler to distinguish I/O-bound programs",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 47,
      "definition": "from CPU-bound programs?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_11",
      "title": "6.11 Discuss how the following pairs of scheduling criteria con\ufb02ict in certain",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 47,
      "definition": "settings. a. CPU utilization and response time b. Average turnaround time and maximum waiting time c. I/O device utilization and CPU utilization",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_12",
      "title": "6.12 One technique for implementing lottery scheduling works by assigning",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 47,
      "definition": "processes lottery tickets, which are used for allocating CPU time. When- ever a scheduling decision has to be made, a lottery ticket is chosen at random, and the process holding that ticket gets the CPU. The BTV operating system implements lottery scheduling by holding a lottery times each second, with each lottery winner getting 20 milliseconds of CPU time (20 milliseconds \u00d7 50 = 1 second). Describe how the BTV scheduler can ensure that higher-priority threads receive more attention from the CP",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_13",
      "title": "6.13 In Chapter 5, we discussed possible race conditions on various kernel",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 47,
      "definition": "data structures. Most scheduling algorithms maintain a run queue, which lists processes eligible to run on a processor. On multicore systems, there are two general options: (1) each processing core has its own run",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_14",
      "title": "6.14 Consider the exponential average formula used to predict the length of",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 48,
      "definition": "the next CPU burst. What are the implications of assigning the following values to the parameters used by the algorithm? a. # = 0 and \"0 = 100 milliseconds b. # = 0.99 and \"0 = 10 milliseconds",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_15",
      "title": "6.15 A variation of the round-robin scheduler is the regressive round-robin",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 48,
      "definition": "scheduler. This scheduler assigns each process a time quantum and a priority. The initial value of a time quantum is 50 milliseconds. However, every time a process has been allocated the CPU and uses its entire time quantum (does not block for I/O), 10 milliseconds is added to its time quantum, and its priority level is boosted. (The time quantum for a process can be increased to a maximum of 100 milliseconds.) When a process blocks before using its entire time quantum, its time quantum is reduc",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_16",
      "title": "6.16 Consider the following set of processes, with the length of the CPU burst",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 48,
      "definition": "given in milliseconds: Process Burst Time Priority P1 2 P2 1 P3 4 P4 2 P5 3 The processes are assumed to have arrived in the order P1, P2, P3, P4, P5, all at time 0. a. Draw four Gantt charts that illustrate the execution of these processes using the following scheduling algorithms: FCFS, SJF, nonpreemptive priority (a larger priority number implies a higher priority), and RR (quantum = 2). b. What is the turnaround time of each process for each of the scheduling algorithms in part a? c. What is",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_17",
      "title": "6.17 The following processes are being scheduled using a preemptive, round-",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 48,
      "definition": "robin scheduling algorithm. Each process is assigned a numerical priority, with a higher number indicating a higher relative priority. In addition to the processes listed below, the system also has an idle",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_18",
      "title": "6.18 The nice command is used to set the nice value of a process on Linux,",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 49,
      "definition": "as well as on other UNIX systems. Explain why some systems may allow any user to assign a process a nice value >= 0 yet allow only the root user to assign nice values < 0.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_19",
      "title": "6.19 Which of the following scheduling algorithms could result in starvation?",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 49,
      "definition": "a. First-come, \ufb01rst-served b. Shortest job \ufb01rst c. Round robin d. Priority",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_20",
      "title": "6.20 Consider a variant of the RR scheduling algorithm in which the entries",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 49,
      "definition": "in the ready queue are pointers to the PCBs. a. What would be the effect of putting two pointers to the same process in the ready queue? b. What would be two major advantages and two disadvantages of this scheme? c. How would you modify the basic RR algorithm to achieve the same effect without the duplicate pointers?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_21",
      "title": "6.21 Consider a system running ten I/O-bound tasks and one CPU-bound",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 49,
      "definition": "task. Assume that the I/O-bound tasks issue an I/O operation once for every millisecond of CPU computing and that each I/O operation takes milliseconds to complete. Also assume that the context-switching overhead is 0.1 millisecond and that all processes are long-running tasks. Describe the CPU utilization for a round-robin scheduler when:",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_22",
      "title": "6.22 Consider a system implementing multilevel queue scheduling. What",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 50,
      "definition": "strategy can a computer user employ to maximize the amount of CPU time allocated to the user\u2019s process?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_23",
      "title": "6.23 Consider a preemptive priority scheduling algorithm based on dynami-",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 50,
      "definition": "cally changing priorities. Larger priority numbers imply higher priority. When a process is waiting for the CPU (in the ready queue, but not running), its priority changes at a rate #. When it is running, its priority changes at a rate &. All processes are given a priority of 0 when they enter the ready queue. The parameters # and & can be set to give many different scheduling algorithms. a. What is the algorithm that results from & > # > 0? b. What is the algorithm that results from # < & < 0?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_24",
      "title": "6.24 Explain the differences in how much the following scheduling algo-",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 50,
      "definition": "rithms discriminate in favor of short processes: a. FCFS b. RR c. Multilevel feedback queues",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_25",
      "title": "6.25 Using the Windows scheduling algorithm, determine the numeric",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 50,
      "definition": "priority of each of the following threads. a. A thread in the REALTIME PRIORITY CLASS with a relative priority of NORMAL b. A thread in the ABOVE NORMAL PRIORITY CLASS with a relative priority of HIGHEST c. A thread in the BELOW NORMAL PRIORITY CLASS with a relative priority of ABOVE NORMAL",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_26",
      "title": "6.26 Assuming that no threads belong to the REALTIME PRIORITY CLASS and",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 50,
      "definition": "that none may be assigned a TIME CRITICAL priority, what combination of priority class and priority corresponds to the highest possible relative priority in Windows scheduling?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_27",
      "title": "6.27 Consider the scheduling algorithm in the Solaris operating system for",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 50,
      "definition": "time-sharing threads. a. What is the time quantum (in milliseconds) for a thread with priority 15? With priority 40? b. Assume that a thread with priority 50 has used its entire time quantum without blocking. What new priority will the scheduler assign this thread? c. Assume that a thread with priority 20 blocks for I/O before its time quantum has expired. What new priority will the scheduler assign this thread?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_28",
      "title": "6.28 Assume that two tasks Aand B are running on a Linux system. The nice",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 51,
      "definition": "values of Aand B are \u22125 and +5, respectively. Using the CFS scheduler as a guide, describe how the respective values of vruntime vary between the two processes given each of the following scenarios: \u2022 Both A and B are CPU-bound. \u2022 A is I/O-bound, and B is CPU-bound. \u2022 A is CPU-bound, and B is I/O-bound.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_29",
      "title": "6.29 Discuss ways in which the priority inversion problem could be",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 51,
      "definition": "addressed in a real-time system. Also discuss whether the solutions could be implemented within the context of a proportional share sched- uler.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_30",
      "title": "6.30 Under what circumstances is rate-monotonic scheduling inferior to",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 51,
      "definition": "earliest-deadline-\ufb01rst scheduling in meeting the deadlines associated with processes?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_31",
      "title": "6.31 Consider two processes, P1 and P2, where p1 = 50, t1 = 25, p2 = 75, and",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 51,
      "definition": "t2 = 30. a. Can these two processes be scheduled using rate-monotonic scheduling? Illustrate your answer using a Gantt chart such as the ones in Figure 6.16\u2013Figure 6.19. b. Illustrate the scheduling of these two processes using earliest- deadline-\ufb01rst (EDF) scheduling.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05_SUB_6_32",
      "title": "6.32 Explain why interrupt and dispatch latency times must be bounded in",
      "label": "Exercise",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 51,
      "definition": "a hard real-time system. Bibliographical Notes Feedback queues were originally implemented on the CTSS system described in [Corbato et al. (1962)]. This feedback queue scheduling system was analyzed by [Schrage (1967)]. The preemptive priority scheduling algorithm of Exercise 6.23 was suggested by [Kleinrock (1975)]. The scheduling algorithms for hard real- time systems, such as rate monotonic scheduling and earliest-deadline-\ufb01rst scheduling, are presented in [Liu and Layland (1973)]. [Anderson ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_05",
      "title": "Chapter 6 CPU Scheduling",
      "label": "Chapter",
      "file_source": "06_Chapter 6 CPU Scheduling.pdf",
      "page": 1,
      "definition": "6 C H A P T E R CPU Scheduling CPU scheduling is the basis of multiprogrammed operating systems.",
      "key_points": [
        "By switching the CPU among processes, the operating system can make the computer more productive.",
        "In Chapter 4, we introduced threads to the process model.",
        "On operating systems that support them, it is kernel-level threads\u2014not processes\u2014that are in fact being scheduled by the operating system.",
        "6.1 Basic Concepts: In a single-processor system, only one process can run at a time....",
        "6.1.1 CPU\u2013I/O Burst Cycle: The success of CPU scheduling depends on an observed property of processes: proc...",
        "6.1.2 CPU Scheduler: Whenever the CPU becomes idle, the operating system must select one of the proce...",
        "6.1.3 Preemptive Scheduling: CPU-scheduling decisions may take place under the following four circum- stances...",
        "6.1.4 Dispatcher: Another component involved in the CPU-scheduling function is the dispatcher...."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_1",
      "title": "7.1 System Model",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 1,
      "definition": "A system consists of a \ufb01nite number of resources to be distributed among a number of competing processes.",
      "key_points": [
        "The resources may be partitioned into several"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_2",
      "title": "7.2 Deadlock Characterization",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 3,
      "definition": "In a deadlock, processes never \ufb01nish executing, and system resources are tied up, preventing other jobs from starting.",
      "key_points": [
        "Before we discuss the various methods for dealing with the deadlock problem, we look more closely at features that characterize deadlocks.",
        "DEADLOCK WITH MUTEX LOCKS Let\u2019s see how deadlock can occur in a multithreaded Pthread program using mutex locks.",
        "The pthread mutex init() function initializes an unlocked mutex.",
        "Mutex locks are acquired and released using pthread mutex lock() and pthread mutex unlock(), respec- tively.",
        "If a thread attempts to acquire a locked mutex, the call to pthread mutex lock() blocks the thread until the owner of the mutex lock invokes pthread mutex unlock()."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_2_1",
      "title": "7.2.1 Necessary Conditions",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 4,
      "definition": "A deadlock situation can arise if the following four conditions hold simultane- ously in a system:",
      "key_points": []
    },
    {
      "id": "CHAP_06_SUB_7_2_2",
      "title": "7.2.2 Resource-Allocation Graph",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 5,
      "definition": "This graph consists of a set of vertices V and a set of edges E.",
      "key_points": [
        "The set of vertices V is partitioned into two different types of nodes: P = {P1, P2, ..., Pn}, the set consisting of all the active processes in the system, and R = {R1, R2, ..., Rm}, the set consisting of all resource types in the system.",
        "A directed edge from process Pi to resource type Rj is denoted by Pi \u2192Rj; it signi\ufb01es that process Pi has requested an instance of resource type Rj and is currently waiting for that resource.",
        "A directed edge from resource type Rj to process Pi is denoted by Rj \u2192Pi; it signi\ufb01es that an instance of resource type Rj has been allocated to process Pi. A directed edge Pi \u2192Rj is called a request edge; a directed edge Rj \u2192Pi is called an assignment edge.",
        "Pictorially, we represent each process Pi as a circle and each resource type Rj as a rectangle.",
        "Note that a request edge points to only the rectangle Rj, whereas an assignment edge must also designate one of the dots in the rectangle."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_3",
      "title": "7.3 Methods for Handling Deadlocks",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 8,
      "definition": "Generally speaking, we can deal with the deadlock problem in one of three ways: \u2022 We can use a protocol to prevent or avoid deadlocks, ensuring that the system will never enter a deadlocked state.",
      "key_points": [
        "We discuss these methods in Section 7.4. Deadlock avoidance requires that the operating system be given additional information in advance concerning which resources a process will request and use during its lifetime.",
        "With this additional knowledge, the operating system can decide for each request whether or not the process should wait.",
        "To decide whether the current request can be satis\ufb01ed or must be delayed, the system must consider the resources currently available, the resources currently allocated to each process, and the future requests and releases of each process."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_4",
      "title": "7.4 Deadlock Prevention",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 9,
      "definition": "As we noted in Section 7.2.1, for a deadlock to occur, each of the four necessary conditions must hold.",
      "key_points": [
        "By ensuring that at least one of these conditions cannot hold, we can prevent the occurrence of a deadlock.",
        "We elaborate on this approach by examining each of the four necessary conditions separately."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_4_1",
      "title": "7.4.1 Mutual Exclusion",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 9,
      "definition": "The mutual exclusion condition must hold.",
      "key_points": [
        "If several processes attempt to open a read-only \ufb01le at the same time, they can be granted simultaneous access to the \ufb01le.",
        "A process never needs to wait for a sharable resource.",
        "For example, a mutex lock cannot be simultaneously shared by several processes."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_4_2",
      "title": "7.4.2 Hold and Wait",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 9,
      "definition": "To ensure that the hold-and-wait condition never occurs in the system, we must guarantee that, whenever a process requests a resource, it does not hold any other resources.",
      "key_points": [
        "One protocol that we can use requires each process to request and be allocated all its resources before it begins execution.",
        "We can implement this provision by requiring that system calls requesting resources for a process precede all other system calls."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_4_3",
      "title": "7.4.3 No Preemption",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 10,
      "definition": "The third necessary condition for deadlocks is that there be no preemption of resources that have already been allocated.",
      "key_points": [
        "If a process is holding some resources and requests another resource that cannot be immediately allocated to it (that is, the process must wait), then all resources the process is currently holding are preempted.",
        "The preempted resources are added to the list of resources for which the process is waiting.",
        "The process will be restarted only when it can regain its old resources, as well as the new ones that it is requesting.",
        "Alternatively, if a process requests some resources, we \ufb01rst check whether they are available.",
        "If they are not, we check whether they are allocated to some other process that is waiting for additional resources."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_4_4",
      "title": "7.4.4 Circular Wait",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 11,
      "definition": "The fourth and \ufb01nal condition for deadlocks is the circular-wait condition.",
      "key_points": [
        "One way to ensure that this condition never holds is to impose a total ordering of all resource types and to require that each process requests resources in an increasing order of enumeration.",
        "For example, if the set of resource types R includes tape drives, disk drives, and printers, then the function F might be de\ufb01ned as follows: F(tape drive) = 1 F(disk drive) = 5 F(printer) = 12 We can now consider the following protocol to prevent deadlocks: Each process can request resources only in an increasing order of enumeration.",
        "That is, a process can initially request any number of instances of a resource type \u2014say, Ri. After that, the process can request instances of resource type Rj if and only if F(Rj) > F(Ri).",
        "For example, using the function de\ufb01ned previously, a process that wants to use the tape drive and printer at the same time must \ufb01rst request the tape drive and then request the printer.",
        "Alternatively, we can require that a process requesting an instance of resource type Rj must have released any resources Ri such that F(Ri) \u2265F(Rj)."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_5",
      "title": "7.5 Deadlock Avoidance",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 13,
      "definition": "Deadlock-preventionalgorithms, asdiscussed inSection7.4, preventdeadlocks by limiting how requests can be made.",
      "key_points": [
        "For example, in a system with one tape drive and one printer, the system might need to know that process P will request \ufb01rst the tape drive and then the printer before releasing both resources, whereas process Q will request \ufb01rst the printer and then the tape drive.",
        "With this knowledge of the complete sequence of requests and releases for each process, the system can decide for each request whether or not the process should wait in order to avoid a possible future deadlock.",
        "Each request requires that in making this decision the system consider the resources currently available, the resources currently allocated to each process, and the future requests and releases of each process.",
        "The simplest and most useful model requires that each process declare the maximum number of resources of each type that it may need."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_5_1",
      "title": "7.5.1 Safe State",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 14,
      "definition": "A sequence of processes <P1, P2, ..., Pn> is a safe sequence for the current allocation state if, for each Pi, the resource requests that Pi can still make can be satis\ufb01ed by the currently available resources plus the resources held by all Pj, with j < i.",
      "key_points": [
        "A state is safe if the system can allocate resources to each process (up to its maximum) in some order and still avoid a deadlock.",
        "In an unsafe state, the operating system cannot prevent processes from requesting resources in such a way that a deadlock occurs.",
        "The behavior of the processes controls unsafe states.",
        "To illustrate, we consider a system with twelve magnetic tape drives and three processes: P0, P1, and P2.",
        "Process P0 requires ten tape drives, process P1 may need as many as four tape drives, and process P2 may need up to nine tape drives."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_5_2",
      "title": "7.5.2 Resource-Allocation-Graph Algorithm",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 15,
      "definition": "If we have a resource-allocation system with only one instance of each resource type, we can use a variant of the resource-allocation graph de\ufb01ned in Section 7.2.2 for deadlock avoidance.",
      "key_points": [
        "A claim edge Pi \u2192Rj indicates that process Pi may request resource Rj at some time in the future.",
        "When process Pi requests resource Rj, the claim edge Pi \u2192Rj is converted to a request edge.",
        "Similarly, when a resource Rj is released by Pi, the assignment edge Rj \u2192Pi is reconverted to a claim edge Pi \u2192Rj. Note that the resources must be claimed a priori in the system.",
        "That is, before process Pi starts executing, all its claim edges must already appear in the resource-allocation graph.",
        "We can relax this condition by allowing a claim edge Pi \u2192Rj to be added to the graph only if all the edges associated with process Pi are claim edges."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_5_3",
      "title": "7.5.3 Banker\u2019s Algorithm",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 16,
      "definition": "The resource-allocation-graph algorithm is not applicable to a resource- allocation system with multiple instances of each resource type.",
      "key_points": [
        "The deadlock- avoidance algorithm that we describe next is applicable to such a system but is less ef\ufb01cient than the resource-allocation graph scheme.",
        "This algorithm is commonly known as the banker\u2019s algorithm.",
        "The name was chosen because the algorithm could be used in a banking system to ensure that the bank never R1 R2 P2 P1 Figure 7.8 An unsafe state in a resource-allocation graph."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_6",
      "title": "7.6 Deadlock Detection",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 19,
      "definition": "If a system does not employ either a deadlock-prevention or a deadlock- avoidance algorithm, then a deadlock situation may occur.",
      "key_points": [
        "In this environment, the system may provide: \u2022 An algorithm that examines the state of the system to determine whether a deadlock has occurred \u2022 An algorithm to recover from the deadlock"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_6_1",
      "title": "7.6.1 Single Instance of Each Resource Type",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 20,
      "definition": "If all resources have only a single instance, then we can de\ufb01ne a deadlock- detection algorithm that uses a variant of the resource-allocation graph, called a wait-for graph.",
      "key_points": [
        "More precisely, an edge from Pi to Pj in a wait-for graph implies that process Pi is waiting for process Pj to release a resource that Pi needs.",
        "We obtain this graph from the resource-allocation graph by removing the resource nodes and collapsing the appropriate edges.",
        "An edge Pi \u2192Pj exists in a wait-for graph if and only if the corresponding resource- allocation graph contains two edges Pi \u2192Rq and Rq \u2192Pj for some resource Rq. In Figure 7.9, we present a resource-allocation graph and the corresponding wait-for graph.",
        "As before, a deadlock exists in the system if and only if the wait-for graph contains a cycle.",
        "To detect deadlocks, the system needs to maintain the wait- for graph and periodically invoke an algorithm that searches for a cycle in the graph."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_6_2",
      "title": "7.6.2 Several Instances of a Resource Type",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 20,
      "definition": "The wait-for graph scheme is not applicable to a resource-allocation system with multiple instances of each resource type.",
      "key_points": [
        "We turn now to a deadlock-"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_6_3",
      "title": "7.6.3 Detection-Algorithm Usage",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 22,
      "definition": "How often is a deadlock likely to occur?",
      "key_points": [
        "How many processes will be affected by deadlock when it happens?",
        "Resources allocated to deadlocked processes will be idle until the deadlock can be broken.",
        "In addition, the number of processes involved in the deadlock cycle may grow.",
        "Deadlocks occur only when some process makes a request that cannot be granted immediately.",
        "This request may be the \ufb01nal request that completes a chain of waiting processes."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_7",
      "title": "7.7 Recovery from Deadlock",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 23,
      "definition": "When a detection algorithm determines that a deadlock exists, several alter- natives are available.",
      "key_points": [
        "One is simply to abort one or more processes to break the circular wait.",
        "The other is to preempt some resources from one or more of the deadlocked processes.",
        "One possibility is to inform the operator that a deadlock has occurred and to let the operator deal with the deadlock manually.",
        "Another possibility is to let the system recover from the deadlock automatically.",
        "There are two options for breaking a deadlock."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_7_1",
      "title": "7.7.1 Process Termination",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 23,
      "definition": "To eliminate deadlocks by aborting a process, we use one of two methods.",
      "key_points": [
        "In both methods, the system reclaims all resources allocated to the terminated processes.",
        "\u2022 Abort all deadlocked processes.",
        "The deadlocked processes may have computed for a long time, and the results of these partial computations must be discarded and probably will have to be recomputed later.",
        "\u2022 Abort one process at a time until the deadlock cycle is eliminated.",
        "This method incurs considerable overhead, since after each process is aborted, a deadlock-detection algorithm must be invoked to determine whether any processes are still deadlocked."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_7_2",
      "title": "7.7.2 Resource Preemption",
      "label": "Topic",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 24,
      "definition": "To eliminate deadlocks using resource preemption, we successively preempt some resources from processes and give these resources to other processes until the deadlock cycle is broken.",
      "key_points": [
        "Which resources and which processes are to be preempted?",
        "As in process termination, we must determine the order of preemption to minimize cost.",
        "Cost factors may include such parameters as the number of resources a deadlocked process is holding and the amount of time the process has thus far consumed.",
        "If we preempt a resource from a process, what should be done with that process?",
        "We must roll back the process to some safe state and restart it from that state."
      ]
    },
    {
      "id": "CHAP_06_SUB_7_8",
      "title": "7.8 Summary",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 25,
      "definition": "A deadlocked state occurs when two or more processes are waiting inde\ufb01nitely for an event that can be caused only by one of the waiting processes. There are three principal methods for dealing with deadlocks: \u2022 Use some protocol to prevent or avoid deadlocks, ensuring that the system will never enter a deadlocked state. \u2022 Allow the system to enter a deadlocked state, detect it, and then recover. \u2022 Ignore the problem altogether and pretend that deadlocks never occur in the system. The third solut",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_1",
      "title": "7.1 List three examples of deadlocks that are not related to a computer-",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 25,
      "definition": "system environment.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_2",
      "title": "7.2 Suppose that a system is in an unsafe state. Show that it is possible for",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 25,
      "definition": "the processes to complete their execution without entering a deadlocked state.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_3",
      "title": "7.3 Consider the following snapshot of a system:",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 26,
      "definition": "Allocation Max Available A B C D A B C D A B C D P0 0 1 2 0 1 2 5 2 0 P1 0 0 0 7 5 0 P2 3 5 4 3 5 6 P3 6 3 2 6 5 2 P4 0 1 4 6 5 6 Answer the following questions using the banker\u2019s algorithm: a. What is the content of the matrix Need? b. Is the system in a safe state? c. If a request from process P1 arrives for (0,4,2,0), can the request be granted immediately?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_4",
      "title": "7.4 A possible method for preventing deadlocks is to have a single, higher-",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 26,
      "definition": "order resource that must be requested before any other resource. For example, if multiple threads attempt to access the synchronization objects A\u00b7 \u00b7 \u00b7 E, deadlock is possible. (Such synchronization objects may include mutexes, semaphores, condition variables, and the like.) We can prevent the deadlock by adding a sixth object F. Whenever a thread wants to acquire the synchronization lock for any object A\u00b7 \u00b7 \u00b7 E, it must \ufb01rst acquire the lock for object F. This solution is known as containment: t",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_5",
      "title": "7.5 Prove that the safety algorithm presented in Section 7.5.3 requires an",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 26,
      "definition": "order of m \u00d7 n2 operations.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_6",
      "title": "7.6 Consider a computer system that runs 5,000 jobs per month and has no",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 26,
      "definition": "deadlock-prevention or deadlock-avoidance scheme. Deadlocks occur about twice per month, and the operator must terminate and rerun about ten jobs per deadlock. Each job is worth about two dollars (in CPU time), and the jobs terminated tend to be about half done when they are aborted. A systems programmer has estimated that a deadlock-avoidance algorithm (like the banker\u2019s algorithm) could be installed in the system with an increase of about 10 percent in the average execution time per job. Since",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_7",
      "title": "7.7 Can a system detect that some of its processes are starving? If you answer",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 27,
      "definition": "\u201cyes,\u201d explain how it can. If you answer \u201cno,\u201d explain how the system can deal with the starvation problem.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_8",
      "title": "7.8 Consider the following resource-allocation policy. Requests for and",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 27,
      "definition": "releases of resources are allowed at any time. If a request for resources cannot be satis\ufb01ed because the resources are not available, then we check any processes that are blocked waiting for resources. If a blocked process has the desired resources, then these resources are taken away from it and are given to the requesting process. The vector of resources for which the blocked process is waiting is increased to include the resources that were taken away. For example, a system has three resource",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_9",
      "title": "7.9 Suppose that you have coded the deadlock-avoidance safety algorithm",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 27,
      "definition": "and now have been asked to implement the deadlock-detection algo- rithm. Can you do so by simply using the safety algorithm code and rede\ufb01ning Maxi = Waitingi + Allocationi, where Waitingi is a vector specifying the resources for which process i is waiting and Allocationi is as de\ufb01ned in Section 7.5? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_10",
      "title": "7.10 Is it possible to have a deadlock involving only one single-threaded",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 27,
      "definition": "process? Explain your answer. Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_11",
      "title": "7.11 Consider the traf\ufb01c deadlock depicted in Figure 7.10.",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 27,
      "definition": "a. Show that the four necessary conditions for deadlock hold in this example. b. State a simple rule for avoiding deadlocks in this system.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_12",
      "title": "7.12 Assume a multithreaded application uses only reader\u2013writer locks for",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 27,
      "definition": "synchronization. Applying the four necessary conditions for deadlock, is deadlock still possible if multiple reader\u2013writer locks are used?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_13",
      "title": "7.13 The program example shown in Figure 7.4 doesn\u2019t always lead to",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 27,
      "definition": "deadlock. Describe what role the CPU scheduler plays and how it can contribute to deadlock in this program.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_14",
      "title": "7.14 In Section 7.4.4, we describe a situation in which we prevent deadlock",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 28,
      "definition": "by ensuring that all locks are acquired in a certain order. However, we also point out that deadlock is possible in this situation if two threads simultaneously invoke the transaction() function. Fix the transaction() function to prevent deadlocks.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_15",
      "title": "7.15 Compare the circular-wait scheme with the various deadlock-avoidance",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 28,
      "definition": "schemes (like the banker\u2019s algorithm) with respect to the following issues: a. Runtime overheads b. System throughput",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_16",
      "title": "7.16 In a real computer system, neither the resources available nor the",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 28,
      "definition": "demands of processes for resources are consistent over long periods (months). Resources break or are replaced, new processes come and go, and new resources are bought and added to the system. If deadlock is controlled by the banker\u2019s algorithm, which of the following changes can be made safely (without introducing the possibility of deadlock), and under what circumstances? a. Increase Available (new resources added). b. Decrease Available (resource permanently removed from system). c. Increase M",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_17",
      "title": "7.17 Consider a system consisting of four resources of the same type that are",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 29,
      "definition": "shared by three processes, each of which needs at most two resources. Show that the system is deadlock free.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_18",
      "title": "7.18 Consider a system consisting of m resources of the same type being",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 29,
      "definition": "shared by n processes. A process can request or release only one resource at a time. Show that the system is deadlock free if the following two conditions hold: a. The maximum need of each process is between one resource and m resources. b. The sum of all maximum needs is less than m + n.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_19",
      "title": "7.19 Consider the version of the dining-philosophers problem in which the",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 29,
      "definition": "chopsticks are placed at the center of the table and any two of them can be used by a philosopher. Assume that requests for chopsticks are made one at a time. Describe a simple rule for determining whether a particular request can be satis\ufb01ed without causing deadlock given the current allocation of chopsticks to philosophers.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_20",
      "title": "7.20 Consider again the setting in the preceding question. Assume now that",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 29,
      "definition": "each philosopher requires three chopsticks to eat. Resource requests are still issued one at a time. Describe some simple rules for determining whether a particular request can be satis\ufb01ed without causing deadlock given the current allocation of chopsticks to philosophers.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_21",
      "title": "7.21 We can obtain the banker\u2019s algorithm for a single resource type from",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 29,
      "definition": "the general banker\u2019s algorithm simply by reducing the dimensionality of the various arrays by 1. Show through an example that we cannot implement the multiple-resource-type banker\u2019s scheme by applying the single-resource-type scheme to each resource type individually.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_22",
      "title": "7.22 Consider the following snapshot of a system:",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 29,
      "definition": "Allocation Max A B C D A B C D P0 0 1 4 1 1 7 P1 2 1 0 2 1 1 P2 1 2 1 3 2 1 P3 5 1 0 6 1 2 P4 2 1 2 3 2 5 Using the banker\u2019s algorithm, determine whether or not each of the following states is unsafe. If the state is safe, illustrate the order in which the processes may complete. Otherwise, illustrate why the state is unsafe. a. Available = (0, 3, 0, 1) b. Available = (1, 0, 0, 2)",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_23",
      "title": "7.23 Consider the following snapshot of a system:",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 30,
      "definition": "Allocation Max Available A B C D A B C D A B C D P0 0 0 1 2 1 2 3 2 1 P1 1 2 1 2 5 2 P2 1 0 3 3 1 6 P3 3 1 2 4 2 4 P4 4 3 2 6 6 5 Answer the following questions using the banker\u2019s algorithm: a. Illustrate that the system is in a safe state by demonstrating an order in which the processes may complete. b. If a request from process P1 arrives for (1, 1, 0, 0), can the request be granted immediately? c. If a request from process P4 arrives for (0, 0, 2, 0), can the request be granted immediately?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_24",
      "title": "7.24 What is the optimistic assumption made in the deadlock-detection",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 30,
      "definition": "algorithm? How can this assumption be violated?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_25",
      "title": "7.25 A single-lane bridge connects the two Vermont villages of North",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 30,
      "definition": "Tunbridge and South Tunbridge. Farmers in the two villages use this bridge to deliver their produce to the neighboring town. The bridge can become deadlocked if a northbound and a southbound farmer get on the bridge at the same time. (Vermont farmers are stubborn and are unable to back up.) Using semaphores and/or mutex locks, design an algorithm in pseudocode that prevents deadlock. Initially, do not be concerned about starvation (the situation in which northbound farmers prevent southbound far",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_26",
      "title": "7.26 Modify your solution to Exercise 7.25 so that it is starvation-free.",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 30,
      "definition": "Programming Problems",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06_SUB_7_27",
      "title": "7.27 Implement your solution to Exercise 7.25 using POSIX synchronization.",
      "label": "Exercise",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 30,
      "definition": "In particular, represent northbound and southbound farmers as separate threads. Once a farmer is on the bridge, the associated thread will sleep for a random period of time, representing traveling across the bridge. Design your program so that you can create several threads representing the northbound and southbound farmers.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_06",
      "title": "Chapter 7 Deadlocks",
      "label": "Chapter",
      "file_source": "07_Chapter 7 Deadlocks.pdf",
      "page": 1,
      "definition": "7 C H A P T E R Deadlocks In a multiprogramming environment, several processes may compete for a \ufb01nite number of resources.",
      "key_points": [
        "A process requests resources; if the resources are not available at that time, the process enters a waiting state.",
        "Sometimes, a waiting process is never again able to change state, because the resources it has requested are held by other waiting processes.",
        "Deadlock problems can only become more common, given current trends, including larger num- bers of processes, multithreaded programs, many more resources within a system, and an emphasis on long-lived \ufb01le and database servers rather than batch systems.",
        "7.1 System Model: A system consists of a \ufb01nite number of resources to be distributed among a numbe...",
        "7.2 Deadlock Characterization: In a deadlock, processes never \ufb01nish executing, and system resources are tied up...",
        "7.2.1 Necessary Conditions: A deadlock situation can arise if the following four conditions hold simultane- ...",
        "7.2.2 Resource-Allocation Graph: This graph consists of a set of vertices V and a set of edges E....",
        "7.3 Methods for Handling Deadlocks: Generally speaking, we can deal with the deadlock problem in one of three ways: ..."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_1",
      "title": "8.1 Background",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 1,
      "definition": "Memory consists of a large array of bytes, each with its own address.",
      "key_points": [
        "The CPU fetches instructions from memory according to the value of the program counter.",
        "These instructions may cause additional loading from and storing to speci\ufb01c memory addresses.",
        "A typical instruction-execution cycle, for example, \ufb01rst fetches an instruc- tion from memory.",
        "The instruction is then decoded and may cause operands to be fetched from memory.",
        "After the instruction has been executed on the operands, results may be stored back in memory."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_1_1",
      "title": "8.1.1 Basic Hardware",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 2,
      "definition": "Main memory and the registers built into the processor itself are the only general-purpose storage that the CPU can access directly.",
      "key_points": [
        "In such cases, the processor normally needs to stall, since it does not have the data required to complete the instruction that it is executing.",
        "For proper system operation we must protect the operating system from access by user processes.",
        "On multiuser systems, we must additionally protect user processes from one another.",
        "We \ufb01rst need to make sure that each process has a separate memory space.",
        "Separate per-process memory space protects the processes from each other and is fundamental to having multiple processes loaded in memory for concurrent execution."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_1_2",
      "title": "8.1.2 Address Binding",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 4,
      "definition": "Usually, a program resides on a disk as a binary executable \ufb01le.",
      "key_points": [
        "To be executed, the program must be brought into memory and placed within a process.",
        "Depending on the memory management in use, the process may be moved between disk and memory during its execution.",
        "The processes on the disk that are waiting to be brought into memory for execution form the input queue.",
        "The normal single-tasking procedure is to select one of the processes in the input queue and to load that process into memory.",
        "As the process is executed, it accesses instructions and data from memory."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_1_3",
      "title": "8.1.3 Logical Versus Physical Address Space",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 5,
      "definition": "An address generated by the CPU is commonly referred to as a logical address, whereas an address seen by the memory unit\u2014that is, the one loaded into the memory-address register of the memory\u2014is commonly referred to as a physical address.",
      "key_points": [
        "The compile-time and load-time address-binding methods generate iden- tical logical and physical addresses.",
        "However, the execution-time address-"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_1_4",
      "title": "8.1.4 Dynamic Loading",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 7,
      "definition": "In our discussion so far, it has been necessary for the entire program and all data of a process to be in physical memory for the process to execute.",
      "key_points": [
        "The size of a process has thus been limited to the size of physical memory.",
        "The advantage of dynamic loading is that a routine is loaded only when it is needed.",
        "It is the responsibility of the users to design their programs to take advantage of such a method."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_1_5",
      "title": "8.1.5 Dynamic Linking and Shared Libraries",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 7,
      "definition": "Dynamically linked libraries are system libraries that are linked to user programs when the programs are run (refer back to Figure 8.3).",
      "key_points": [
        "This feature is usually used with system libraries, such as language subroutine libraries.",
        "Under this scheme, all processes that use a language library execute only one copy of the library code.",
        "This feature can be extended to library updates (such as bug \ufb01xes)."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_2",
      "title": "8.2 Swapping",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 8,
      "definition": "A process must be in memory to be executed.",
      "key_points": [
        "A process, however, can be swapped temporarily out of memory to a backing store and then brought back into memory for continued execution (Figure 8.5).",
        "Swapping makes it possible for the total physical address space of all processes to exceed the real physical memory of the system, thus increasing the degree of multiprogramming in a system."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_2_1",
      "title": "8.2.1 Standard Swapping",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 8,
      "definition": "Standard swapping involves moving processes between main memory and a backing store.",
      "key_points": [
        "It must be large operating system swap out swap in user space main memory backing store process P2 process P1 2 Figure 8.5 Swapping of two processes using a disk as a backing store.",
        "The backing store is commonly a fast disk."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_2_2",
      "title": "8.2.2 Swapping on Mobile Systems",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 10,
      "definition": "Although most operating systems for PCs and servers support some modi\ufb01ed version of swapping, mobile systems typically do not support swapping in any form.",
      "key_points": [
        "It may terminate a process if insuf\ufb01cient free memory is available.",
        "However, before terminating a process, Android writes its application state to \ufb02ash memory so that it can be quickly restarted.",
        "Note that both iOS and Android support paging, so they do have memory-management abilities."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_3",
      "title": "8.3 Contiguous Memory Allocation",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 10,
      "definition": "The main memory must accommodate both the operating system and the various user processes.",
      "key_points": [
        "The memory is usually divided into two partitions: one for the resident operating system and one for the user processes.",
        "We therefore need to allocate main memory in the most ef\ufb01cient way possible.",
        "This section explains one early method, contiguous memory allocation.",
        "We can place the operating system in either low memory or high memory.",
        "The major factor affecting this decision is the location of the interrupt vector."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_3_1",
      "title": "8.3.1 Memory Protection",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 11,
      "definition": "Before discussing memory allocation further, we must discuss the issue of memory protection.",
      "key_points": [
        "We can prevent a process from accessing memory it does not own by combining two ideas previously discussed.",
        "When the CPU scheduler selects a process for execution, the dispatcher loads the relocation and limit registers with the correct values as part of the context switch.",
        "Because every address generated by a CPU is checked against these registers, we can protect both the operating system and the other users\u2019 programs and data from being modi\ufb01ed by this running process."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_3_2",
      "title": "8.3.2 Memory Allocation",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 12,
      "definition": "Now we are ready to turn to memory allocation.",
      "key_points": [
        "Each partition may contain exactly one process.",
        "In this multiple- partition method, when a partition is free, a process is selected from the input queue and is loaded into the free partition.",
        "When the process terminates, the partition becomes available for another process.",
        "Initially, all memory is available for user processes and is considered one large block of available memory, a hole.",
        "As processes enter the system, they are put into an input queue."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_3_3",
      "title": "8.3.3 Fragmentation",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 13,
      "definition": "Both the \ufb01rst-\ufb01t and best-\ufb01t strategies for memory allocation suffer from external fragmentation.",
      "key_points": [
        "As processes are loaded and removed from memory, the free memory space is broken into little pieces.",
        "In the worst case, we could have a block of free (or wasted) memory between every two processes.",
        "If all these small pieces of memory were in one big free block instead, we might be able to run several more processes.",
        "Depending on the total amount of memory storage and the average process size, external fragmentation may be a minor or a major problem.",
        "Suppose that the next process requests 18,462 bytes."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_4",
      "title": "8.4 Segmentation",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 14,
      "definition": "As we\u2019ve already seen, the user\u2019s view of memory is not the same as the actual physical memory.",
      "key_points": [
        "This is equally true of the programmer\u2019s view of memory.",
        "Indeed, dealing with memory in terms of its physical properties is inconvenient to both the operating system and the programmer.",
        "What if the hardware could provide a memory mechanism that mapped the programmer\u2019s view to the actual physical memory?",
        "The system would have more freedom to manage memory, while the programmer would have a more natural programming environment.",
        "Segmentation provides such a mechanism."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_4_1",
      "title": "8.4.1 Basic Method",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 14,
      "definition": "Do programmers think of memory as a linear array of bytes, some containing instructions and others containing data?",
      "key_points": [
        "Most programmers would say \u201cno.\u201d Rather, they prefer to view memory as a collection of variable-sized segments, with no necessary ordering among the segments (Figure 8.7).",
        "When writing a program, a programmer thinks of it as a main program with a set of methods, procedures, or functions.",
        "It may also include various data structures: objects, arrays, stacks, variables, and so on.",
        "Each of these modules or data elements is referred to by name.",
        "The programmer talks about \u201cthe stack,\u201d \u201cthe math library,\u201d and \u201cthe main program\u201d without caring what addresses in memory these elements occupy."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_4_2",
      "title": "8.4.2 Segmentation Hardware",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 15,
      "definition": "Although the programmer can now refer to objects in the program by a two-dimensional address, the actual physical memory is still, of course, a one- dimensional sequence of bytes.",
      "key_points": [
        "Thus, we must de\ufb01ne an implementation to map two-dimensional user-de\ufb01ned addresses into one-dimensional physical"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_5",
      "title": "8.5 Paging",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 16,
      "definition": "Segmentation permits the physical address space of a process to be non- contiguous.",
      "key_points": [
        "Paging is another memory-management scheme that offers this advantage.",
        "However, paging avoids external fragmentation and the need for"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_5_1",
      "title": "8.5.1 Basic Method",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 17,
      "definition": "The basic method for implementing paging involves breaking physical mem- ory into \ufb01xed-sized blocks called frames and breaking logical memory into blocks of the same size called pages.",
      "key_points": [
        "When a process is to be executed, its pages are loaded into any available memory frames from their source (a \ufb01le system or the backing store).",
        "For example, the logical address space is now totally separate from the physical address space, so a process can have a logical 64-bit address space even though the system has less than 264 bytes of physical memory.",
        "The backing store is divided into \ufb01xed-sized blocks that are the same size as the memory frames or clusters of multiple frames.",
        "This rather simple idea has great functionality and wide rami\ufb01cations.",
        "The hardware support for paging is illustrated in Figure 8.10."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_5_2",
      "title": "8.5.2 Hardware Support",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 22,
      "definition": "Each operating system has its own methods for storing page tables.",
      "key_points": [
        "Some allocate a page table for each process.",
        "A pointer to the page table is stored with the other register values (like the instruction counter) in the process control block.",
        "When the dispatcher is told to start a process, it must reload the user registers and de\ufb01ne the correct hardware page-table values from the stored user page table.",
        "Other operating systems provide one or at most a few page tables, which decreases the overhead involved when processes are context-switched."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_5_3",
      "title": "8.5.3 Protection",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 25,
      "definition": "Memory protection in a paged environment is accomplished by protection bits associated with each frame.",
      "key_points": [
        "When this bit is set to valid, the associated page is in the process\u2019s logical address space and is thus a legal (or valid) page.",
        "When the bit is set toinvalid, the page is not in the process\u2019s logical address space.",
        "Normally, these bits are kept in the page table.",
        "One bit can de\ufb01ne a page to be read\u2013write or read-only.",
        "Every reference to memory goes through the page table to \ufb01nd the correct frame number."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_5_4",
      "title": "8.5.4 Shared Pages",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 26,
      "definition": "If the text editor consists of 150 KB of code and 50 KB of data space, we need 8,000 KB to support the 40 users.",
      "key_points": [
        "An advantage of paging is the possibility of sharing common code.",
        "This con- sideration is particularly important in a time-sharing environment.",
        "Here, we see three processes sharing a three-page editor\u2014each page 50 KB in size (the large page size is used to simplify the \ufb01gure).",
        "Each process has its own data page.",
        "Thus, two or more processes can execute the same code at the same time."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_6",
      "title": "8.6 Structure of the Page Table",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 28,
      "definition": "In this section, we explore some of the most common techniques for structuring the page table, including hierarchical paging, hashed page tables, and inverted page tables.",
      "key_points": []
    },
    {
      "id": "CHAP_07_SUB_8_6_1",
      "title": "8.6.1 Hierarchical Paging",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 28,
      "definition": "Assuming that each entry consists of 4 bytes, each process may need up to 4 MB of physical address space for the page table alone.",
      "key_points": [
        "In such an environment, the page table itself becomes excessively large.",
        "For example, consider a system with a 32-bit logical address space.",
        "If the page size in such a system is 4 KB (212), then a page table may consist of up to 1 million entries (232/212).",
        "Clearly, we would not want to allocate the page table contiguously in main memory.",
        "One simple solution to this problem is to divide the page table into smaller pieces."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_6_2",
      "title": "8.6.2 Hashed Page Tables",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 30,
      "definition": "Each element consists of three \ufb01elds: (1) the virtual page number, (2) the value of the mapped page frame, and (3) a pointer to the next element in the linked list.",
      "key_points": [
        "Each entry in the hash table contains a linked list of elements that hash to the same location (to handle collisions).",
        "The algorithm works as follows: The virtual page number in the virtual address is hashed into the hash table.",
        "The virtual page number is compared with \ufb01eld 1 in the \ufb01rst element in the linked list.",
        "If there is a match, the corresponding page frame (\ufb01eld 2) is used to form the desired physical address.",
        "If there is no match, subsequent entries in the linked list are searched for a matching virtual page number."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_6_3",
      "title": "8.6.3 Inverted Page Tables",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 31,
      "definition": "This table representation is a natural one, since processes reference pages through the pages\u2019 virtual addresses.",
      "key_points": [
        "Usually, each process has an associated page table.",
        "The page table has one entry for each page that the process is using (or one slot for each virtual address, regardless of the latter\u2019s validity).",
        "Each entry consists of the virtual address of the page stored in that real memory location, with information about the process that owns the page.",
        "Storing the address-space identi\ufb01er ensures that a logical page for a particular process is mapped to the corresponding physical page frame."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_6_4",
      "title": "8.6.4 Oracle SPARC Solaris",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 33,
      "definition": "Solaris running on the SPARC CPU is a fully 64-bit operating system and as such has to solve the problem of virtual memory without using up all of its physical memory by keeping multiple levels of page tables.",
      "key_points": [
        "There are two hash tables\u2014one for the kernel and one for all user processes.",
        "Its approach is a bit complex but solves the problem ef\ufb01ciently using hashed page tables.",
        "Each maps memory addresses from virtual to physical memory.",
        "Each hash-table entry represents a contiguous area of mapped virtual memory, which is more ef\ufb01cient than having a separate hash-table entry for each page.",
        "Each entry has a base address and a span indicating the number of pages the entry represents."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_7",
      "title": "8.7 Example: Intel 32 and 64-bit Architectures",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 33,
      "definition": "The architecture of Intel chips has dominated the personal computer landscape for several years.",
      "key_points": [
        "Intel later produced a series of 32-bit chips \u2014the IA-32\u2014which included the family of 32-bit Pentium processors.",
        "The 16-bit Intel 8086 appeared in the late 1970s and was soon followed by another 16-bit chip\u2014the Intel 8088\u2014which was notable for being the chip used in the original IBM PC.",
        "Both the 8086 chip and the 8088 chip were based on a segmented architecture.",
        "The IA-32 architecture supported both paging and segmentation.",
        "More recently, Intel has produced a series of 64-bit chips based on the x86-64 architecture."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_7_1",
      "title": "8.7.1 IA-32 Architecture",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 34,
      "definition": "Memory management in IA-32 systems is divided into two components\u2014 segmentation and paging\u2014and works as follows: The CPU generates logical addresses, which are given to the segmentation unit.",
      "key_points": [
        "8.7.1.1 IA-32 Segmentation The IA-32 architecture allows a segment to be as large as 4 GB, and the maximum number of segments per process is 16 K.",
        "The logical address space of a process is divided into two partitions.",
        "The \ufb01rst partition consists of up to 8 Ksegments that are private to that process.",
        "The second partition consists of up to 8 K segments that are shared among all the processes.",
        "The machine has six segment registers, allowing six segments to be addressed at any one time by a process."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_8",
      "title": "8.8 Example: ARM Architecture",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 38,
      "definition": "Although Intel chips have dominated the personal computer market for over 30 years, chips for mobile devices such as smartphones and tablet computers often instead run on 32-bit ARM processors.",
      "key_points": [
        "Apple has licensed the ARM design for its iPhone and iPad mobile devices, and several Android-based smartphones use ARM processors as well.",
        "Interestingly, whereas Intel both designs and manufactures chips, ARM only designs them.",
        "It then licenses its designs to chip manufacturers.",
        "The 32-bit ARM architecture supports the following page sizes: 1.",
        "4-KB and 16-KB pages 2."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_9",
      "title": "8.9 Summary",
      "label": "Topic",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 39,
      "definition": "Memory-management algorithms for multiprogrammed operating systems range from the simple single-user system approach to segmentation and paging.",
      "key_points": [
        "The most important determinant of the method used in a particular system is the hardware provided.",
        "For a given set of processes, we can increase the multiprogramming level only by packing more processes into memory.",
        "At intervals deter- mined by the operating system, usually dictated by CPU-scheduling poli- cies, processes are copied from main memory to a backing store and later are copied back to main memory.",
        "This scheme allows more processes to be run than can be \ufb01t into memory at one time.",
        "Another means of increasing the multiprogramming level is to share code and data among different processes."
      ]
    },
    {
      "id": "CHAP_07_SUB_8_1",
      "title": "8.1 Name two differences between logical and physical addresses.",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 40,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_2",
      "title": "8.2 Consider a system in which a program can be separated into two",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 40,
      "definition": "parts: code and data. The CPU knows whether it wants an instruction (instruction fetch) or data (data fetch or store). Therefore, two base\u2013 limit register pairs are provided: one for instructions and one for data. The instruction base\u2013limit register pair is automatically read-only, so programs can be shared among different users. Discuss the advantages and disadvantages of this scheme.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_3",
      "title": "8.3 Why are page sizes always powers of 2?",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 40,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_4",
      "title": "8.4 Consider a logical address space of 64 pages of 1,024 words each, mapped",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 40,
      "definition": "onto a physical memory of 32 frames. a. How many bits are there in the logical address? b. How many bits are there in the physical address?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_5",
      "title": "8.5 What is the effect of allowing two entries in a page table to point to the",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 40,
      "definition": "same page frame in memory? Explain how this effect could be used to decrease the amount of time needed to copy a large amount of memory from one place to another. What effect would updating some byte on the one page have on the other page?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_6",
      "title": "8.6 Describe a mechanism by which one segment could belong to the address",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 40,
      "definition": "space of two different processes.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_7",
      "title": "8.7 Sharing segments among processes without requiring that they have the",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 40,
      "definition": "same segment number is possible in a dynamically linked segmentation system. a. De\ufb01ne a system that allows static linking and sharing of segments without requiring that the segment numbers be the same. b. Describe a paging scheme that allows pages to be shared without requiring that the page numbers be the same.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_8",
      "title": "8.8 In the IBM/370, memory protection is provided through the use of keys.",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 40,
      "definition": "A key is a 4-bit quantity. Each 2-K block of memory has a key (the storage key) associated with it. The CPU also has a key (the protection key) associated with it. A store operation is allowed only if both keys",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_9",
      "title": "8.9 Explain the difference between internal and external fragmentation.",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 41,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_10",
      "title": "8.10 Consider the following process for generating binaries. A compiler is",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 41,
      "definition": "used to generate the object code for individual modules, and a linkage editor is used to combine multiple object modules into a single program binary. How does the linkage editor change the binding of instructions and data to memory addresses? What information needs to be passed from the compiler to the linkage editor to facilitate the memory-binding tasks of the linkage editor?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_11",
      "title": "8.11 Given six memory partitions of 300 KB, 600 KB, 350 KB, 200 KB, 750 KB,",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 41,
      "definition": "and 125 KB (in order), how would the \ufb01rst-\ufb01t, best-\ufb01t, and worst-\ufb01t algorithms place processes of size 115 KB, 500 KB, 358 KB, 200 KB, and KB (in order)? Rank the algorithms in terms of how ef\ufb01ciently they use memory.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_12",
      "title": "8.12 Most systems allow a program to allocate more memory to its address",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 41,
      "definition": "space during execution. Allocation of data in the heap segments of programs is an example of such allocated memory. What is required to support dynamic memory allocation in the following schemes? a. Contiguous memory allocation b. Pure segmentation c. Pure paging",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_13",
      "title": "8.13 Compare the memory organization schemes of contiguous memory",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 41,
      "definition": "allocation, pure segmentation, and pure paging with respect to the following issues: a. External fragmentation b. Internal fragmentation c. Ability to share code across processes",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_14",
      "title": "8.14 On a system with paging, a process cannot access memory that it does",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 41,
      "definition": "not own. Why? How could the operating system allow access to other memory? Why should it or should it not?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_15",
      "title": "8.15 Explain why mobile operating systems such as iOS and Android do not",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 42,
      "definition": "support swapping.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_16",
      "title": "8.16 Although Android does not support swapping on its boot disk, it is",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 42,
      "definition": "possible to set up a swap space using a separate SD nonvolatile memory card. Why would Android disallow swapping on its boot disk yet allow it on a secondary disk?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_17",
      "title": "8.17 Compare paging with segmentation with respect to how much memory",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 42,
      "definition": "the address translation structures require to convert virtual addresses to physical addresses.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_18",
      "title": "8.18 Explain why address space identi\ufb01ers (ASIDs) are used.",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 42,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_19",
      "title": "8.19 Program binaries in many systems are typically structured as follows.",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 42,
      "definition": "Code is stored starting with a small, \ufb01xed virtual address, such as 0. The code segment is followed by the data segment that is used for storing the program variables. When the program starts executing, the stack is allocated at the other end of the virtual address space and is allowed to grow toward lower virtual addresses. What is the signi\ufb01cance of this structure for the following schemes? a. Contiguous memory allocation b. Pure segmentation c. Pure paging",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_20",
      "title": "8.20 Assuming a 1-KB page size, what are the page numbers and offsets for",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 42,
      "definition": "the following address references (provided as decimal numbers): a. b. c. d. e. 2000001",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_21",
      "title": "8.21 The BTV operating system has a 21-bit virtual address, yet on certain",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 42,
      "definition": "embedded devices, it has only a 16-bit physical address. It also has a 2-KB page size. How many entries are there in each of the following? a. A conventional, single-level page table b. An inverted page table",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_22",
      "title": "8.22 What is the maximum amount of physical memory?",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 42,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_23",
      "title": "8.23 Consider a logical address space of 256 pages with a 4-KB page size,",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 42,
      "definition": "mapped onto a physical memory of 64 frames. a. How many bits are required in the logical address? b. How many bits are required in the physical address?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_24",
      "title": "8.24 Consider a computer system with a 32-bit logical address and 4-KB page",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 43,
      "definition": "size. The system supports up to 512 MB of physical memory. How many entries are there in each of the following?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_25",
      "title": "8.25 Consider a paging system with the page table stored in memory.",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 43,
      "definition": "a. If a memory reference takes 50 nanoseconds, how long does a paged memory reference take? b. If we add TLBs, and 75 percent of all page-table references are found in the TLBs, what is the effective memory reference time? (Assume that \ufb01nding a page-table entry in the TLBs takes 2 nanoseconds, if the entry is present.)",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_26",
      "title": "8.26 Why are segmentation and paging sometimes combined into one",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 43,
      "definition": "scheme?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_27",
      "title": "8.27 Explain why sharing a reentrant module is easier when segmentation is",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 43,
      "definition": "used than when pure paging is used.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_28",
      "title": "8.28 Consider the following segment table:",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 43,
      "definition": "Segment Base Length 219 1 14 90 3 580 1952 What are the physical addresses for the following logical addresses? a. 0,430 b. 1,10 c. 2,500 d. 3,400 e. 4,112",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_29",
      "title": "8.29 What is the purpose of paging the page tables?",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 43,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_30",
      "title": "8.30 Consider the hierarchical paging scheme used by the VAX architecture.",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 43,
      "definition": "How many memory operations are performed when a user program executes a memory-load operation?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_31",
      "title": "8.31 Compare the segmented paging scheme with the hashed page table",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 43,
      "definition": "scheme for handling large address spaces. Under what circumstances is one scheme preferable to the other?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_32",
      "title": "8.32 Consider the Intel address-translation scheme shown in Figure 8.22.",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 43,
      "definition": "a. Describe all the steps taken by the Intel Pentium in translating a logical address into a physical address. b. What are the advantages to the operating system of hardware that provides such complicated memory translation?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07_SUB_8_33",
      "title": "8.33 Assume that a system has a 32-bit virtual address with a 4-KB page size.",
      "label": "Exercise",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 44,
      "definition": "Write a C program that is passed a virtual address (in decimal) on the command line and have it output the page number and offset for the given address. As an example, your program would run as follows: ./a.out 19986 Your program would output: The address 19986 contains: page number = 4 offset = 3602 Writing this program will require using the appropriate data type to store 32 bits. We encourage you to use unsigned data types as well. Bibliographical Notes Dynamic storage allocation was discusse",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_07",
      "title": "Chapter 8 Main Memory",
      "label": "Chapter",
      "file_source": "08_Chapter 8 Main Memory.pdf",
      "page": 1,
      "definition": "8 C H A P T E R Main Memory In Chapter 6, we showed how the CPU can be shared by a set of processes.",
      "key_points": [
        "To realize this increase in performance, however, we must keep several processes in memory\u2014that is, we must share memory.",
        "Each approach has its own advantages and disadvantages.",
        "\u2022 To explore various techniques of allocating memory to processes.",
        "8.1 Background: Memory consists of a large array of bytes, each with its own address....",
        "8.1.1 Basic Hardware: Main memory and the registers built into the processor itself are the only gener...",
        "8.1.2 Address Binding: Usually, a program resides on a disk as a binary executable \ufb01le....",
        "8.1.3 Logical Versus Physical Address Space: An address generated by the CPU is commonly referred to as a logical address, wh...",
        "8.1.4 Dynamic Loading: In our discussion so far, it has been necessary for the entire program and all d..."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_1",
      "title": "9.1 Background",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 1,
      "definition": "The memory-management algorithms outlined in Chapter 8 are necessary because of one basic requirement: The instructions being executed must be",
      "key_points": []
    },
    {
      "id": "CHAP_08_SUB_9_2",
      "title": "9.2 Demand Paging",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 5,
      "definition": "Consider how an executable program might be loaded from disk into memory.",
      "key_points": [
        "A demand-paging system is similar to a paging system with swapping (Figure 9.4) where processes reside in secondary memory (usually a disk).",
        "When we want to execute a process, we swap it into memory.",
        "Rather than swapping the entire process into memory, though, we use a lazy swapper.",
        "A swapper manipulates entire processes, whereas a pager is concerned with the individual pages of a process."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_2_1",
      "title": "9.2.1 Basic Concepts",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 6,
      "definition": "When a process is to be swapped in, the pager guesses which pages will be used before the process is swapped out again.",
      "key_points": [
        "Instead of swapping in a whole process, the pager brings only those pages into memory.",
        "If the bit is set to \u201cinvalid,\u201d the page either is not valid (that is, not in the logical address space of the process) or is valid but is currently on the disk.",
        "This situation is depicted in Figure 9.5. Notice that marking a page invalid will have no effect if the process never attempts to access that page.",
        "Hence, if we guess right and page in all pages that are actually needed and only those pages, the process will run exactly as though we had brought in all pages.",
        "While the process executes and accesses pages that are memory resident, execution proceeds normally."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_2_2",
      "title": "9.2.2 Performance of Demand Paging",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 9,
      "definition": "Demand paging can signi\ufb01cantly affect the performance of a computer system.",
      "key_points": [
        "For most computer systems, the memory-access time, denoted ma, ranges from 10 to 200 nanoseconds.",
        "Save the user registers and process state.",
        "To see why, let\u2019s compute the effective access time for a demand-paged memory.",
        "As long as we have no page faults, the effective access time is equal to the memory access time.",
        "If, however, a page fault occurs, we must \ufb01rst read the relevant page from disk and then access the desired word."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_3",
      "title": "9.3 Copy-on-Write",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 12,
      "definition": "Recall that the fork() system call creates a child process that is a duplicate of its parent.",
      "key_points": [
        "In Section 9.2, we illustrated how a process can start quickly by demand-paging in the page containing the \ufb01rst instruction.",
        "However, process creation using the fork() system call may initially bypass the need for demand paging by using a technique similar to page sharing (covered in Section 8.5.4).",
        "This technique provides rapid process creation and minimizes the number of new pages that must be allocated to the newly created process.",
        "However, considering that many child processes invoke the exec() system call immediately after creation, the copying of the parent\u2019s address space may be unnecessary.",
        "Instead, we can use a technique known as copy-on-write, which works by allowing the parent and child processes initially to share the same pages."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_4",
      "title": "9.4 Page Replacement",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 13,
      "definition": "In our earlier discussion of the page-fault rate, we assumed that each page faults at most once, when it is \ufb01rst referenced.",
      "key_points": [
        "If a process of ten pages actually uses only half of them, then demand paging saves the I/O necessary to load the \ufb01ve pages that are never used.",
        "We could also increase our degree of multiprogramming by running twice as many processes.",
        "Thus, if we had forty frames, we could run eight processes, rather than the four that could run if each required ten frames (\ufb01ve of which were never used).",
        "If we run six processes, each of which is ten pages in size but actually uses only \ufb01ve pages, we have higher CPU utilization and throughput, with ten frames to spare.",
        "It is possible, however, that each of these processes, for a particular data set, may suddenly try to use all ten of its pages, resulting in a need for sixty frames when only forty are available."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_4_1",
      "title": "9.4.1 Basic Page Replacement",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 14,
      "definition": "Page replacement takes the following approach.",
      "key_points": [
        "We can now use the freed frame to hold the page for which the process faulted.",
        "If no frame is free, we \ufb01nd one that is not currently being used and free it.",
        "We can free a frame by writing its contents to swap space and changing the page table (and all other tables) to indicate that the page is no longer in memory (Figure 9.10).",
        "We modify the page-fault service routine to include page replacement:"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_4_2",
      "title": "9.4.2 FIFO Page Replacement",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 17,
      "definition": "The simplest page-replacement algorithm is a \ufb01rst-in, \ufb01rst-out (FIFO) algorithm.",
      "key_points": [
        "A FIFO replacement algorithm associates with each page the time when that page was brought into memory.",
        "When a page must be replaced, the oldest page is chosen.",
        "Notice that it is not strictly necessary to record the time when a page is brought in.",
        "We can create a FIFO queue to hold all pages in memory.",
        "We replace the page at the head of the queue."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_4_3",
      "title": "9.4.3 Optimal Page Replacement",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 18,
      "definition": "One result of the discovery of Belady\u2019s anomaly was the search for an optimal page-replacement algorithm\u2014the algorithm that has the lowest page-fault rate of all algorithms and will never suffer from Belady\u2019s anomaly.",
      "key_points": [
        "Such an algorithm does exist and has been called OPT or MIN.",
        "It is simply this: Replace the page that will not be used for the longest period of time.",
        "Use of this page-replacement algorithm guarantees the lowest possible page- fault rate for a \ufb01xed number of frames."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_4_4",
      "title": "9.4.4 LRU Page Replacement",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 20,
      "definition": "If the optimal algorithm is not feasible, perhaps an approximation of the optimal algorithm is possible.",
      "key_points": [
        "The key distinction between the FIFO and OPT algorithms (other than looking backward versus forward in time) is that the FIFO algorithm uses the time when a page was brought into memory, whereas the OPT algorithm uses the time when a page is to be used.",
        "If we use the recent past as an approximation of the near future, then we can replace the page that has not been used for the longest period of time.",
        "This approach is the least recently used (LRU) algorithm.",
        "LRU replacement associates with each page the time of that page\u2019s last use.",
        "When a page must be replaced, LRU chooses the page that has not been used for the longest period of time."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_4_5",
      "title": "9.4.5 LRU-Approximation Page Replacement",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 22,
      "definition": "Few computer systems provide suf\ufb01cient hardware support for true LRU page replacement.",
      "key_points": [
        "As a user process executes, the bit associated with each page referenced is set (to 1) by the hardware.",
        "9.4.5.1 Additional-Reference-Bits Algorithm We can gain additional ordering information by recording the reference bits at regular intervals.",
        "9.4.5.2 Second-Chance Algorithm The basic algorithm of second-chance replacement is a FIFO replacement algorithm."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_4_6",
      "title": "9.4.6 Counting-Based Page Replacement",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 24,
      "definition": "There are many other algorithms that can be used for page replacement.",
      "key_points": [
        "A problem arises, however, when a page is used heavily during the initial phase of a process but then is never used again.",
        "For example, we can keep a counter of the number of references that have been made to each page and develop the following two schemes.",
        "\u2022 The least frequently used (LFU) page-replacement algorithm requires that the page with the smallest count be replaced.",
        "The reason for this selection is that an actively used page should have a large reference count.",
        "Since it was used heavily, it has a large count and remains in memory even though it is no longer needed."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_4_7",
      "title": "9.4.7 Page-Buffering Algorithms",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 24,
      "definition": "Other procedures are often used in addition to a speci\ufb01c page-replacement algorithm.",
      "key_points": [
        "This procedure allows the process to restart as soon as possible, without waiting for the victim page to be written out.",
        "For example, systems commonly keep a pool of free frames.",
        "When a page fault occurs, a victim frame is chosen as before.",
        "However, the desired page is read into a free frame from the pool before the victim is written out.",
        "When the victim is later written out, its frame is added to the free-frame pool."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_4_8",
      "title": "9.4.8 Applications and Page Replacement",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 25,
      "definition": "A typical example is a database, which provides its own memory management and I/O buffering.",
      "key_points": [
        "Note that although certain applications are more ef\ufb01cient when implementing their own special-purpose storage services on a raw partition, most applications perform better when they use the regular \ufb01le-system services.",
        "Applications like this understand their memory use and disk use better than does an operating system that is implementing algorithms for general-purpose use.",
        "If the operating system is buffering I/O and the application is doing so as well, however, then twice the memory is being used for a set of I/O.",
        "In another example, data warehouses frequently perform massive sequen- tial disk reads, followed by computations and writes.",
        "The LRU algorithm would be removing old pages and preserving new ones, while the application would more likely be reading older pages than newer ones (as it starts its sequential reads again)."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_5",
      "title": "9.5 Allocation of Frames",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 25,
      "definition": "We turn next to the issue of allocation.",
      "key_points": [
        "How do we allocate the \ufb01xed amount of free memory among the various processes?",
        "If we have 93 free frames and two processes, how many frames does each process get?",
        "The simplest case is the single-user system.",
        "Consider a single-user system with 128 KB of memory composed of pages 1 KB in size."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_5_1",
      "title": "9.5.1 Minimum Number of Frames",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 26,
      "definition": "Our strategies for the allocation of frames are constrained in various ways.",
      "key_points": [
        "Obviously, as the number of frames allocated to each process decreases, the page-fault rate increases, slowing process execution.",
        "In addition, if one-level indirect addressing is allowed (for example, a load instruction on page 16 can refer to an address on page 0, which is an indirect reference to page 23), then paging requires at least three frames per process.",
        "Think about what might happen if a process had only two frames."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_5_2",
      "title": "9.5.2 Allocation Algorithms",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 27,
      "definition": "The easiest way to split m frames among n processes is to give everyone an equal share, m/n frames (ignoring frames needed by the operating system for the moment).",
      "key_points": [
        "For instance, if there are 93 frames and \ufb01ve processes, each process will get 18 frames.",
        "An alternative is to recognize that various processes will need differing amounts of memory.",
        "If a small student process of 10 KB and an interactive database of 127 KB are the only two processes running in a system with 62 free frames, it does not make much sense to give each process 31 frames.",
        "The student process does not need more than 10 frames, so the other 21 are, strictly speaking, wasted.",
        "To solve this problem, we can use proportional allocation, in which we allocate available memory to each process according to its size."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_5_3",
      "title": "9.5.3 Global versus Local Allocation",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 28,
      "definition": "Another important factor in the way frames are allocated to the various processes is page replacement.",
      "key_points": [
        "With multiple processes competing for frames, we can classify page-replacement algorithms into two broad categories: global replacement and local replacement.",
        "Global replacement allows a process to select a replacement frame from the set of all frames, even if that frame is currently allocated to some other process; that is, one process can take a frame from another.",
        "Local replacement requires that each process select from only its own set of allocated frames.",
        "For example, consider an allocation scheme wherein we allow high-priority processes to select frames from low-priority processes for replacement.",
        "A process can select a replacement from among its own frames or the frames of any lower-priority process."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_5_4",
      "title": "9.5.4 Non-Uniform Memory Access",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 28,
      "definition": "Thus far in our coverage of virtual memory, we have assumed that all main memory is created equal\u2014or at least that it is accessed equally.",
      "key_points": []
    },
    {
      "id": "CHAP_08_SUB_9_6",
      "title": "9.6 Thrashing",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 29,
      "definition": "If the number of frames allocated to a low-priority process falls below the minimum number required by the computer architecture, we must suspend that process\u2019s execution.",
      "key_points": [
        "In fact, look at any process that does not have \u201cenough\u201d frames.",
        "If the process does not have the number of frames it needs to support pages in active use, it will quickly page-fault.",
        "We should then page out its remaining pages, freeing all its allocated frames.",
        "This provision introduces a swap-in, swap-out level of intermediate CPU scheduling.",
        "At this point, it must replace some page."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_6_1",
      "title": "9.6.1 Cause of Thrashing",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 30,
      "definition": "Thrashing results in severe performance problems.",
      "key_points": [
        "If CPU utilization is too low, we increase the degree of multiprogramming by introducing a new process to the system.",
        "A global page-replacement algorithm is used; it replaces pages without regard to the process to which they belong.",
        "Now suppose that a process enters a new phase in its execution and needs more frames.",
        "It starts faulting and taking frames away from other processes.",
        "These processes need those pages, however, and so they also fault, taking frames from other processes."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_6_2",
      "title": "9.6.2 Working-Set Model",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 31,
      "definition": "As mentioned, the working-set model is based on the assumption of locality.",
      "key_points": [
        "In the extreme, if ! is in\ufb01nite, the working set is the set of pages touched during the process execution.",
        "This model uses a parameter, !, to de\ufb01ne the working-set window.",
        "The idea is to examine the most recent ! page references.",
        "The set of pages in the most recent ! page references is the working set (Figure 9.20).",
        "If a page is in active use, it will be in the working set."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_6_3",
      "title": "9.6.3 Page-Fault Frequency",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 33,
      "definition": "The working-set model is successful, and knowledge of the working set can be useful for prepaging (Section 9.9.1), but it seems a clumsy way to control thrashing.",
      "key_points": [
        "When it is too high, we know that the process needs more frames.",
        "Conversely, if the page-fault rate is too low, then the process may have too many frames.",
        "If the actual page-fault rate exceeds the upper limit, we allocate the process another"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_6_4",
      "title": "9.6.4 Concluding Remarks",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 34,
      "definition": "Practically speaking, thrashing and the resulting swapping have a disagreeably large impact on performance.",
      "key_points": [
        "The current best practice in implementing a computer facility is to include enough physical memory, whenever possible, to avoid thrashing and swapping.",
        "From smartphones through mainframes, providing enough memory to keep all working sets in memory concurrently, except under extreme conditions, gives the best user experience."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_7",
      "title": "9.7 Memory-Mapped Files",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 34,
      "definition": "Consider a sequential read of a \ufb01le on disk using the standard system calls open(), read(), and write().",
      "key_points": [
        "Each \ufb01le access requires a system call and disk access.",
        "Alternatively, we can use the virtual memory techniques discussed so far to treat \ufb01le I/O as routine memory accesses.",
        "This approach, known as memory mapping a \ufb01le, allows a part of the virtual address space to be logically associated with the \ufb01le.",
        "As we shall see, this can lead to signi\ufb01cant performance increases."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_7_1",
      "title": "9.7.1 Basic Mechanism",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 34,
      "definition": "Memory mapping a \ufb01le is accomplished by mapping a disk block to a page (or pages) in memory.",
      "key_points": [
        "Initial access to the \ufb01le proceeds through ordinary demand paging, resulting in a page fault.",
        "However, a page-sized portion of the \ufb01le is read from the \ufb01le system into a physical page (some systems may opt to read"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_7_2",
      "title": "9.7.2 Shared Memory in the Windows API",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 37,
      "definition": "The general outline for creating a region of shared memory using memory- mapped \ufb01les in the Windows API involves \ufb01rst creating a \ufb01le mapping for the \ufb01le to be mapped and then establishing a view of the mapped \ufb01le in a process\u2019s virtual address space.",
      "key_points": [
        "A second process can then open and create a view of the mapped \ufb01le in its virtual address space.",
        "The mapped \ufb01le represents the shared-memory object that will enable communication to take place between the processes.",
        "We next illustrate these steps in more detail.",
        "In this example, a producer process \ufb01rst creates a shared-memory object using the memory-mapping features available in the Windows API.",
        "After that, a consumer process opens a mapping to the shared-memory object and reads the message written by the consumer."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_7_3",
      "title": "9.7.3 Memory-Mapped I/O",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 39,
      "definition": "In the case of I/O, as mentioned in Section 1.2.1, each I/O controller includes registers to hold commands and the data being transferred.",
      "key_points": [
        "Usually, special I/O instructions allow data transfers between these registers and system memory.",
        "To allow more convenient access to I/O devices, many computer architectures provide memory-mapped I/O.",
        "In this case, ranges of memory addresses are set aside and are mapped to the device registers.",
        "Reads and writes to these memory addresses cause the data to be transferred to and from the device registers.",
        "This method is appropriate for devices that have fast response times, such as video controllers."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_8",
      "title": "9.8 Allocating Kernel Memory",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 40,
      "definition": "When a process running in user mode requests additional memory, pages are allocated from the list of free page frames maintained by the kernel.",
      "key_points": [
        "Remember, too, that if a user process requests a single byte of memory, internal fragmentation will result, as the process will be granted an entire page frame.",
        "Kernel memory is often allocated from a free-memory pool different from the list used to satisfy ordinary user-mode processes.",
        "There are two primary reasons for this: 1.",
        "This is especially important because many operating systems do not subject kernel code or data to the paging system.",
        "Pages allocated to user-mode processes do not necessarily have to be in contiguous physical memory."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_8_1",
      "title": "9.8.1 Buddy System",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 40,
      "definition": "The buddy system allocates memory from a \ufb01xed-size segment consisting of physically contiguous pages.",
      "key_points": [
        "Memory is allocated from this segment using a power-of-2 allocator, which satis\ufb01es requests in units sized as a power of 2 (4 KB, 8 KB, 16 KB, and so forth).",
        "A request in units not appropriately sized is rounded up to the next highest power of 2.",
        "For example, a request for 11 KB is satis\ufb01ed with a 16-KB segment.",
        "Let\u2019s consider a simple example.",
        "Assume the size of a memory segment is initially 256 KB and the kernel requests 21 KB of memory."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_8_2",
      "title": "9.8.2 Slab Allocation",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 41,
      "definition": "A cache consists of one or more slabs.",
      "key_points": [
        "There is a single cache for each unique kernel data structure \u2014for example, a separate cache for the data structure representing process descriptors, a separate cache for \ufb01le objects, a separate cache for semaphores, and so forth.",
        "For example, the cache representing semaphores stores instances of semaphore objects, the cache representing process descriptors stores instances of process descriptor objects, and so forth.",
        "A slab is made up of one or more physically contiguous pages.",
        "Each cache is populated with objects that are instantiations of the kernel data structure the cache represents.",
        "The relationship among slabs, caches, and objects is shown in Figure 9.27."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_9",
      "title": "9.9 Other Considerations",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 43,
      "definition": "The major decisions that we make for a paging system are the selections of a replacement algorithm and an allocation policy, which we discussed earlier in this chapter.",
      "key_points": [
        "There are many other considerations as well, and we discuss several of them here."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_9_1",
      "title": "9.9.1 Prepaging",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 43,
      "definition": "An obvious property of pure demand paging is the large number of page faults that occur when a process is started.",
      "key_points": [
        "This situation results from trying to get the initial locality into memory.",
        "The same situation may arise at other times."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_9_2",
      "title": "9.9.2 Page Size",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 44,
      "definition": "Rather, there is a set of factors that support various sizes.",
      "key_points": [
        "Because each active process must have its own copy of the page table, a large page size is desirable.",
        "If a process is allocated memory starting at location 00000 and continuing until it has as much as it needs, it probably will not end exactly on a page boundary.",
        "Assuming independence of process size and page size, we can expect that, on the average, half of the \ufb01nal page of each process will be wasted."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_9_3",
      "title": "9.9.3 TLB Reach",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 45,
      "definition": "Recall that the hit ratio for the TLB refers to the percentage of virtual address translations that are resolved in the TLB rather than the page table.",
      "key_points": [
        "Ideally, the working set for a process is stored in the TLB.",
        "If it is not, the process will spend a considerable amount of time resolving memory references in the page table rather than the TLB.",
        "Clearly, the hit ratio is related to the number of entries in the TLB, and the way to increase the hit ratio is by increasing the number of entries in the TLB.",
        "This, however, does not come cheaply, as the associative memory used to construct the TLB is both expensive and power hungry.",
        "Related to the hit ratio is a similar metric: the TLBreach."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_9_4",
      "title": "9.9.4 Inverted Page Tables",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 46,
      "definition": "Section 8.6.3 introduced the concept of the inverted page table.",
      "key_points": [
        "We accomplish this savings by creating a table that has one entry per page of physical memory, indexed by the pair <process-id, page-number>.",
        "However, the inverted page table no longer contains complete information about the logical address space of a process, and that information is required if a referenced page is not currently in memory.",
        "Demand paging requires this information to process page faults.",
        "For the information to be available, an external page table (one per process) must be kept.",
        "Each such table looks like the traditional per-process page table and contains information on where each virtual page is located."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_9_5",
      "title": "9.9.5 Program Structure",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 46,
      "definition": "Demand paging is designed to be transparent to the user program.",
      "key_points": [
        "In many cases, the user is completely unaware of the paged nature of memory."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_9_6",
      "title": "9.9.6 I/O Interlock and Page Locking",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 48,
      "definition": "When demand paging is used, we sometimes need to allow some of the pages to be locked in memory.",
      "key_points": [
        "I/O is often implemented by a separate I/O processor.",
        "We must be sure the following sequence of events does not occur: A process issues an I/O request and is put in a queue for that I/O device.",
        "Meanwhile, the CPU is given to other processes.",
        "These processes cause page faults, and one of them, using a global replacement algorithm, replaces the page containing the memory buffer for the waiting process.",
        "However, this frame is now being used for a different page belonging to another process."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_10",
      "title": "9.10 Operating-System Examples",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 49,
      "definition": "In this section, we describe how Windows and Solaris implement virtual memory.",
      "key_points": []
    },
    {
      "id": "CHAP_08_SUB_9_10_1",
      "title": "9.10.1 Windows",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 49,
      "definition": "Windows implements virtual memory using demand paging with clustering.",
      "key_points": [
        "Clustering handles page faults by bringing in not only the faulting page but also"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_10_2",
      "title": "9.10.2 Solaris",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 50,
      "definition": "Associated with this list of free pages is a parameter\u2014lotsfree\u2014that represents a threshold to begin paging.",
      "key_points": [
        "If the number of free pages falls below lotsfree, a process known as a pageout starts up.",
        "The pageout process is similar to the second-chance algorithm described in Section 9.4.5.2, except that it uses two hands while scanning pages, rather than one.",
        "The pageout process works as follows: The front hand of the clock scans all pages in memory, setting the reference bit to 0."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_11",
      "title": "9.11 Summary",
      "label": "Topic",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 52,
      "definition": "Virtual memory is a technique that enables us to map a large logical address space onto a smaller physical memory.",
      "key_points": [
        "It is desirable to be able to execute a process whose logical address space is larger than the available physical address space.",
        "Virtual memory allows us to run extremely large processes and to raise the degree of multiprogramming, increasing CPU utilization.",
        "In addition, with virtual memory, several processes can share system libraries and memory.",
        "With virtual memory, we can also use an ef\ufb01cient type of process creation known as copy-on-write, wherein parent and child processes share actual pages of memory.",
        "This approach allows a process to run even though its entire memory image is not in main memory at once."
      ]
    },
    {
      "id": "CHAP_08_SUB_9_1",
      "title": "9.1 Under what circumstances do page faults occur? Describe the actions",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 53,
      "definition": "taken by the operating system when a page fault occurs.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_2",
      "title": "9.2 Assume that you have a page-reference string for a process with m",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 53,
      "definition": "frames (initially all empty). The page-reference string has length p, and n distinct page numbers occur in it. Answer these questions for any page-replacement algorithms: a. What is a lower bound on the number of page faults? b. What is an upper bound on the number of page faults?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_3",
      "title": "9.3 Consider the page table shown in Figure 9.30 for a system with 12-bit",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 53,
      "definition": "virtual and physical addresses and with 256-byte pages. The list of free page frames is D, E, F (that is, D is at the head of the list, E is second, and F is last). Page Page Frame 1 3 5 \u2013 C A \u2013 6 7 \u2013 B 0 Figure 9.30 Page table for Exercise 9.3.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_4",
      "title": "9.4 Consider the following page-replacement algorithms. Rank these algo-",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 54,
      "definition": "rithms on a \ufb01ve-point scale from \u201cbad\u201d to \u201cperfect\u201d according to their page-fault rate. Separate those algorithms that suffer from Belady\u2019s anomaly from those that do not. a. LRU replacement b. FIFO replacement c. Optimal replacement d. Second-chance replacement",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_5",
      "title": "9.5 Discuss the hardware support required to support demand paging.",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 54,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_6",
      "title": "9.6 An operating system supports a paged virtual memory. The central",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 54,
      "definition": "processor has a cycle time of 1 microsecond. It costs an additional 1 microsecond to access a page other than the current one. Pages have 1,000 words, and the paging device is a drum that rotates at 3,000 revolutions per minute and transfers 1 million words per second. The following statistical measurements were obtained from the system: \u2022 One percent of all instructions executed accessed a page other than the current page. \u2022 Of the instructions that accessed another page, 80 percent accessed a ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_7",
      "title": "9.7 Consider the two-dimensional array A:",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 54,
      "definition": "int A[][] = new int[100][100]; where A[0][0] is at location 200 in a paged memory system with pages of size 200. A small process that manipulates the matrix resides in page (locations 0 to 199). Thus, every instruction fetch will be from page 0. For three page frames, how many page faults are generated by the following array-initialization loops? Use LRU replacement, and assume",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_8",
      "title": "9.8 Consider the following page reference string:",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 55,
      "definition": "1, 2, 3, 4, 2, 1, 5, 6, 2, 1, 2, 3, 7, 6, 3, 2, 1, 2, 3, 6. How many page faults would occur for the following replacement algorithms, assuming one, two, three, four, \ufb01ve, six, and seven frames? Remember that all frames are initially empty, so your \ufb01rst unique pages will cost one fault each. \u2022 LRU replacement \u2022 FIFO replacement \u2022 Optimal replacement",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_9",
      "title": "9.9 Suppose that youwant touse apagingalgorithmthat requiresareference",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 55,
      "definition": "bit (such as second-chance replacement or working-set model), but the hardware does not provide one. Sketch how you could simulate a reference bit even if one were not provided by the hardware, or explain why it is not possible to do so. If it is possible, calculate what the cost would be.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_10",
      "title": "9.10 You have devised a new page-replacement algorithm that you think may",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 55,
      "definition": "be optimal. In some contorted test cases, Belady\u2019s anomaly occurs. Is the new algorithm optimal? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_11",
      "title": "9.11 Segmentation is similar to paging but uses variable-sized \u201cpages.\u201d De\ufb01ne",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 55,
      "definition": "two segment-replacement algorithms, one based on the FIFO page- replacement scheme and the other on the LRU page-replacement scheme. Remember that since segments are not the same size, the segment that is chosen for replacement may be too small to leave enough consecutive locations for the needed segment. Consider strategies for systems where segments cannot be relocated and strategies for systems where they can.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_12",
      "title": "9.12 Consider a demand-paged computer system where the degree of mul-",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 55,
      "definition": "tiprogramming is currently \ufb01xed at four. The system was recently measured to determine utilization of the CPU and the paging disk. Three alternative results are shown below. For each case, what is happening? Can the degree of multiprogramming be increased to increase the CPU utilization? Is the paging helping? a. CPU utilization 13 percent; disk utilization 97 percent b. CPU utilization 87 percent; disk utilization 3 percent c. CPU utilization 13 percent; disk utilization 3 percent",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_13",
      "title": "9.13 We have an operating system for a machine that uses base and limit",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 56,
      "definition": "registers, but we have modi\ufb01ed the machine to provide a page table. Can the page tables be set up to simulate base and limit registers? How can they be, or why can they not be? Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_14",
      "title": "9.14 Assume that a program has just referenced an address in virtual memory.",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 56,
      "definition": "Describe a scenario in which each of the following can occur. (If no such scenario can occur, explain why.) \u2022 TLB miss with no page fault \u2022 TLB miss and page fault \u2022 TLB hit and no page fault \u2022 TLB hit and page fault",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_15",
      "title": "9.15 A simpli\ufb01ed view of thread states isReady, Running, and Blocked, where",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 56,
      "definition": "a thread is either ready and waiting to be scheduled, is running on the processor, or is blocked (for example, waiting for I/O). This is illustrated in Figure 9.31. Assuming a thread is in the Running state, answer the following questions, and explain your answer: a. Will the thread change state if it incurs a page fault? If so, to what state will it change? b. Will the thread change state if it generates a TLBmiss that is resolved in the page table? If so, to what state will it change? c. Will ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_16",
      "title": "9.16 Consider a system that uses pure demand paging.",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 56,
      "definition": "a. When a process \ufb01rst starts execution, how would you characterize the page-fault rate? b. Once the working set for a process is loaded into memory, how would you characterize the page-fault rate? Ready Blocked Running Figure 9.31 Thread state diagram for Exercise 9.15.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_17",
      "title": "9.17 What is the copy-on-write feature, and under what circumstances is its",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 57,
      "definition": "use bene\ufb01cial? What hardware support is required to implement this feature?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_18",
      "title": "9.18 A certain computer provides its users with a virtual memory space of",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 57,
      "definition": "bytes. The computer has 222 bytes of physical memory. The virtual memory is implemented by paging, and the page size is 4,096 bytes. A user process generates the virtual address 11123456. Explain how the system establishes the corresponding physical location. Distinguish between software and hardware operations.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_19",
      "title": "9.19 Assume that we have a demand-paged memory. The page table is held in",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 57,
      "definition": "registers. It takes 8 milliseconds to service a page fault if an empty frame is available or if the replaced page is not modi\ufb01ed and 20 milliseconds if the replaced page is modi\ufb01ed. Memory-access time is 100 nanoseconds. Assume that the page to be replaced is modi\ufb01ed 70 percent of the time. What is the maximum acceptable page-fault rate for an effective access time of no more than 200 nanoseconds?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_20",
      "title": "9.20 When a page fault occurs, the process requesting the page must block",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 57,
      "definition": "while waiting for the page to be brought from disk into physical memory. Assume that there exists a process with \ufb01ve user-level threads and that the mapping of user threads to kernel threads is one to one. If one user thread incurs a page fault while accessing its stack, would the other user threads belonging to the same process also be affected by the page fault\u2014that is, would they also have to wait for the faulting page to be brought into memory? Explain.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_21",
      "title": "9.21 Consider the following page reference string:",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 57,
      "definition": "7, 2, 3, 1, 2, 5, 3, 4, 6, 7, 7, 1, 0, 5, 4, 6, 2, 3, 0 , 1. Assuming demand paging with three frames, how many page faults would occur for the following replacement algorithms? \u2022 LRU replacement \u2022 FIFO replacement \u2022 Optimal replacement",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_22",
      "title": "9.22 The page table shown in Figure 9.32 is for a system with 16-bit virtual",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 57,
      "definition": "and physical addresses and with 4,096-byte pages. The reference bit is set to 1 when the page has been referenced. Periodically, a thread zeroes out all values of the reference bit. A dash for a page frame indicates the page is not in memory. The page-replacement algorithm is localized LRU, and all numbers are provided in decimal. a. Convert the following virtual addresses (in hexadecimal) to the equivalent physical addresses. You may provide answers in either",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_23",
      "title": "9.23 Assume that you are monitoring the rate at which the pointer in the",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 58,
      "definition": "clock algorithm moves. (The pointer indicates the candidate page for replacement.) What can you say about the system if you notice the following behavior: a. Pointer is moving fast. b. Pointer is moving slow.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_24",
      "title": "9.24 Discuss situations in which the least frequently used (LFU) page-",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 58,
      "definition": "replacementalgorithmgeneratesfewer page faults thanthe least recently used (LRU) page-replacement algorithm. Also discuss under what cir- cumstances the opposite holds.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_25",
      "title": "9.25 Discuss situations in which the most frequently used (MFU) page-",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 58,
      "definition": "replacementalgorithmgeneratesfewer page faults thanthe least recently used (LRU) page-replacement algorithm. Also discuss under what cir- cumstances the opposite holds.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_26",
      "title": "9.26 The VAX/VMS system uses a FIFO replacement algorithm for resident",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 59,
      "definition": "pages and a free-frame pool of recently used pages. Assume that the free-frame pool is managed using the LRU replacement policy. Answer the following questions: a. If a page fault occurs and the page does not exist in the free-frame pool, how is free space generated for the newly requested page? b. If a page fault occurs and the page exists in the free-frame pool, how is the resident page set and the free-frame pool managed to make space for the requested page? c. What does the system degenerate",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_27",
      "title": "9.27 Consider a demand-paging system with the following time-measured",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 59,
      "definition": "utilizations: CPU utilization 20% Paging disk 97.7% Other I/O devices 5% For each of the following, indicate whether it will (or is likely to) improve CPU utilization. Explain your answers. a. Install a faster CPU. b. Install a bigger paging disk. c. Increase the degree of multiprogramming. d. Decrease the degree of multiprogramming. e. Install more main memory. f. Install a faster hard disk or multiple controllers with multiple hard disks. g. Add prepaging to the page-fetch algorithms. h. Incre",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_28",
      "title": "9.28 Suppose that a machine provides instructions that can access memory",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 59,
      "definition": "locations using the one-level indirect addressing scheme. What sequence of page faults is incurred when all of the pages of a program are currently nonresident and the \ufb01rst instruction of the program is an indirect memory-load operation? What happens when the operating system is using a per-process frame allocation technique and only two pages are allocated to this process?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_29",
      "title": "9.29 Suppose that your replacement policy (in a paged system) is to examine",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 59,
      "definition": "each page regularly and to discard that page if it has not been used since the last examination. What would you gain and what would you lose by using this policy rather than LRU or second-chance replacement?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_30",
      "title": "9.30 A page-replacement algorithm should minimize the number of page",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 60,
      "definition": "faults. We can achieve this minimization by distributing heavily used pages evenly over all of memory, rather than having them compete for a small number of page frames. We can associate with each page frame a counter of the number of pages associated with that frame. Then, to replace a page, we can search for the page frame with the smallest counter. a. De\ufb01ne a page-replacement algorithm using this basic idea. Specif- ically address these problems: i. What is the initial value of the counters? ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_31",
      "title": "9.31 Consider a demand-paging system with a paging disk that has an",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 60,
      "definition": "average access and transfer time of 20 milliseconds. Addresses are translated through a page table in main memory, with an access time of 1 microsecond per memory access. Thus, each memory reference through the page table takes two accesses. To improve this time, we have added an associative memory that reduces access time to one memory reference if the page-table entry is in the associative memory. Assume that 80 percent of the accesses are in the associative memory and that, of those remaining",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_32",
      "title": "9.32 What is the cause of thrashing? How does the system detect thrashing?",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 60,
      "definition": "Once it detects thrashing, what can the system do to eliminate this problem?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_33",
      "title": "9.33 Is it possible for a process to have two working sets, one representing",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 60,
      "definition": "data and another representing code? Explain.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_34",
      "title": "9.34 Consider the parameter ! used to de\ufb01ne the working-set window in the",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 60,
      "definition": "working-set model. When ! is set to a small value, what is the effect on the page-fault frequency and the number of active (nonsuspended) processes currently executing in the system? What is the effect when ! is set to a very high value?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_35",
      "title": "9.35 In a 1,024-KB segment, memory is allocated using the buddy system.",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 60,
      "definition": "Using Figure 9.26 as a guide, draw a tree illustrating how the following memory requests are allocated: \u2022 Request 6-KB",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_36",
      "title": "9.36 A system provides support for user-level and kernel-level threads. The",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 61,
      "definition": "mapping in this system is one to one (there is a corresponding kernel thread for each user thread). Does a multithreaded process consist of (a) a working set for the entire process or (b) a working set for each thread? Explain",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_37",
      "title": "9.37 The slab-allocation algorithm uses a separate cache for each different",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 61,
      "definition": "object type. Assuming there is one cache per object type, explain why this scheme doesn\u2019t scale well with multiple CPUs. What could be done to address this scalability issue?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_38",
      "title": "9.38 Consider a system that allocates pages of different sizes to its processes.",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 61,
      "definition": "What are the advantages of such a paging scheme? What modi\ufb01cations to the virtual memory system provide this functionality? Programming Problems",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_39",
      "title": "9.39 Write a program that implements the FIFO, LRU, and optimal page-",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 61,
      "definition": "replacement algorithms presented in this chapter. First, generate a random page-reference string where page numbers range from 0 to 9. Apply the random page-reference string to each algorithm, and record the number of page faults incurred by each algorithm. Implement the replacement algorithms so that the number of page frames can vary from to 7. Assume that demand paging is used.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08_SUB_9_40",
      "title": "9.40 Repeat Exercise 3.22, this time using Windows shared memory. In partic-",
      "label": "Exercise",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 61,
      "definition": "ular, using the producer\u2014consumer strategy, design two programs that communicate with shared memory using the Windows API as outlined in Section 9.7.2. The producer will generate the numbers speci\ufb01ed in the Collatz conjecture and write them to a shared memory object. The consumer will then read and output the sequence of numbers from shared memory. In this instance, the producer will be passed an integer parameter on the command line specifying how many numbers to produce (for example, providing",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_08",
      "title": "Chapter 9 Virtual Memory",
      "label": "Chapter",
      "file_source": "09_Chapter 9 Virtual Memory.pdf",
      "page": 1,
      "definition": "Virtual memory is a technique that allows the execution of processes that are not completely in memory.",
      "key_points": [
        "All these strategies have the same goal: to keep many processes in memory simultaneously to allow multiprogramming.",
        "However, they tend to require that an entire process be in memory before it can execute.",
        "One major advantage of this scheme is that programs can be larger than physical memory.",
        "9.1 Background: The memory-management algorithms outlined in Chapter 8 are necessary because of ...",
        "9.2 Demand Paging: Consider how an executable program might be loaded from disk into memory....",
        "9.2.1 Basic Concepts: When a process is to be swapped in, the pager guesses which pages will be used b...",
        "9.2.2 Performance of Demand Paging: Demand paging can signi\ufb01cantly affect the performance of a computer system....",
        "9.3 Copy-on-Write: Recall that the fork() system call creates a child process that is a duplicate o..."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_1",
      "title": "10.1 Overview of Mass-Storage Structure",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 1,
      "definition": "In this section, we present a general overview of the physical structure of secondary and tertiary storage devices.",
      "key_points": []
    },
    {
      "id": "CHAP_09_SUB_10_1_1",
      "title": "10.1.1 Magnetic Disks",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 1,
      "definition": "Magnetic disks provide the bulk of secondary storage for modern computer systems.",
      "key_points": [
        "Conceptually, disks are relatively simple (Figure 10.1).",
        "Each disk platter has a \ufb02at circular shape, like a CD.",
        "Common platter diameters range from 1.8 to 3.5 inches.",
        "The two surfaces of a platter are covered with a magnetic material.",
        "We store information by recording it magnetically on the platters."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_1_2",
      "title": "10.1.2 Solid-State Disks",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 3,
      "definition": "Sometimes old technologies are used in new ways as economics change or the technologies evolve.",
      "key_points": [
        "An example is the growing importance of solid-state disks, or SSDs. Simply described, an SSD is nonvolatile memory that is used like a hard drive.",
        "There are many variations of this technology, from DRAM with a battery to allow it to maintain its state in a power failure through \ufb02ash-memory technologies like single-level cell (SLC) and multilevel cell (MLC) chips.",
        "SSDs have the same characteristics as traditional hard disks but can be more reliable because they have no moving parts and faster because they have no seek time or latency.",
        "In addition, they consume less power.",
        "However, they are more expensive per megabyte than traditional hard disks, have less capacity than the larger hard disks, and may have shorter life spans than hard disks, so their uses are somewhat limited."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_1_3",
      "title": "10.1.3 Magnetic Tapes",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 3,
      "definition": "Magnetic tape was used as an early secondary-storage medium.",
      "key_points": [
        "Although it is relatively permanent and can hold large quantities of data, its access time is slow compared with that of main memory and magnetic disk.",
        "In addition, random access to magnetic tape is about a thousand times slower than random access to magnetic disk, so tapes are not very useful for secondary storage."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_2",
      "title": "10.2 Disk Structure",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 4,
      "definition": "Modern magnetic disk drives are addressed as large one-dimensional arrays of logical blocks, where the logical block is the smallest unit of transfer.",
      "key_points": [
        "The size of a logical block is usually 512 bytes, although some disks can be low-level formatted to have a different logical block size, such as 1,024 bytes.",
        "This option is described in Section 10.5.1. The one-dimensional array of logical blocks is mapped onto the sectors of the disk sequentially.",
        "Sector 0 is the \ufb01rst sector of the \ufb01rst track on the outermost cylinder.",
        "The mapping proceeds in order through that track, then through the rest of the tracks in that cylinder, and then through the rest of the cylinders from outermost to innermost.",
        "By using this mapping, we can\u2014at least in theory\u2014convert a logical block number into an old-style disk address that consists of a cylinder number, a track number within that cylinder, and a sector number within that track."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_3",
      "title": "10.3 Disk Attachment",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 5,
      "definition": "Computers access disk storage in two ways.",
      "key_points": [
        "One way is via I/O ports (or host-attached storage); this is common on small systems.",
        "The other way is via a remote host in a distributed \ufb01le system; this is referred to as network-attached storage."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_3_1",
      "title": "10.3.1 Host-Attached Storage",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 5,
      "definition": "Host-attached storage is storage accessed through local I/O ports.",
      "key_points": [
        "These ports use several technologies.",
        "The typical desktop PC uses an I/O bus architecture called IDE or ATA.",
        "This architecture supports a maximum of two drives per I/O bus.",
        "A newer, similar protocol that has simpli\ufb01ed cabling is SATA.",
        "High-end workstations and servers generally use more sophisticated I/O architectures such as \ufb01bre channel (FC), a high-speed serial architecture that can operate over optical \ufb01ber or over a four-conductor copper cable."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_3_2",
      "title": "10.3.2 Network-Attached Storage",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 5,
      "definition": "A network-attached storage (NAS) device is a special-purpose storage system that is accessed remotely over a data network (Figure 10.2).",
      "key_points": [
        "Clients access network-attached storage via a remote-procedure-call interface such as NFS for UNIX systems or CIFS for Windows machines.",
        "The remote procedure calls (RPCs) are carried via TCP or UDP over an IP network\u2014usually the same local- area network (LAN) that carries all data traf\ufb01c to the clients.",
        "Thus, it may be easiest to think of NAS as simply another storage-access protocol.",
        "The network- attached storage unit is usually implemented as a RAID array with software that implements the RPC interface."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_3_3",
      "title": "10.3.3 Storage-Area Network",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 6,
      "definition": "A storage-area network (SAN) is a private network (using storage protocols rather than networking protocols) connecting servers and storage units, as shown in Figure 10.3. The power of a SAN lies in its \ufb02exibility.",
      "key_points": [
        "This problem can be particularly acute in large client\u2013server installations\u2014the communication between servers and clients competes for bandwidth with the communication among servers and storage devices.",
        "Multiple hosts and multiple storage arrays can attach to the same SAN, and storage can be dynamically allocated to hosts.",
        "A SAN switch allows or prohibits access between the hosts and the storage.",
        "As one example, if a host is running low on disk space, the SAN can be con\ufb01gured to allocate more storage to that host.",
        "SANs make it possible for clusters of servers to share the same storage and for storage arrays to include multiple direct host connections."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_4",
      "title": "10.4 Disk Scheduling",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 6,
      "definition": "One of the responsibilities of the operating system is to use the hardware ef\ufb01ciently.",
      "key_points": [
        "For the disk drives, meeting this responsibility entails having fast"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_4_1",
      "title": "10.4.1 FCFS Scheduling",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 7,
      "definition": "The simplest form of disk scheduling is, of course, the \ufb01rst-come, \ufb01rst-served (FCFS) algorithm.",
      "key_points": [
        "This algorithm is intrinsically fair, but it generally does not provide the fastest service.",
        "Consider, for example, a disk queue with requests for I/O to blocks on cylinders 98, 183, 37, 122, 14, 124, 65, 67,"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_4_2",
      "title": "10.4.2 SSTF Scheduling",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 8,
      "definition": "It seems reasonable to service all the requests close to the current head position before moving the head far away to service other requests.",
      "key_points": [
        "This assumption is the basis for the shortest-seek-time-\ufb01rst (SSTF) algorithm.",
        "The SSTF algorithm selects the request with the least seek time from the current head position.",
        "In other words, SSTF chooses the pending request closest to the current head position.",
        "For our example request queue, the closest request to the initial head position (53) is at cylinder 65.",
        "Once we are at cylinder 65, the next closest request is at cylinder 67."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_4_3",
      "title": "10.4.3 SCAN Scheduling",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 9,
      "definition": "In the SCAN algorithm, the disk arm starts at one end of the disk and moves toward the other end, servicing requests as it reaches each cylinder, until it gets to the other end of the disk.",
      "key_points": [
        "At the other end, the direction of head movement is reversed, and servicing continues.",
        "The head continuously scans back and forth across the disk.",
        "The SCAN algorithm is sometimes called the elevator algorithm, since the disk arm behaves just like an elevator in a building, \ufb01rst servicing all the requests going up and then reversing to service requests the other way.",
        "Let\u2019s return to our example to illustrate.",
        "Before applying SCAN to schedule the requests on cylinders 98, 183, 37, 122, 14, 124, 65, and 67, we need to know the direction of head movement in addition to the head\u2019s current position."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_4_4",
      "title": "10.4.4 C-SCAN Scheduling",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 10,
      "definition": "Circular SCAN (C-SCAN) scheduling is a variant of SCAN designed to provide a more uniform wait time.",
      "key_points": [
        "Like SCAN, C-SCAN moves the head from one end of the disk to the other, servicing requests along the way.",
        "When the head reaches the other end, however, it immediately returns to the beginning of the disk without servicing any requests on the return trip (Figure 10.7).",
        "The C-SCAN scheduling algorithm essentially treats the cylinders as a circular list that wraps around from the \ufb01nal cylinder to the \ufb01rst one.",
        "14 53 65 67 122124 queue = 98, 183, 37, 122, 14, 124, 65, 67 head starts at 53 Figure 10.7 C-SCAN disk scheduling."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_4_5",
      "title": "10.4.5 LOOK Scheduling",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 11,
      "definition": "As we described them, both SCAN and C-SCAN move the disk arm across the full width of the disk.",
      "key_points": [
        "In practice, neither algorithm is often implemented this way.",
        "More commonly, the arm goes only as far as the \ufb01nal request in each direction.",
        "Then, it reverses direction immediately, without going all the way to the end of the disk.",
        "Versions of SCAN and C-SCAN that follow this pattern are called LOOK and C-LOOK scheduling, because they look for a request before continuing to move in a given direction (Figure 10.8)."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_4_6",
      "title": "10.4.6 Selection of a Disk-Scheduling Algorithm",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 11,
      "definition": "Given so many disk-scheduling algorithms, how do we choose the best one?",
      "key_points": [
        "The location of directories and index blocks is also important.",
        "SSTF is common and has a natural appeal because it increases performance over FCFS.",
        "SCAN and C-SCAN perform better for systems that place a heavy load on the disk, because they are less likely to cause a starvation problem.",
        "For any particular list of requests, we can de\ufb01ne an optimal order of retrieval, but the computation needed to \ufb01nd an optimal schedule may not justify the savings over SSTF or SCAN.",
        "With any scheduling algorithm, however, performance depends heavily on the number and types of requests."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_5",
      "title": "10.5 Disk Management",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 12,
      "definition": "The operating system is responsible for several other aspects of disk manage- ment, too.",
      "key_points": [
        "Here we discuss disk initialization, booting from disk, and bad-block recovery."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_5_1",
      "title": "10.5.1 Disk Formatting",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 13,
      "definition": "A new magnetic disk is a blank slate: it is just a platter of a magnetic recording material.",
      "key_points": [
        "This process is called low-level formatting, or physical formatting.",
        "The controller automatically does the ECC processing whenever a sector is read or written.",
        "Most hard disks are low-level-formatted at the factory as a part of the manufacturing process.",
        "It does so in two steps.",
        "The \ufb01rst step is to partition the disk into one or more groups of cylinders."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_5_2",
      "title": "10.5.2 Boot Block",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 14,
      "definition": "For a computer to start running\u2014for instance, when it is powered up or rebooted\u2014it must have an initial program to run.",
      "key_points": [
        "This location is convenient, because ROM needs no initialization and is at a \ufb01xed location that the processor can start executing when powered up or reset.",
        "Let\u2019s consider as an example the boot process in Windows.",
        "First, note that Windows allows a hard disk to be divided into partitions, and one partition \u2014identi\ufb01ed as the boot partition\u2014contains the operating system and device drivers.",
        "In addition to containing boot code, the MBR contains a table listing the partitions for the hard disk and a \ufb02ag indicating which partition the system is to be booted from, as illustrated in Figure 10.9. Once the system identi\ufb01es the boot partition, it reads the \ufb01rst sector from that partition (which is called the boot sector) and continues with the remainder of the boot process, which includes loading the various subsystems and system services."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_5_3",
      "title": "10.5.3 Bad Blocks",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 14,
      "definition": "Because disks have moving parts and small tolerances (recall that the disk head \ufb02ies just above the disk surface), they are prone to failure.",
      "key_points": [
        "Sometimes the failure is complete; in this case, the disk needs to be replaced and its contents"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_6",
      "title": "10.6 Swap-Space Management",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 16,
      "definition": "Swapping was \ufb01rst presented in Section 8.2, where we discussed moving entire processes between disk and main memory.",
      "key_points": [
        "Swapping in that setting occurs when the amount of physical memory reaches a critically low point and processes are moved from memory to swap space to free available memory.",
        "Rather, systems now combine swapping with virtual memory techniques (Chapter 9) and swap pages, not necessarily entire processes.",
        "In practice, very few modern operating systems implement swapping in this fashion.",
        "In fact, some systems now use the terms \u201cswapping\u201d and \u201cpaging\u201d interchangeably, re\ufb02ecting the merging of these two concepts.",
        "Swap-space management is another low-level task of the operating system."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_6_1",
      "title": "10.6.1 Swap-Space Use",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 16,
      "definition": "Swap space is used in various ways by different operating systems, depending on the memory-management algorithms in use.",
      "key_points": [
        "For instance, systems that implement swapping may use swap space to hold an entire process image, including the code and data segments.",
        "Note that it may be safer to overestimate than to underestimate the amount of swap space required, because if a system runs out of swap space it may be forced to abort processes or may crash entirely.",
        "Paging systems may simply store pages that have been pushed out of main memory.",
        "The amount of swap space needed on a system can therefore vary from a few megabytes of disk space to gigabytes, depending on the amount of physical memory, the amount of virtual memory it is backing, and the way in which the virtual memory is used.",
        "Overestimation wastes disk space that could otherwise be used for \ufb01les, but it does no other harm."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_6_2",
      "title": "10.6.2 Swap-Space Location",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 17,
      "definition": "A swap space can reside in one of two places: it can be carved out of the normal \ufb01le system, or it can be in a separate disk partition.",
      "key_points": [
        "External fragmentation can greatly increase swapping times by forcing multiple seeks during reading or writing of a process image.",
        "If the swap space is simply a large \ufb01le within the \ufb01le system, normal \ufb01le-system routines can be used to create it, name it, and allocate its space.",
        "This approach, though easy to implement, is inef\ufb01cient.",
        "Navigating the directory structure and the disk- allocation data structures takes time and (possibly) extra disk accesses.",
        "We can improve performance by caching the block location information in physical memory and by using special tools to allocate physically contiguous blocks for the swap \ufb01le, but the cost of traversing the \ufb01le-system data structures remains."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_6_3",
      "title": "10.6.3 Swap-Space Management: An Example",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 17,
      "definition": "We can illustrate how swap space is used by following the evolution of swapping and paging in various UNIX systems.",
      "key_points": [
        "The traditional UNIX kernel started with an implementation of swapping that copied entire processes between contiguous disk regions and memory.",
        "When a process executes, text-segment pages containing code are brought in from the \ufb01le",
        "UNIX later evolved to a combination of swapping and paging as paging hardware became available.",
        "In Solaris 1 (SunOS), the designers changed standard UNIX methods to improve ef\ufb01ciency and re\ufb02ect technological developments."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_7",
      "title": "10.7 RAID Structure",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 18,
      "definition": "Disk drives have continued to get smaller and cheaper, so it is now econom- ically feasible to attach many disks to a computer system.",
      "key_points": [
        "Having a large number of disks in a system presents opportunities for improving the rate at which data can be read or written, if the disks are operated in parallel.",
        "Furthermore, this setup offers the potential for improving the reliability of data storage, because redundant information can be stored on multiple disks.",
        "Thus, failure of one disk does not lead to loss of data.",
        "A variety of disk-organization techniques, collectively called redundant arrays of independent disks (RAID), are commonly used to address the performance and reliability issues.",
        "In the past, RAIDs composed of small, cheap disks were viewed as a cost-effective alternative to large, expensive disks."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_7_1",
      "title": "10.7.1 Improvement of Reliability via Redundancy",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 19,
      "definition": "Let\u2019s \ufb01rst consider the reliability of RAIDs. The chance that some disk out of a set of N disks will fail is much higher than the chance that a speci\ufb01c single disk will fail.",
      "key_points": [
        "Suppose that the mean time to failure of a single disk is 100,000 hours.",
        "Then the mean time to failure of some disk in an array of 100 disks will be 100,000/100 = 1,000 hours, or 41.66 days, which is not long at all! If we store only one copy of the data, then each disk failure will result in loss of a signi\ufb01cant amount of data\u2014and such a high rate of data loss is unacceptable.",
        "The solution to the problem of reliability is to introduce redundancy; we store extra information that is not normally needed but that can be used in the event of failure of a disk to rebuild the lost information.",
        "Thus, even if a disk fails, data are not lost.",
        "The simplest (but most expensive) approach to introducing redundancy is to duplicate every disk."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_7_2",
      "title": "10.7.2 Improvement in Performance via Parallelism",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 20,
      "definition": "In its simplest form, data striping consists of splitting the bits of each byte across multiple disks; such striping is called bit-level striping.",
      "key_points": [
        "The array of eight disks can be treated as a single disk with sectors that are eight times the normal size and, more important, that have eight times the access rate.",
        "Every disk participates in every access (read or write); so the number of accesses that can be processed per second is about the same as on a single disk, but each access can read eight times as many data in the same time as on a single disk.",
        "With disk mirroring, the rate at which read requests can be handled is doubled, since read requests can be sent to either disk (as long as both disks in a pair are functional, as is almost always the case).",
        "The transfer rate of each read is the same as in a single-disk system, but the number of reads per unit time has doubled.",
        "With multiple disks, we can improve the transfer rate as well (or instead) by striping data across the disks."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_7_3",
      "title": "10.7.3 RAID Levels",
      "label": "Topic",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 21,
      "definition": "Mirroring provides high reliability, but it is expensive.",
      "key_points": [
        "Striping provides high data-transfer rates, but it does not improve reliability.",
        "Numerous schemes to provide redundancy at lower cost by using disk striping combined with \u201cparity\u201d bits (which we describe shortly) have been proposed.",
        "These schemes have different cost\u2013performance trade-offs and are classi\ufb01ed according to levels called RAID levels.",
        "We describe the various levels here; Figure 10.11 shows them pictorially (in the \ufb01gure, P indicates error-correcting bits and C indicates a second copy of the data).",
        "In all cases depicted in the \ufb01gure, four disks\u2019 worth of data are stored, and the extra disks are used to store redundant information for failure recovery."
      ]
    },
    {
      "id": "CHAP_09_SUB_10_7_4",
      "title": "10.7.4 Selecting a RAID Level",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 26,
      "definition": "Given the many choices they have, how do system designers choose a RAID level? One consideration is rebuild performance. If a disk fails, the time needed to rebuild its data can be signi\ufb01cant. This may be an important factor if a continuous supply of data is required, as it is in high-performance or interactive database systems. Furthermore, rebuild performance in\ufb02uences the mean time to failure. Rebuild performance varies with the RAID level used. Rebuilding is easiest for RAID level 1, since d",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_7_5",
      "title": "10.7.5 Extensions",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 26,
      "definition": "The concepts of RAID have been generalized to other storage devices, including arrays of tapes, and even to the broadcast of data over wireless systems. When applied to arrays of tapes, RAID structures are able to recover data even if one of the tapes in an array is damaged. When applied to broadcast of data, a block of data is split into short units and is broadcast along with a parity unit. If one of the units is not received for any reason, it can be reconstructed from the other units. Common",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_7_6",
      "title": "10.7.6 Problems with RAID",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 26,
      "definition": "Unfortunately, RAID does not always assure that data are available for the operating system and its users. A pointer to a \ufb01le could be wrong, for example, or pointers within the \ufb01le structure could be wrong. Incomplete writes, if not properly recovered, could result in corrupt data. Some other process could accidentally write over a \ufb01le system\u2019s structures, too. RAID protects against physical media errors, but not other hardware and software errors. As large as is the landscape of software and h",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_8",
      "title": "10.8 Stable-Storage Implementation",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 28,
      "definition": "In Chapter 5, we introduced the write-ahead log, which requires the availability of stable storage. By de\ufb01nition, information residing in stable storage is never lost. To implement such storage, we need to replicate the required information",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_9",
      "title": "10.9 Summary",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 30,
      "definition": "Disk drives are the major secondary storage I/O devices on most computers. Most secondary storage devices are either magnetic disks or magnetic tapes, although solid-state disks are growing in importance. Modern disk drives are structured as large one-dimensional arrays of logical disk blocks. Generally, these logical blocks are 512 bytes in size. Disks may be attached to a computer system in one of two ways: (1) through the local I/O ports on the host computer or (2) through a network connectio",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_1",
      "title": "10.1 Is disk scheduling, other than FCFS scheduling, useful in a single-user",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 31,
      "definition": "environment? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_2",
      "title": "10.2 Explain why SSTF scheduling tends to favor middle cylinders over the",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 31,
      "definition": "innermost and outermost cylinders.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_3",
      "title": "10.3 Why is rotational latency usually not considered in disk scheduling?",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 31,
      "definition": "How would you modify SSTF, SCAN, and C-SCAN to include latency optimization?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_4",
      "title": "10.4 Why is it important to balance \ufb01le-system I/O among the disks and",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 31,
      "definition": "controllers on a system in a multitasking environment?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_5",
      "title": "10.5 What are the tradeoffs involved in rereading code pages from the \ufb01le",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 31,
      "definition": "system versus using swap space to store them?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_6",
      "title": "10.6 Is there any way to implement truly stable storage? Explain your",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 31,
      "definition": "answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_7",
      "title": "10.7 It is sometimes said that tape is a sequential-access medium, whereas",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 31,
      "definition": "a magnetic disk is a random-access medium. In fact, the suitability of a storage device for random access depends on the transfer size. The term \u201cstreaming transfer rate\u201d denotes the rate for a data transfer that is underway, excluding the effect of access latency. In contrast, the \u201ceffective transfer rate\u201d is the ratio of total bytes per total seconds, including overhead time such as access latency. Suppose we have a computer with the following characteristics: the level-2 cache has an access l",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_8",
      "title": "10.8 Could a RAID level 1 organization achieve better performance for read",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 32,
      "definition": "requests than a RAID level 0 organization (with nonredundant striping of data)? If so, how? Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_9",
      "title": "10.9 None of the disk-scheduling disciplines, except FCFS, is truly fair",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 32,
      "definition": "(starvation may occur). a. Explain why this assertion is true. b. Describe a way to modify algorithms such as SCAN to ensure fairness. c. Explain why fairness is an important goal in a time-sharing system. d. Give three or more examples of circumstances in which it is important that the operating system be unfair in serving I/O requests.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_10",
      "title": "10.10 Explain why SSDs often use an FCFS disk-scheduling algorithm.",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 32,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_11",
      "title": "10.11 Suppose that a disk drive has 5,000 cylinders, numbered 0 to 4,999. The",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 32,
      "definition": "drive is currently serving a request at cylinder 2,150, and the previous request was at cylinder 1,805. The queue of pending requests, in FIFO order, is: 2,069, 1,212, 2,296, 2,800, 544, 1,618, 356, 1,523, 4,965, 3681",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_12",
      "title": "10.12 Elementary physics states that when an object is subjected to a constant",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 33,
      "definition": "acceleration a, the relationship between distance d and time t is given by d = 1 2at2. Suppose that, during a seek, the disk in Exercise 10.11 accelerates the disk arm at a constant rate for the \ufb01rst half of the seek, then decelerates the disk arm at the same rate for the second half of the seek. Assume that the disk can perform a seek to an adjacent cylinder in 1 millisecond and a full-stroke seek over all 5,000 cylinders in 18 milliseconds. a. The distance of a seek is the number of cylinders ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_13",
      "title": "10.13 Suppose that the disk in Exercise 10.12 rotates at 7,200 RPM.",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 33,
      "definition": "a. What is the average rotational latency of this disk drive? b. What seek distance can be covered in the time that you found for part a?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_14",
      "title": "10.14 Describe some advantages and disadvantages of using SSDs as a",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 33,
      "definition": "caching tier and as a disk-drive replacement compared with using only magnetic disks.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_15",
      "title": "10.15 Compare the performance of C-SCAN and SCAN scheduling, assuming",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 33,
      "definition": "a uniform distribution of requests. Consider the average response time (the time between the arrival of a request and the completion of that request\u2019s service), the variation in response time, and the effective",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_16",
      "title": "10.16 Requests are not usually uniformly distributed. For example, we can",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 34,
      "definition": "expect a cylinder containing the \ufb01le-system metadata to be accessed more frequently than a cylinder containing only \ufb01les. Suppose you know that 50 percent of the requests are for a small, \ufb01xed number of cylinders. a. Would any of the scheduling algorithms discussed in this chapter be particularly good for this case? Explain your answer. b. Propose a disk-scheduling algorithm that gives even better per- formance by taking advantage of this \u201chot spot\u201d on the disk.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_17",
      "title": "10.17 Consider a RAID level 5 organization comprising \ufb01ve disks, with the",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 34,
      "definition": "parity for sets of four blocks on four disks stored on the \ufb01fth disk. How many blocks are accessed in order to perform the following? a. A write of one block of data b. A write of seven continuous blocks of data",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_18",
      "title": "10.18 Compare the throughput achieved by a RAID level 5 organization with",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 34,
      "definition": "that achieved by a RAID level 1 organization for the following: a. Read operations on single blocks b. Read operations on multiple contiguous blocks",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_19",
      "title": "10.19 Compare the performance of write operations achieved by a RAID level",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 34,
      "definition": "organization with that achieved by a RAID level 1 organization.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_20",
      "title": "10.20 Assume that you have a mixed con\ufb01guration comprising disks orga-",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 34,
      "definition": "nized as RAID level 1 and RAID level 5 disks. Assume that the system has \ufb02exibility in deciding which disk organization to use for storing a particular \ufb01le. Which \ufb01les should be stored in the RAID level 1 disks and which in the RAID level 5 disks in order to optimize performance?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_21",
      "title": "10.21 The reliability of a hard-disk drive is typically described in terms of",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 34,
      "definition": "a quantity called mean time between failures (MTBF). Although this quantity is called a \u201ctime,\u201d the MTBF actually is measured in drive-hours per failure. a. If a system contains 1,000 disk drives, each of which has a 750,000- hour MTBF, which of the following best describes how often a drive failure will occur in that disk farm: once per thousand years, once per century, once per decade, once per year, once per month, once per week, once per day, once per hour, once per minute, or once per secon",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_22",
      "title": "10.22 Discuss the relative advantages and disadvantages of sector sparing",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 35,
      "definition": "and sector slipping.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_23",
      "title": "10.23 Discuss the reasons why the operating system might require accurate",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 35,
      "definition": "information on how blocks are stored on a disk. How could the oper- ating system improve \ufb01le-system performance with this knowledge? Programming Problems",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09_SUB_10_24",
      "title": "10.24 Write a program that implements the following disk-scheduling algo-",
      "label": "Exercise",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 35,
      "definition": "rithms: a. FCFS b. SSTF c. SCAN d. C-SCAN e. LOOK f. C-LOOK Your program will service a disk with 5,000 cylinders numbered 0 to 4,999. The program will generate a random series of 1,000 cylinder requests and service them according to each of the algorithms listed above. The program will be passed the initial position of the disk head (as a parameter on the command line) and report the total amount of head movement required by each algorithm. Bibliographical Notes [Services (2012)] provides an ov",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_09",
      "title": "Chapter 10 Mass-Storage Structure",
      "label": "Chapter",
      "file_source": "10_Chapter 10 Mass-Storage Structure.pdf",
      "page": 1,
      "definition": "10 C H A P T E R Mass-Storage Structure The \ufb01le system can be viewed logically as consisting of three parts.",
      "key_points": [
        "In Chapter 11, we examine the user and programmer interface to the \ufb01le system.",
        "In Chapter 12, we describe the internal data structures and algorithms used by the operating system to implement this interface.",
        "In this chapter, we begin a discussion of \ufb01le systems at the lowest level: the structure of secondary storage.",
        "10.1 Overview of Mass-Storage Structure: In this section, we present a general overview of the physical structure of seco...",
        "10.1.1 Magnetic Disks: Magnetic disks provide the bulk of secondary storage for modern computer systems...",
        "10.1.2 Solid-State Disks: Sometimes old technologies are used in new ways as economics change or the techn...",
        "10.1.3 Magnetic Tapes: Magnetic tape was used as an early secondary-storage medium....",
        "10.2 Disk Structure: Modern magnetic disk drives are addressed as large one-dimensional arrays of log..."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_1",
      "title": "11.1 File Concept",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 1,
      "definition": "Computers can store information on various storage media, such as magnetic disks, magnetic tapes, and optical disks.",
      "key_points": [
        "So that the computer system will be convenient to use, the operating system provides a uniform logical view of stored information.",
        "The operating system abstracts from the physical properties of its storage devices to de\ufb01ne a logical storage unit, the \ufb01le.",
        "Files are mapped by the operating system onto physical devices.",
        "These storage devices are usually nonvolatile, so the contents are persistent between system reboots."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_1_1",
      "title": "11.1.1 File Attributes",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 2,
      "definition": "A \ufb01le is named, for the convenience of its human users, and is referred to by its name.",
      "key_points": [
        "When a \ufb01le is named, it becomes independent of the process, the user, and even the system that created it.",
        "A name is usually a string of characters, such as example.c. Some systems differentiate between uppercase and lowercase characters in names, whereas other systems do not.",
        "For instance, one user might create the \ufb01le example.c, and another user might edit that \ufb01le by specifying its name.",
        "The \ufb01le\u2019s owner might write the \ufb01le to a USB disk, send it as an e-mail attachment, or copy it across a network, and it could still be called example.c on the destination system.",
        "A \ufb01le\u2019s attributes vary from one operating system to another but typically consist of these: \u2022 Name."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_1_2",
      "title": "11.1.2 File Operations",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 4,
      "definition": "A \ufb01le is an abstract data type.",
      "key_points": [
        "Two steps are necessary to create a \ufb01le.",
        "Because a process is usually either reading from or writing to a \ufb01le, the current operation location can be kept as a per-process current- \ufb01le-position pointer.",
        "To de\ufb01ne a \ufb01le properly, we need to consider the operations that can be performed on \ufb01les.",
        "The operating system can provide system calls to create, write, read, reposition, delete, and truncate \ufb01les.",
        "Let\u2019s examine what the operating system must do to perform each of these six basic \ufb01le operations."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_1_3",
      "title": "11.1.3 File Types",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 8,
      "definition": "This attempt normally produces garbage; however, the attempt can succeed if the operating system has been told that the \ufb01le is a binary-object program.",
      "key_points": [
        "For example, Java compilers expect source \ufb01les to have a .java extension, and the Microsoft Word word processor expects its \ufb01les to end with a .doc or .docx extension.",
        "If an operating system recognizes the type of a \ufb01le, it can then operate on the \ufb01le in reasonable ways.",
        "For example, a common mistake occurs when a user tries to output the binary-object form of a program.",
        "A common technique for implementing \ufb01le types is to include the type as part of the \ufb01le name.",
        "The name is split into two parts\u2014a name and an extension, usually separated by a period (Figure 11.3)."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_1_4",
      "title": "11.1.4 File Structure",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 9,
      "definition": "File types also can be used to indicate the internal structure of the \ufb01le.",
      "key_points": [
        "As mentioned in Section 11.1.3, source and object \ufb01les have structures that match the expectations of the programs that read them.",
        "Further, certain \ufb01les must"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_1_5",
      "title": "11.1.5 Internal File Structure",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 10,
      "definition": "Internally, locating an offset within a \ufb01le can be complicated for the operating system.",
      "key_points": [
        "Disk systems typically have a well-de\ufb01ned block size determined by the size of a sector.",
        "All disk I/O is performed in units of one block (physical record), and all blocks are the same size.",
        "It is unlikely that the physical record size will exactly match the length of the desired logical record.",
        "Logical records may even vary in length.",
        "Packing a number of logical records into physical blocks is a common solution to this problem."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_2",
      "title": "11.2 Access Methods",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 11,
      "definition": "while others support many access methods, and choosing the right one for a particular application is a major design problem.",
      "key_points": [
        "When it is used, this information must be accessed and read into computer memory.",
        "The information in the \ufb01le can be accessed in several ways.",
        "Some systems provide only one access method for \ufb01les."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_2_1",
      "title": "11.2.1 Sequential Access",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 11,
      "definition": "The simplest access method is sequential access.",
      "key_points": [
        "Information in the \ufb01le is processed in order, one record after the other.",
        "This mode of access is by far the most common; for example, editors and compilers usually access \ufb01les in this fashion.",
        "Reads and writes make up the bulk of the operations on a \ufb01le.",
        "A read operation\u2014read next()\u2014reads the next portion of the \ufb01le and automatically advances a \ufb01le pointer, which tracks the I/O location.",
        "Similarly, the write operation\u2014write next()\u2014appends to the end of the \ufb01le and advances to the end of the newly written material (the new end of \ufb01le)."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_2_2",
      "title": "11.2.2 Direct Access",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 11,
      "definition": "Another method is direct access (or relative access).",
      "key_points": [
        "Here, a \ufb01le is made up of \ufb01xed-length logical records that allow programs to read and write records rapidly in no particular order.",
        "The direct-access method is based on a disk model of a \ufb01le, since disks allow random access to any \ufb01le block."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_2_3",
      "title": "11.2.3 Other Access Methods",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 12,
      "definition": "Other access methods can be built on top of a direct-access method.",
      "key_points": [
        "These methods generally involve the construction of an index for the \ufb01le.",
        "The index, like an index in the back of a book, contains pointers to the various blocks."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_3",
      "title": "11.3 Directory and Disk Structure",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 13,
      "definition": "Next, we consider how to store \ufb01les.",
      "key_points": [
        "Certainly, no general-purpose computer stores just one \ufb01le.",
        "There are typically thousands, millions, even billions of \ufb01les within a computer.",
        "Files are stored on random-access storage devices, including hard disks, optical disks, and solid-state (memory-based) disks.",
        "A storage device can be used in its entirety for a \ufb01le system.",
        "It can also be subdivided for \ufb01ner-grained control."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_3_1",
      "title": "11.3.1 Storage Structure",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 15,
      "definition": "As we have just seen, a general-purpose computer system has multiple storage devices, and those devices can be sliced up into volumes that hold \ufb01le systems.",
      "key_points": [
        "Consider the types of \ufb01le systems in the Solaris example mentioned above: \u2022 tmpfs\u2014a \u201ctemporary\u201d \ufb01le system that is created in volatile main memory and has its contents erased if the system reboots or crashes \u2022 objfs\u2014a \u201cvirtual\u201d \ufb01le system (essentially an interface to the kernel that looks like a \ufb01le system) that gives debuggers access to kernel symbols \u2022 ctfs\u2014a virtual \ufb01le system that maintains \u201ccontract\u201d information to manage which processes start when the system boots and must continue to run during operation \u2022 lofs\u2014a \u201cloop back\u201d \ufb01le system that allows one \ufb01le system to be accessed in place of another one \u2022 procfs\u2014a virtual \ufb01le system that presents information on all processes as a \ufb01le system \u2022 ufs, zfs\u2014general-purpose \ufb01le systems",
        "Computer systems may have zero or more \ufb01le systems, and the \ufb01le systems may be of varying types.",
        "For example, a typical Solaris system may have dozens of \ufb01le systems of a dozen different types, as shown in the \ufb01le system list in Figure 11.8. In this book, we consider only general-purpose \ufb01le systems.",
        "It is worth noting, though, that there are many special-purpose \ufb01le systems."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_3_2",
      "title": "11.3.2 Directory Overview",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 16,
      "definition": "The directory can be viewed as a symbol table that translates \ufb01le names into their directory entries.",
      "key_points": [
        "If we take such a view, we see that the directory itself can be organized in many ways.",
        "The organization must allow us to insert entries, to delete entries, to search for a named entry, and to list all the entries in the directory.",
        "In this section, we examine several schemes for de\ufb01ning the logical structure of the directory system.",
        "When considering a particular directory structure, we need to keep in mind the operations that are to be performed on a directory: \u2022 Search for a \ufb01le.",
        "We need to be able to search a directory structure to \ufb01nd the entry for a particular \ufb01le."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_3_3",
      "title": "11.3.3 Single-Level Directory",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 16,
      "definition": "The simplest directory structure is the single-level directory.",
      "key_points": [
        "All \ufb01les are contained in the same directory, which is easy to support and understand (Figure 11.9).",
        "A single-level directory has signi\ufb01cant limitations, however, when the number of \ufb01les increases or when the system has more than one user.",
        "Since all \ufb01les are in the same directory, they must have unique names."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_3_4",
      "title": "11.3.4 Two-Level Directory",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 17,
      "definition": "As we have seen, a single-level directory often leads to confusion of \ufb01le names among different users.",
      "key_points": [
        "The standard solution is to create a separate directory for each user.",
        "In the two-level directory structure, each user has his own user \ufb01le directory (UFD).",
        "The UFDs have similar structures, but each lists only the \ufb01les of a single user.",
        "When a user job starts or a user logs in, the system\u2019s master \ufb01le directory (MFD) is searched.",
        "The MFD is indexed by user name or account number, and each entry points to the UFD for that user (Figure 11.10)."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_3_5",
      "title": "11.3.5 Tree-Structured Directories",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 19,
      "definition": "Once we have seen how to view a two-level directory as a two-level tree, the natural generalization is to extend the directory structure to a tree of arbitrary height (Figure 11.11).",
      "key_points": [
        "In normal use, each process has a current directory.",
        "The current directory should contain most of the \ufb01les that are of current interest to the process.",
        "This generalization allows users to create their own subdirectories and to organize their \ufb01les accordingly.",
        "A tree is the most common directory structure.",
        "The tree has a root directory, and every \ufb01le in the system has a unique path name."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_3_6",
      "title": "11.3.6 Acyclic-Graph Directories",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 21,
      "definition": "Consider two programmers who are working on a joint project.",
      "key_points": [
        "It is important to note that a shared \ufb01le (or directory) is not the same as two copies of the \ufb01le.",
        "Sharing is particularly important for subdirectories; a new \ufb01le created by one person will automatically appear in all the shared subdirectories.",
        "The \ufb01les asso- ciated with that project can be stored in a subdirectory, separating them from other projects and \ufb01les of the two programmers.",
        "But since both programmers are equally responsible for the project, both want the subdirectory to be in their own directories.",
        "In this situation, the common subdirectory should be shared."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_3_7",
      "title": "11.3.7 General Graph Directory",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 23,
      "definition": "A serious problem with using an acyclic-graph structure is ensuring that there are no cycles.",
      "key_points": [
        "The primary advantage of an acyclic graph is the relative simplicity of the algorithms to traverse the graph and to determine when there are no more references to a \ufb01le.",
        "If we start with a two-level directory and allow users to create subdirectories, a tree-structured directory results.",
        "It should be fairly easy to see that simply adding new \ufb01les and subdirectories to an existing tree-structured directory preserves the tree-structured nature.",
        "However, when we add links, the tree structure is destroyed, resulting in a simple graph structure (Figure 11.13).",
        "We want to avoid traversing shared sections of an acyclic graph twice, mainly for performance reasons."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_4",
      "title": "11.4 File-System Mounting",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 24,
      "definition": "Just as a \ufb01le must be opened before it is used, a \ufb01le system must be mounted before it can be available to processes on the system.",
      "key_points": [
        "Finally, the operating system notes in its directory structure that a \ufb01le system is mounted at the speci\ufb01ed mount point.",
        "More speci\ufb01cally, the directory structure may be built out of multiple volumes, which must be mounted to make them available within the \ufb01le-system name space.",
        "The mount procedure is straightforward.",
        "The operating system is given the name of the device and the mount point\u2014the location within the \ufb01le structure where the \ufb01le system is to be attached.",
        "Some operating systems require that a \ufb01le system type be provided, while others inspect the structures of the device and determine the type of \ufb01le system."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_5",
      "title": "11.5 File Sharing",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 26,
      "definition": "In the previous sections, we explored the motivation for \ufb01le sharing and some of the dif\ufb01culties involved in allowing users to share \ufb01les.",
      "key_points": [
        "Such \ufb01le sharing is very desirable for users who want to collaborate and to reduce the effort required to achieve a computing goal.",
        "Therefore, user-oriented operating systems must accommodate the need to share \ufb01les in spite of the inherent dif\ufb01culties.",
        "In this section, we examine more aspects of \ufb01le sharing.",
        "We begin by discussing general issues that arise when multiple users share \ufb01les.",
        "Once multiple users are allowed to share \ufb01les, the challenge is to extend sharing to multiple \ufb01le systems, including remote \ufb01le systems; we discuss that challenge as well."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_5_1",
      "title": "11.5.1 Multiple Users",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 26,
      "definition": "When an operating system accommodates multiple users, the issues of \ufb01le sharing, \ufb01le naming, and \ufb01le protection become preeminent.",
      "key_points": [
        "Given a directory structure that allows \ufb01les to be shared by users, the system must mediate the \ufb01le sharing.",
        "The system can either allow a user to access the \ufb01les of other users by default or require that a user speci\ufb01cally grant access to the \ufb01les.",
        "These are the issues of access control and protection, which are covered in Section 11.6. To implement sharing and protection, the system must maintain more \ufb01le and directory attributes than are needed on a single-user system.",
        "Although many approaches have been taken to meet this requirement, most systems have evolved to use the concepts of \ufb01le (or directory) owner (or user) and group.",
        "The owner is the user who can change attributes and grant access and who has"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_5_2",
      "title": "11.5.2 Remote File Systems",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 27,
      "definition": "With the advent of networks (Chapter 17), communication among remote computers became possible.",
      "key_points": [
        "Networking allows the sharing ofresources spread across a campus or even around the world.",
        "One obvious resource to share is data in the form of \ufb01les.",
        "Through the evolution of network and \ufb01le technology, remote \ufb01le-sharing methods have changed.",
        "The \ufb01rst implemented method involves manually transferring \ufb01les between machines via programs like ftp.",
        "The second major method uses a distributed \ufb01le system (DFS) in which remote directories are visible from a local machine."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_5_3",
      "title": "11.5.3 Consistency Semantics",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 30,
      "definition": "Consistency semantics represent an important criterion for evaluating any \ufb01le system that supports \ufb01le sharing.",
      "key_points": [
        "Consistency semantics are directly related to the process synchronization algorithms of Chapter 5.",
        "These semantics specify how multiple users of a system are to access a shared \ufb01le simultaneously.",
        "In particular, they specify when modi\ufb01cations of data by one user will be observable by other users.",
        "These semantics are typically implemented as code with the \ufb01le system.",
        "However, the complex algorithms of that chapter tend not to be implemented in the case of \ufb01le I/O because of the great latencies and slow transfer rates of disks and networks."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_6",
      "title": "11.6 Protection",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 31,
      "definition": "When information is stored in a computer system, we want to keep it safe from physical damage (the issue of reliability) and improper access (the issue of protection).",
      "key_points": [
        "Reliability is generally provided by duplicate copies of \ufb01les.",
        "Many comput- ers have systems programs that automatically (or through computer-operator intervention) copy disk \ufb01les to tape at regular intervals (once per day or week or month) to maintain a copy should a \ufb01le system be accidentally destroyed.",
        "File systems can be damaged by hardware problems (such as errors in reading or writing), power surges or failures, head crashes, dirt, temperature extremes, and vandalism.",
        "Files may be deleted accidentally.",
        "Bugs in the \ufb01le-system soft- ware can also cause \ufb01le contents to be lost."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_6_1",
      "title": "11.6.1 Types of Access",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 32,
      "definition": "The need to protect \ufb01les is a direct result of the ability to access \ufb01les.",
      "key_points": [
        "Each has advantages and disadvantages and must be appropriate for its intended application.",
        "Systems that do not permit access to the \ufb01les of other users do not need protection.",
        "Thus, we could provide complete protection by prohibiting access.",
        "Alternatively, we could provide free access with no protection.",
        "Both approaches are too extreme for general use."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_6_2",
      "title": "11.6.2 Access Control",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 32,
      "definition": "The most common approach to the protection problem is to make access dependent on the identity of the user.",
      "key_points": [
        "Different users may need different types of access to a \ufb01le or directory.",
        "The most general scheme to implement identity- dependent access is to associate with each \ufb01le and directory an access-control list (ACL) specifying user names and the types of access allowed for each user.",
        "When a user requests access to a particular \ufb01le, the operating system checks the access list associated with that \ufb01le.",
        "If that user is listed for the requested access, the access is allowed.",
        "Otherwise, a protection violation occurs, and the user job is denied access to the \ufb01le."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_6_3",
      "title": "11.6.3 Other Protection Approaches",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 35,
      "definition": "Another approach to the protection problem is to associate a password with each \ufb01le.",
      "key_points": [
        "Just as access to the computer system is often controlled by a"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_7",
      "title": "11.7 Summary",
      "label": "Topic",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 36,
      "definition": "It is a sequence of logical records.",
      "key_points": [
        "A logical record may be a byte, a line (of \ufb01xed or variable length), or a more complex data item.",
        "The operating system may speci\ufb01cally support various record types or may leave that support to the application program.",
        "The major task for the operating system is to map the logical \ufb01le concept onto physical storage devices such as magnetic disk or tape.",
        "Since the physical record size of the device may not be the same as the logical record size, it may be necessary to order logical records into physical records.",
        "Again, this task may be supported by the operating system or left for the application program."
      ]
    },
    {
      "id": "CHAP_10_SUB_11_1",
      "title": "11.1 Some systems automatically delete all user \ufb01les when a user logs off or",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 37,
      "definition": "a job terminates, unless the user explicitly requests that they be kept. Other systems keep all \ufb01les unless the user explicitly deletes them. Discuss the relative merits of each approach.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_2",
      "title": "11.2 Why do some systems keep track of the type of a \ufb01le, while others leave",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 37,
      "definition": "it to the user and others simply do not implement multiple \ufb01le types? Which system is \u201cbetter\u201d?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_3",
      "title": "11.3 Similarly, some systems support many types of structures for a \ufb01le\u2019s",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 37,
      "definition": "data, while others simply support a stream of bytes. What are the advantages and disadvantages of each approach?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_4",
      "title": "11.4 Could you simulate a multilevel directory structure with a single-level",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 37,
      "definition": "directory structure in which arbitrarily long names can be used? If your answer is yes, explain how you can do so, and contrast this scheme with the multilevel directory scheme. If your answer is no, explain what prevents your simulation\u2019s success. How would your answer change if \ufb01le names were limited to seven characters?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_5",
      "title": "11.5 Explain the purpose of the open() and close() operations.",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 37,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_6",
      "title": "11.6 In some systems, a subdirectory can be read and written by an",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 37,
      "definition": "authorized user, just as ordinary \ufb01les can be. a. Describe the protection problems that could arise. b. Suggest a scheme for dealing with each of these protection problems.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_7",
      "title": "11.7 Consider a system that supports 5,000 users. Suppose that you want to",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 37,
      "definition": "allow 4,990 of these users to be able to access one \ufb01le. a. How would you specify this protection scheme in UNIX?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_8",
      "title": "11.8 Researchers have suggested that, instead of having an access list",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 38,
      "definition": "associated with each \ufb01le (specifying which users can access the \ufb01le, and how), we should have a user control list associated with each user (specifying which \ufb01les a user can access, and how). Discuss the relative merits of these two schemes. Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_9",
      "title": "11.9 Consider a \ufb01le system in which a \ufb01le can be deleted and its disk space",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 38,
      "definition": "reclaimed while links to that \ufb01le still exist. What problems may occur if a new \ufb01le is created in the same storage area or with the same absolute path name? How can these problems be avoided?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_10",
      "title": "11.10 The open-\ufb01le table is used to maintain information about \ufb01les that are",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 38,
      "definition": "currently open. Should the operating system maintain a separate table for each user or maintain just one table that contains references to \ufb01les that are currently being accessed by all users? If the same \ufb01le is being accessed by two different programs or users, should there be separate entries in the open-\ufb01le table? Explain.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_11",
      "title": "11.11 What are the advantages and disadvantages of providing mandatory",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 38,
      "definition": "locks instead of advisory locks whose use is left to users\u2019 discretion?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_12",
      "title": "11.12 Provide examples of applications that typically access \ufb01les according",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 38,
      "definition": "to the following methods: \u2022 Sequential \u2022 Random",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_13",
      "title": "11.13 Some systems automatically open a \ufb01le when it is referenced for the \ufb01rst",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 38,
      "definition": "time and close the \ufb01le when the job terminates. Discuss the advantages and disadvantages of this scheme compared with the more traditional one, where the user has to open and close the \ufb01le explicitly.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_14",
      "title": "11.14 If the operating system knew that a certain application was going",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 38,
      "definition": "to access \ufb01le data in a sequential manner, how could it exploit this information to improve performance?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_15",
      "title": "11.15 Give an example of an application that could bene\ufb01t from operating-",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 38,
      "definition": "system support for random access to indexed \ufb01les.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_16",
      "title": "11.16 Discuss the advantages and disadvantages of supporting links to \ufb01les",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 38,
      "definition": "that cross mount points (that is, the \ufb01le link refers to a \ufb01le that is stored in a different volume).",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_17",
      "title": "11.17 Some systems provide \ufb01le sharing by maintaining a single copy of a",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 38,
      "definition": "\ufb01le. Other systems maintain several copies, one for each of the users sharing the \ufb01le. Discuss the relative merits of each approach.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_18",
      "title": "11.18 Discuss the advantages and disadvantages of associating with remote",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 39,
      "definition": "\ufb01le systems (stored on \ufb01le servers) a set of failure semantics different from that associated with local \ufb01le systems.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10_SUB_11_19",
      "title": "11.19 What are the implications of supporting UNIX consistency semantics",
      "label": "Exercise",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 39,
      "definition": "for shared access to \ufb01les stored on remote \ufb01le systems? Bibliographical Notes Database systems and their \ufb01le structures are described in full in [Silberschatz et al. (2010)]. A multilevel directory structure was \ufb01rst implemented on the MULTICS system ([Organick (1972)]). Most operating systems now implement multilevel directory structures. These include Linux ([Love (2010)]), Mac OS X ([Singh (2007)]), Solaris ([McDougall and Mauro (2007)]), and all versions of Windows ([Russinovich and Solomon ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_10",
      "title": "Chapter 11 File-System Interface",
      "label": "Chapter",
      "file_source": "11_Chapter 11 File-System Interface.pdf",
      "page": 1,
      "definition": "The \ufb01le system consists of two distinct parts: a collection of \ufb01les, each storing related data, and a directory structure, which organizes and provides information about all the \ufb01les in the system.",
      "key_points": [
        "We also discuss the semantics of sharing \ufb01les among multiple processes, users, and computers.",
        "It provides the mechanism for on-line storage of and access to both data and programs of the operating system and all the users of the computer system.",
        "File systems live on devices, which we described in the preceding chapter and will continue to discuss in the following one.",
        "11.1 File Concept: Computers can store information on various storage media, such as magnetic disks...",
        "11.1.1 File Attributes: A \ufb01le is named, for the convenience of its human users, and is referred to by it...",
        "11.1.2 File Operations: A \ufb01le is an abstract data type....",
        "11.1.3 File Types: This attempt normally produces garbage; however, the attempt can succeed if the ...",
        "11.1.4 File Structure: File types also can be used to indicate the internal structure of the \ufb01le...."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_1",
      "title": "12.1 File-System Structure",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 1,
      "definition": "Disks provide most of the secondary storage on which \ufb01le systems are maintained.",
      "key_points": [
        "Two characteristics make them convenient for this purpose: 1.",
        "A disk can be rewritten in place; it is possible to read a block from the disk, modify the block, and write it back into the same place.",
        "A disk can access directly any block of information it contains.",
        "Thus, it is simple to access any \ufb01le either sequentially or randomly, and switching from one \ufb01le to another requires only moving the read\u2013write heads and waiting for the disk to rotate.",
        "We discuss disk structure in great detail in Chapter 10."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_2",
      "title": "12.2 File-System Implementation",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 4,
      "definition": "As was described in Section 11.1.2, operating systems implement open() and close() systems calls for processes to request access to \ufb01le contents.",
      "key_points": [
        "In this section, we delve into the structures and operations used to implement \ufb01le-system operations."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_2_1",
      "title": "12.2.1 Overview",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 4,
      "definition": "Several on-disk and in-memory structures are used to implement a \ufb01le system.",
      "key_points": [
        "These structures vary depending on the operating system and the \ufb01le system, but some general principles apply.",
        "On disk, the \ufb01le system may contain information about how to boot an operating system stored there, the total number of blocks, the number and location of free blocks, the directory structure, and individual \ufb01les.",
        "Many of these structures are detailed throughout the remainder of this chapter.",
        "Here, we describe them brie\ufb02y: \u2022 A boot control block (per volume) can contain information needed by the system to boot an operating system from that volume.",
        "If the disk does not contain an operating system, this block can be empty."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_2_2",
      "title": "12.2.2 Partitions and Mounting",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 7,
      "definition": "The layout of a disk can have many variations, depending on the operating system.",
      "key_points": [
        "Finally, the operating system notes in its in-memory mount table that a \ufb01le system is mounted, along with the type of the \ufb01le system.",
        "Microsoft Windows\u2013based systems mount each volume in a separate name space, denoted by a letter and a colon.",
        "When a process speci\ufb01es the driver letter, the operating system \ufb01nds the appropriate \ufb01le-system pointer and traverses the directory structures on that device to \ufb01nd the speci\ufb01ed \ufb01le"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_2_3",
      "title": "12.2.3 Virtual File Systems",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 8,
      "definition": "The previous section makes it clear that modern operating systems must concurrently support multiple types of \ufb01le systems.",
      "key_points": [
        "The VFS layer serves two important functions: 1.",
        "But how does an operating system allow multiple types of \ufb01le systems to be integrated into a directory structure?",
        "And how can users seamlessly move between \ufb01le-system types as they navigate the \ufb01le-system space?",
        "We now discuss some of these implementation details.",
        "An obvious but suboptimal method of implementing multiple types of \ufb01le systems is to write directory and \ufb01le routines for each type."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_3",
      "title": "12.3 Directory Implementation",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 10,
      "definition": "The selection of directory-allocation and directory-management algorithms signi\ufb01cantly affects the ef\ufb01ciency, performance, and reliability of the \ufb01le system.",
      "key_points": [
        "In this section, we discuss the trade-offs involved in choosing one of these algorithms."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_3_1",
      "title": "12.3.1 Linear List",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 10,
      "definition": "The simplest method of implementing a directory is to use a linear list of \ufb01le names with pointers to the data blocks.",
      "key_points": [
        "The real disadvantage of a linear list of directory entries is that \ufb01nding a \ufb01le requires a linear search.",
        "An advantage of the sorted list is that a sorted directory listing can be produced without a separate sort step.",
        "This method is simple to program but time-consuming to execute.",
        "To create a new \ufb01le, we must \ufb01rst search the directory to be sure that no existing \ufb01le has the same name.",
        "Then, we add a new entry at the end of the directory."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_3_2",
      "title": "12.3.2 Hash Table",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 10,
      "definition": "Another data structure used for a \ufb01le directory is a hash table.",
      "key_points": [
        "Here, a linear list stores the directory entries, but a hash data structure is also used.",
        "The hash table takes a value computed from the \ufb01le name and returns a pointer to the \ufb01le"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_4",
      "title": "12.4 Allocation Methods",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 11,
      "definition": "The direct-access nature of disks gives us \ufb02exibility in the implementation of \ufb01les.",
      "key_points": [
        "Each method has advantages and disadvantages.",
        "In almost every case, many \ufb01les are stored on the same disk.",
        "The main problem is how to allocate space to these \ufb01les so that disk space is utilized effectively and \ufb01les can be accessed quickly.",
        "Three major methods of allocating disk space are in wide use: contiguous, linked, and indexed.",
        "Although some systems support all three, it is more common for a system to use one method for all \ufb01les within a \ufb01le-system type."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_4_1",
      "title": "12.4.1 Contiguous Allocation",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 11,
      "definition": "Contiguous allocation requires that each \ufb01le occupy a set of contiguous blocks on the disk.",
      "key_points": [
        "Disk addresses de\ufb01ne a linear ordering on the disk.",
        "With this ordering, assuming that only one job is accessing the disk, accessing block b + after block b normally requires no head movement.",
        "When head movement is needed (from the last sector of one cylinder to the \ufb01rst sector of the next cylinder), the head need only move from one track to the next.",
        "Thus, the number of disk seeks required for accessing contiguously allocated \ufb01les is minimal, as is seek time when a seek is \ufb01nally needed.",
        "Contiguous allocation of a \ufb01le is de\ufb01ned by the disk address and length (in block units) of the \ufb01rst block."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_4_2",
      "title": "12.4.2 Linked Allocation",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 13,
      "definition": "With linked allocation, each \ufb01le is a linked list of disk blocks; the disk blocks may be scattered anywhere on the disk.",
      "key_points": [
        "The directory contains a pointer to the \ufb01rst"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_4_3",
      "title": "12.4.3 Indexed Allocation",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 15,
      "definition": "Linked allocation solves the external-fragmentation and size-declaration prob- lems of contiguous allocation.",
      "key_points": [
        "However, in the absence of a FAT, linked allocation cannot support ef\ufb01cient direct access, since the pointers to the blocks are scattered with the blocks themselves all over the disk and must be retrieved in order.",
        "Indexed allocation solves this problem by bringing all the pointers together into one location: the index block.",
        "Each \ufb01le has its own index block, which is an array of disk-block addresses.",
        "The ith entry in the index block points to the ith block of the \ufb01le."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_4_4",
      "title": "12.4.4 Performance",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 18,
      "definition": "The allocation methods that we have discussed vary in their storage ef\ufb01ciency and data-block access times.",
      "key_points": [
        "Both are important criteria in selecting the proper method or methods for an operating system to implement.",
        "Before selecting an allocation method, we need to determine how the systems will be used.",
        "A system with mostly sequential access should not use the same method as a system with mostly random access.",
        "For any type of access, contiguous allocation requires only one access to get a disk block.",
        "Since we can easily keep the initial address of the \ufb01le in memory, we can calculate immediately the disk address of the ith block (or the next block) and read it directly."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_5",
      "title": "12.5 Free-Space Management",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 19,
      "definition": "Since disk space is limited, we need to reuse the space from deleted \ufb01les for new \ufb01les, if possible.",
      "key_points": [
        "(Write-once optical disks allow only one write to any given sector, and thus reuse is not physically possible.) To keep track of free disk space, the system maintains a free-space list.",
        "The free-space list records all free disk blocks\u2014those not allocated to some \ufb01le or directory.",
        "To create a \ufb01le, we search the free-space list for the required amount of space and allocate that space to the new \ufb01le.",
        "This space is then removed from the free-space list.",
        "When a \ufb01le is deleted, its disk space is added to the free-space list."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_5_1",
      "title": "12.5.1 Bit Vector",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 19,
      "definition": "Frequently, the free-space list is implemented as a bit map or bit vector.",
      "key_points": [
        "The main advantage of this approach is its relative simplicity and its ef\ufb01ciency in \ufb01nding the \ufb01rst free block or n consecutive free blocks on the disk.",
        "Each block is represented by 1 bit.",
        "If the block is free, the bit is 1; if the block is allocated, the bit is 0.",
        "For example, consider a disk where blocks 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17, 18, 25, 26, and 27 are free and the rest of the blocks are allocated.",
        "The free-space bit map would be ..."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_5_2",
      "title": "12.5.2 Linked List",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 20,
      "definition": "Another approach to free-space management is to link together all the free disk blocks, keeping a pointer to the \ufb01rst free block in a special location on the disk and caching it in memory.",
      "key_points": [
        "This \ufb01rst block contains a pointer to the next free disk block, and so on.",
        "Recall our earlier example (Section 12.5.1), in which blocks 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17, 18, 25, 26, and 27 were free and the rest of the blocks were allocated.",
        "In this situation, we would keep a pointer to block 2 as the \ufb01rst free block.",
        "Block 2 would contain a pointer to block 3, which would point to block 4, which would point to block 5, which would point to block 8, and so on (Figure 12.10).",
        "This scheme is not ef\ufb01cient; to traverse the list, we must read each block, which requires substantial I/O time."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_5_3",
      "title": "12.5.3 Grouping",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 21,
      "definition": "A modi\ufb01cation of the free-list approach stores the addresses of n free blocks in the \ufb01rst free block.",
      "key_points": [
        "The \ufb01rst n\u22121 of these blocks are actually free.",
        "The last block contains the addresses of another n free blocks, and so on.",
        "The addresses of a large number of free blocks can now be found quickly, unlike the situation when the standard linked-list approach is used."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_5_4",
      "title": "12.5.4 Counting",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 21,
      "definition": "Each entry in the free-space list then consists of a disk address and a count.",
      "key_points": [
        "Another approach takes advantage of the fact that, generally, several contigu- ous blocks may be allocated or freed simultaneously, particularly when space is allocated with the contiguous-allocation algorithm or through clustering.",
        "Note that this method of tracking free space is similar to the extent method of allocating blocks.",
        "Thus, rather than keeping a list of n free disk addresses, we can keep the address of the \ufb01rst free block and the number (n) of free contiguous blocks that follow the \ufb01rst block.",
        "Although each entry requires more space than would a simple disk address, the overall list is shorter, as long as the count is generally greater than 1.",
        "These entries can be stored in a balanced tree, rather than a linked list, for ef\ufb01cient lookup, insertion, and deletion."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_5_5",
      "title": "12.5.5 Space Maps",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 21,
      "definition": "Oracle\u2019s ZFS \ufb01le system (found in Solaris and other operating systems) was designed to encompass huge numbers of \ufb01les, directories, and even \ufb01le systems (in ZFS, we can create \ufb01le-system hierarchies).",
      "key_points": [
        "On these scales, metadata I/O can have a large performance impact.",
        "Consider, for example, that if the free-space list is implemented as a bit map, bit maps must be modi\ufb01ed both when blocks are allocated and when they are freed.",
        "Freeing 1 GB of data on a 1-TB disk could cause thousands of blocks of bit maps to be updated, because those data blocks could be scattered over the entire disk.",
        "Clearly, the data structures for such a system could be large and inef\ufb01cient.",
        "In its management of free space, ZFS uses a combination of techniques to control the size of data structures and minimize the I/O needed to manage those structures."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_6",
      "title": "12.6 Ef\ufb01ciency and Performance",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 22,
      "definition": "Now that we have discussed various block-allocation and directory- management options, we can further consider their effect on performance and ef\ufb01cient disk use.",
      "key_points": [
        "Disks tend to represent a major bottleneck in system performance, since they are the slowest main computer component.",
        "In this section, we discuss a variety of techniques used to improve the ef\ufb01ciency and performance of secondary storage."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_6_1",
      "title": "12.6.1 Ef\ufb01ciency",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 22,
      "definition": "The ef\ufb01cient use of disk space depends heavily on the disk-allocation and directory algorithms in use.",
      "key_points": [
        "For instance, UNIX inodes are preallocated on a volume.",
        "Even an empty disk has a percentage of its space lost to inodes.",
        "However, by preallocating the inodes and spreading them across the volume, we improve the \ufb01le system\u2019s performance.",
        "This improved performance results from the UNIX allocation and free-space algorithms, which try to keep a \ufb01le\u2019s data blocks near that \ufb01le\u2019s inode block to reduce seek time.",
        "As another example, let\u2019s reconsider the clustering scheme discussed in Section 12.4, which improves \ufb01le-seek and \ufb01le-transfer performance at the cost of internal fragmentation."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_6_2",
      "title": "12.6.2 Performance",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 23,
      "definition": "Even after the basic \ufb01le-system algorithms have been selected, we can still improve performance in several ways.",
      "key_points": [
        "Several systems\u2014including Solaris, Linux, and Windows \u2014use page caching to cache both process pages and \ufb01le data.",
        "As will be discussed in Chapter 13, most disk controllers include local memory to form an on-board cache that is large enough to store entire tracks at a time.",
        "Once a seek is performed, the track is read into the disk cache starting at the sector under the disk head (reducing latency time).",
        "The disk controller then transfers any sector requests to the operating system.",
        "Once blocks make it from the disk controller into main memory, the operating system may cache the blocks there."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_7",
      "title": "12.7 Recovery",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 26,
      "definition": "Files and directories are kept both in main memory and on disk, and care must be taken to ensure that a system failure does not result in loss of data or in data inconsistency.",
      "key_points": [
        "We deal with these issues in this section.",
        "We also consider how a system can recover from such a failure.",
        "A system crash can cause inconsistencies among on-disk \ufb01le-system data structures, such as directory structures, free-block pointers, and free FCB pointers.",
        "Many \ufb01le systems apply changes to these structures in place.",
        "A typical operation, such as creating a \ufb01le, can involve many structural changes within the \ufb01le system on the disk."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_7_1",
      "title": "12.7.1 Consistency Checking",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 26,
      "definition": "Whatever the cause of corruption, a \ufb01le system must \ufb01rst detect the problems and then correct them.",
      "key_points": [
        "For detection, a scan of all the metadata on each \ufb01le system can con\ufb01rm or deny the consistency of the system.",
        "Unfortunately, this scan can take minutes or hours and should occur every time the system boots.",
        "Alternatively, a \ufb01le system can record its state within the \ufb01le-system metadata.",
        "At the start of any metadata change, a status bit is set to indicate that the metadata is in \ufb02ux.",
        "If all updates to the metadata complete successfully, the \ufb01le system can clear that bit."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_7_2",
      "title": "12.7.2 Log-Structured File Systems",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 27,
      "definition": "Computer scientists often \ufb01nd that algorithms and technologies originally used in one area are equally useful in other areas.",
      "key_points": [
        "Note that with the consistency-checking approach discussed in the pre- ceding section, we essentially allow structures to break and repair them on recovery.",
        "Once the changes are written to this log, they are considered to be committed, and the system call can return to the user process, allowing it to continue execution.",
        "Such is the case with the database log-based recovery algorithms.",
        "These logging algorithms have been applied successfully to the problem of consistency checking.",
        "The resulting implementations are known as log-based transaction-oriented (or journaling) \ufb01le systems."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_7_3",
      "title": "12.7.3 Other Solutions",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 28,
      "definition": "Another alternative to consistency checking is employed by Network Appli- ance\u2019s WAFL \ufb01le system and the Solaris ZFS \ufb01le system.",
      "key_points": [
        "These systems never overwrite blocks with new data.",
        "Rather, a transaction writes all data and meta- data changes to new blocks.",
        "When the transaction is complete, the metadata structures that pointed to the old versions of these blocks are updated to point to the new blocks.",
        "The \ufb01le system can then remove the old pointers and the old blocks and make them available for reuse.",
        "If the old pointers and blocks are kept, a snapshot is created; the snapshot is a view of the \ufb01le system before the last update took place."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_7_4",
      "title": "12.7.4 Backup and Restore",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 28,
      "definition": "Magnetic disks sometimes fail, and care must be taken to ensure that the data lost in such a failure are not lost forever.",
      "key_points": [
        "To this end, system programs can be used to back up data from disk to another storage device, such as a magnetic tape or other hard disk.",
        "Recovery from the loss of an individual \ufb01le, or of an entire disk, may then be a matter of restoring the data from backup.",
        "To minimize the copying needed, we can use information from each \ufb01le\u2019s directory entry.",
        "For instance, if the backup program knows when the last backup of a \ufb01le was done, and the \ufb01le\u2019s last write date in the directory indicates that the \ufb01le has not changed since that date, then the \ufb01le does not need to be copied again.",
        "A typical backup schedule may then be as follows: \u2022 Day 1."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_8",
      "title": "12.8 NFS",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 29,
      "definition": "NFS is a good example of a widely used, well implemented client\u2013server network \ufb01le system.",
      "key_points": [
        "They are typically integrated with the overall directory structure and interface of the client system.",
        "Here, we use it as an example to explore the implementation details of network \ufb01le systems.",
        "NFS is both an implementation and a speci\ufb01cation of a software system for accessing remote \ufb01les across LANs (or even WANs).",
        "NFS is part of ONC+, which most UNIX vendors and some PC operating systems support.",
        "The implementa- tion described here is part of the Solaris operating system, which is a modi\ufb01ed version of UNIX SVR4."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_8_1",
      "title": "12.8.1 Overview",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 30,
      "definition": "NFS views aset ofinterconnected workstations as aset ofindependent machines with independent \ufb01le systems.",
      "key_points": [
        "The goal is to allow some degree of sharing among these \ufb01le systems (on explicit request) in a transparent manner.",
        "Sharing is based on a client\u2013server relationship.",
        "A machine may be, and often is, both a client and a server.",
        "Sharing is allowed between any pair of machines.",
        "To ensure machine independence, sharing of a remote \ufb01le system affects only the client machine and no other machine."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_8_2",
      "title": "12.8.2 The Mount Protocol",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 32,
      "definition": "The mount protocol establishes the initial logical connection between a server and a client.",
      "key_points": [
        "In Solaris, each machine has a server process, outside the kernel, performing the protocol functions.",
        "When the server receives a mount request that conforms to its export list, it returns to the client a \ufb01le handle that serves as the key for further accesses to \ufb01les within the mounted \ufb01le system.",
        "A mount operation includes the name of the remote directory to be mounted and the name of the server machine storing it.",
        "The mount request is mapped to the corresponding RPC and is forwarded to the mount server running on the speci\ufb01c server machine.",
        "The server maintains an export list that speci\ufb01es local \ufb01le systems that it exports for mounting, along with names of machines that are permitted to mount them."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_8_3",
      "title": "12.8.3 The NFS Protocol",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 32,
      "definition": "The NFS protocol provides a set of RPCs for remote \ufb01le operations.",
      "key_points": [
        "A prominent feature of NFS servers is that they are stateless.",
        "The procedures support the following operations: \u2022 Searching for a \ufb01le within a directory \u2022 Reading a set of directory entries \u2022 Manipulating links and directories \u2022 Accessing \ufb01le attributes \u2022 Reading and writing \ufb01les These procedures can be invoked only after a \ufb01le handle for the remotely mounted directory has been established.",
        "The omission of open and close operations is intentional.",
        "Servers do not maintain information about their clients from one access to another."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_8_4",
      "title": "12.8.4 Path-Name Translation",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 34,
      "definition": "Path-name translation in NFS involves the parsing of a path name such as /usr/local/dir1/file.txt into separate directory entries, or components: (1) usr, (2) local, and (3) dir1.",
      "key_points": [
        "Path-name translation is done by breaking the path into component names and performing a separate NFS lookup call for every pair of component name and directory vnode.",
        "Once a mount point is crossed, every component lookup causes a separate RPC to the server.",
        "This expensive path-name-traversal scheme is needed, since the layout of each client\u2019s logical name space is unique, dictated by the mounts the client has performed.",
        "It would be much more ef\ufb01cient to hand a server a path name and receive a target vnode once a mount point is encountered.",
        "At any point, however, there might be another mount point for the particular client of which the stateless server is unaware."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_8_5",
      "title": "12.8.5 Remote Operations",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 35,
      "definition": "With the exception of opening and closing \ufb01les, there is an almost one-to-one correspondence between the regular UNIX system calls for \ufb01le operations and the NFS protocol RPCs. Thus, a remote \ufb01le operation can be translated directly to the corresponding RPC.",
      "key_points": [
        "Conceptually, NFS adheres to the remote-service paradigm; but in practice, buffering and caching techniques are employed for the sake of performance.",
        "No direct correspondence exists between a remote operation and an RPC.",
        "Instead, \ufb01le blocks and \ufb01le attributes are fetched by the RPCs and are cached locally.",
        "Future remote operations use the cached data, subject to consistency constraints.",
        "There are two caches: the \ufb01le-attribute (inode-information) cache and the \ufb01le-blocks cache."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_9",
      "title": "12.9 Example: The WAFL File System",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 35,
      "definition": "WAFL is a powerful, elegant \ufb01le system optimized for random writes.",
      "key_points": [
        "Some \ufb01le systems are general purpose, in that they can provide reasonable performance and functionality for a wide variety of \ufb01le sizes, \ufb01le types, and I/O loads.",
        "Others are optimized for speci\ufb01c tasks in an attempt to provide better performance in those areas than general-purpose \ufb01le systems.",
        "The write-anywhere \ufb01le layout (WAFL) from Network Appliance is an example of this sort of optimization.",
        "WAFL is used exclusively on network \ufb01le servers produced by Network Appliance and is meant for use as a distributed \ufb01le system.",
        "It can provide \ufb01les to clients via the NFS, CIFS, ftp, and http protocols, although it was designed just for NFS and CIFS."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_10",
      "title": "12.10 Summary",
      "label": "Topic",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 38,
      "definition": "The \ufb01le system resides permanently on secondary storage, which is designed to hold a large amount of data permanently.",
      "key_points": [
        "The most common secondary-storage medium is the disk.",
        "Physical disks may be segmented into partitions to control media use and to allow multiple, possibly varying, \ufb01le systems on a single spindle.",
        "These \ufb01le systems are mounted onto a logical \ufb01le system architecture to make them available for use.",
        "File systems are often implemented in a layered or modular structure.",
        "The lower levels deal with the physical properties of storage devices."
      ]
    },
    {
      "id": "CHAP_11_SUB_12_1",
      "title": "12.1 Consider a \ufb01le currently consisting of 100 blocks. Assume that the \ufb01le-",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 39,
      "definition": "control block (and the index block, in the case of indexed allocation) is already in memory. Calculate how many disk I/O operations are required for contiguous, linked, and indexed (single-level) allocation strategies, if, for one block, the following conditions hold. In the contiguous-allocation case, assume that there is no room to grow at the beginning but there is room to grow at the end. Also assume that the block information to be added is stored in memory. a. The block is added at the beg",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_2",
      "title": "12.2 What problems could occur if a system allowed a \ufb01le system to be",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 39,
      "definition": "mounted simultaneously at more than one location?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_3",
      "title": "12.3 Why must the bit map for \ufb01le allocation be kept on mass storage, rather",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 39,
      "definition": "than in main memory?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_4",
      "title": "12.4 Consider a system that supports the strategies of contiguous, linked,",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 39,
      "definition": "and indexed allocation. What criteria should be used in deciding which strategy is best utilized for a particular \ufb01le?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_5",
      "title": "12.5 One problem with contiguous allocation is that the user must preallo-",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 39,
      "definition": "cate enough space for each \ufb01le. If the \ufb01le grows to be larger than the space allocated for it, special actions must be taken. One solution to this problem is to de\ufb01ne a \ufb01le structure consisting of an initial contiguous area (of a speci\ufb01ed size). If this area is \ufb01lled, the operating system automatically de\ufb01nes an over\ufb02ow area that is linked to the initial contiguous area. If the over\ufb02ow area is \ufb01lled, another over\ufb02ow area is allocated. Compare this implementation of a \ufb01le with the standard contig",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_6",
      "title": "12.6 How do caches help improve performance? Why do systems not use",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 40,
      "definition": "more or larger caches if they are so useful?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_7",
      "title": "12.7 Why is it advantageous to the user for an operating system to dynami-",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 40,
      "definition": "cally allocate its internal tables? What are the penalties to the operating system for doing so?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_8",
      "title": "12.8 Explain how the VFS layer allows an operating system to support",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 40,
      "definition": "multiple types of \ufb01le systems easily. Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_9",
      "title": "12.9 Consider a \ufb01le system that uses a modifed contiguous-allocation",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 40,
      "definition": "scheme with support for extents. A \ufb01le is a collection of extents, with each extent corresponding to a contiguous set of blocks. A key issue in such systems is the degree of variability in the size of the extents. What are the advantages and disadvantages of the following schemes? a. All extents are of the same size, and the size is predetermined. b. Extents can be of any size and are allocated dynamically. c. Extents can be of a few \ufb01xed sizes, and these sizes are predeter- mined.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_10",
      "title": "12.10 Contrast the performance of the three techniques for allocating disk",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 40,
      "definition": "blocks (contiguous, linked, and indexed) for both sequential and random \ufb01le access.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_11",
      "title": "12.11 What are the advantages of the variant of linked allocation that uses a",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 40,
      "definition": "FAT to chain together the blocks of a \ufb01le?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_12",
      "title": "12.12 Consider a system where free space is kept in a free-space list.",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 40,
      "definition": "a. Suppose that the pointer to the free-space list is lost. Can the system reconstruct the free-space list? Explain your answer. b. Consider a \ufb01le system similar to the one used by UNIX with indexed allocation. How many disk I/O operations might be required to read the contents of a small local \ufb01le at /a/b/c? Assume that none of the disk blocks is currently being cached. c. Suggest a scheme to ensure that the pointer is never lost as a result of memory failure.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_13",
      "title": "12.13 Some \ufb01le systems allow disk storage to be allocated at different levels",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 40,
      "definition": "of granularity. For instance, a \ufb01le system could allocate 4 KB of disk space as a single 4-KB block or as eight 512-byte blocks. How could we take advantage of this \ufb02exibility to improve performance? What modi\ufb01cations would have to be made to the free-space management scheme in order to support this feature?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_14",
      "title": "12.14 Discuss how performance optimizations for \ufb01le systems might result",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 40,
      "definition": "in dif\ufb01culties in maintaining the consistency of the systems in the event of computer crashes.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_15",
      "title": "12.15 Consider a \ufb01le system on a disk that has both logical and physical",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 41,
      "definition": "block sizes of 512 bytes. Assume that the information about each \ufb01le is already in memory. For each of the three allocation strategies (contiguous, linked, and indexed), answer these questions: a. How is the logical-to-physical address mapping accomplished in this system? (For the indexed allocation, assume that a \ufb01le is always less than 512 blocks long.) b. If we are currently at logical block 10 (the last block accessed was block 10) and want to access logical block 4, how many physical blocks",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_16",
      "title": "12.16 Consider a \ufb01le system that uses inodes to represent \ufb01les. Disk blocks",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 41,
      "definition": "are 8 KB in size, and a pointer to a disk block requires 4 bytes. This \ufb01le system has 12 direct disk blocks, as well as single, double, and triple indirect disk blocks. What is the maximum size of a \ufb01le that can be stored in this \ufb01le system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_17",
      "title": "12.17 Fragmentation on a storage device can be eliminated by recompaction",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 41,
      "definition": "of the information. Typical disk devices do not have relocation or base registers (such as those used when memory is to be compacted), so how can we relocate \ufb01les? Give three reasons why recompacting and relocation of \ufb01les are often avoided.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_18",
      "title": "12.18 Assume that in a particular augmentation of a remote-\ufb01le-access",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 41,
      "definition": "protocol, each client maintains a name cache that caches translations from \ufb01le names to corresponding \ufb01le handles. What issues should we take into account in implementing the name cache?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_19",
      "title": "12.19 Explain why logging metadata updates ensures recovery of a \ufb01le",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 41,
      "definition": "system after a \ufb01le-system crash.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_20",
      "title": "12.20 Consider the following backup scheme:",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 41,
      "definition": "\u2022 Day 1. Copy to a backup medium all \ufb01les from the disk. \u2022 Day 2. Copy to another medium all \ufb01les changed since day 1. \u2022 Day 3. Copy to another medium all \ufb01les changed since day 1. This differs from the schedule given in Section 12.7.4 by having all subsequent backups copy all \ufb01les modi\ufb01ed since the \ufb01rst full backup. What are the bene\ufb01ts of this system over the one in Section 12.7.4? What are the drawbacks? Are restore operations made easier or more dif\ufb01cult? Explain your answer. Programming Pro",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11_SUB_12_21",
      "title": "12.21 In the source code available with this text, open file1.txt and",
      "label": "Exercise",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 42,
      "definition": "examine its contents. Next, obtain the inode number of this \ufb01le with the command ls -li file1.txt This will produce output similar to the following: -rw-r--r-- 2 os os 22 Sep 14 16:13 file1.txt where the inode number is boldfaced. (The inode number of file1.txt is likely to be different on your system.) The UNIX ln command creates a link between a source and target \ufb01le. This command works as follows: ln [-s] <source file> <target file> UNIX provides two types of links: (1) hard links and (2) sof",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_11",
      "title": "Chapter 12 File-System Implementation",
      "label": "Chapter",
      "file_source": "12_Chapter 12 File-System Implementation.pdf",
      "page": 1,
      "definition": "12 C H A P T E R File-System Implementation As we saw in Chapter 11, the \ufb01le system provides the mechanism for on-line storage and access to \ufb01le contents, including data and programs.",
      "key_points": [
        "The \ufb01le system resides permanently on secondary storage, which is designed to hold a large amount of data permanently.",
        "This chapter is primarily concerned with issues surrounding \ufb01le storage and access on the most common secondary-storage medium, the disk.",
        "We explore ways to structure \ufb01le use, to allocate disk space, to recover freed space, to track the locations of data, and to interface other parts of the operating system to secondary storage.",
        "12.1 File-System Structure: Disks provide most of the secondary storage on which \ufb01le systems are maintained....",
        "12.2 File-System Implementation: As was described in Section 11.1.2, operating systems implement open() and close...",
        "12.2.1 Overview: Several on-disk and in-memory structures are used to implement a \ufb01le system....",
        "12.2.2 Partitions and Mounting: The layout of a disk can have many variations, depending on the operating system...",
        "12.2.3 Virtual File Systems: The previous section makes it clear that modern operating systems must concurren..."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_1",
      "title": "13.1 Overview",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 1,
      "definition": "The control of devices connected to the computer is a major concern of operating-system designers.",
      "key_points": [
        "Because I/O devices vary so widely in their function and speed (consider a mouse, a hard disk, and a tape robot), varied methods are needed to control them.",
        "These methods form the I/O subsystem of the kernel, which separates the rest of the kernel from the complexities of managing I/O devices."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_2",
      "title": "13.2 I/O Hardware",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 2,
      "definition": "Computers operate a great many kinds of devices.",
      "key_points": [
        "Most \ufb01t into the general categories of storage devices (disks, tapes), transmission devices (network con- nections, Bluetooth), and human-interface devices (screen, keyboard, mouse, audio in and out).",
        "A typical PC bus structure appears in Figure 13.1. In the \ufb01gure, a PCI bus (the common PC system bus) connects the processor\u2013memory subsystem to fast devices, and an expansion bus connects relatively slow devices, such as the keyboard and serial and USB ports.",
        "Other devices are more specialized, such as those involved in the steering of a jet.",
        "In these aircraft, a human gives input to the \ufb02ight computer via a joystick and foot pedals, and the computer sends output commands that cause motors to move rudders and \ufb02aps and fuels to the engines.",
        "Despite the incredible variety of I/O devices, though, we need only a few concepts to understand how the devices are attached and how the software can control the hardware."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_2_1",
      "title": "13.2.1 Polling",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 5,
      "definition": "(Recall that to set a bit means to write a 1 into the bit and to clear a bit means to write a 0 into it.) The controller sets the busy bit when it is busy working and clears the busy bit when it is ready to accept the next command.",
      "key_points": [
        "In step 1, the host is busy-waiting or polling: it is in a loop, reading the status register over and over until the busy bit becomes clear.",
        "For instance, when data are streaming in on a serial port or from a keyboard, the small buffer on the controller will over\ufb02ow and data will be lost if the host waits too long before returning to read the bytes.",
        "But polling becomes inef\ufb01cient when it is attempted repeatedly yet rarely \ufb01nds a device ready for service, while other useful CPU processing remains undone."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_2_2",
      "title": "13.2.2 Interrupts",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 6,
      "definition": "The basic interrupt mechanism works as follows.",
      "key_points": [
        "The interrupt handler determines the cause of the interrupt, performs the necessary processing, performs a state restore, and executes a return from interrupt instruction to return the CPU to the execution state prior to the interrupt.",
        "In a modern operating system, however, we need more sophisticated interrupt-handling features.",
        "The CPU hardware has a wire called the interrupt-request line that the CPU senses after executing every instruction.",
        "When the CPU detects that a controller has asserted a signal on the interrupt-request line, the CPU performs a state save and jumps to the interrupt-handler routine at a \ufb01xed address in memory.",
        "We say that the device controller raises an interrupt by asserting a signal on the interrupt request line, the CPU catches the interrupt and dispatches it to the interrupt handler, and the handler clears the interrupt by servicing the device."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_2_3",
      "title": "13.2.3 Direct Memory Access",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 9,
      "definition": "For a device that does large transfers, such as a disk drive, it seems wasteful to use an expensive general-purpose processor to watch status bits and to feed data into a controller register one byte at a time\u2014a process termed programmed I/O (PIO).",
      "key_points": [
        "Many computers avoid burdening the main CPU with PIO by of\ufb02oading some of this work to a special-purpose processor called a direct-memory-access (DMA) controller.",
        "To initiate a DMA transfer, the host writes a DMA command block into memory.",
        "This block contains a pointer to the source of a transfer, a pointer to the destination of the transfer, and a count of the number of bytes to be transferred.",
        "The CPU writes the address of this command block to the DMA controller, then goes on with other work.",
        "The DMA controller proceeds to operate the memory bus directly, placing addresses on the bus to perform transfers without the help of the main CPU."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_2_4",
      "title": "13.2.4 I/O Hardware Summary",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 11,
      "definition": "Although the hardware aspects of I/O are complex when considered at the level of detail of electronics-hardware design, the concepts that we have just described are suf\ufb01cient to enable us to understand many I/O features of operating systems.",
      "key_points": [
        "Let\u2019s review the main concepts: \u2022 A bus \u2022 A controller \u2022 An I/O port and its registers \u2022 The handshaking relationship between the host and a device controller \u2022 The execution of this handshaking in a polling loop or via interrupts \u2022 The of\ufb02oading of this work to a DMA controller for large transfers We gave a basic example of the handshaking that takes place between a device controller and the host earlier in this section.",
        "In reality, the wide variety of available devices poses a problem for operating-system implementers.",
        "Each kind of device has its own set of capabilities, control-bit de\ufb01nitions, and protocols for interacting with the host\u2014and they are all different.",
        "How can the operating system be designed so that we can attach new devices to the computer without rewriting the operating system?",
        "And when the devices vary so widely, how can the operating system give a convenient, uniform I/O interface to applications?"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_3",
      "title": "13.3 Application I/O Interface",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 11,
      "definition": "In this section, we discuss structuring techniques and interfaces for the operating system that enable I/O devices to be treated in a standard, uniform way.",
      "key_points": [
        "We explain, for instance, how an application can open a \ufb01le on a disk without knowing what kind of disk it is and how new disks and other devices can be added to a computer without disruption of the operating system.",
        "Like other complex software-engineering problems, the approach here involves abstraction, encapsulation, and software layering.",
        "Speci\ufb01cally, we can abstract away the detailed differences in I/O devices by identifying a few general kinds.",
        "Each general kind is accessed through a standardized set of functions\u2014an interface.",
        "The differences are encapsulated in kernel modules called device drivers that internally are custom-tailored to speci\ufb01c devices but that export one of the standard interfaces."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_3_1",
      "title": "13.3.1 Block and Character Devices",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 14,
      "definition": "If it is a random-access device, it is also expected to have a seek() command to specify which block to transfer next.",
      "key_points": [
        "To avoid these con\ufb02icts, raw-device access passes control of the device directly to the application, letting the operating system step out of the way.",
        "A keyboard is an example of a device that is accessed through a character- stream interface.",
        "This style of access is convenient for input devices such as keyboards, mice, and modems that produce data for input \u201cspontaneously\u201d \u2014that is, at times that cannot necessarily be predicted by the application."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_3_2",
      "title": "13.3.2 Network Devices",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 14,
      "definition": "Because the performance and addressing characteristics of network I/O differ signi\ufb01cantly from those of disk I/O, most operating systems provide a network",
      "key_points": []
    },
    {
      "id": "CHAP_12_SUB_13_3_3",
      "title": "13.3.3 Clocks and Timers",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 15,
      "definition": "Most computers have hardware clocks and timers that provide three basic functions: \u2022 Give the current time.",
      "key_points": [
        "It can be set to wait a certain amount of time and then generate an interrupt, and it can be set to do this once or to repeat the process to generate periodic interrupts.",
        "The scheduler uses this mechanism to generate an interrupt that will preempt a process at the end of its time slice.",
        "The operating system may also provide an interface for user processes to use timers."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_3_4",
      "title": "13.3.4 Nonblocking and Asynchronous I/O",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 16,
      "definition": "Another aspect of the system-call interface relates to the choice between blocking I/O and nonblocking I/O.",
      "key_points": [
        "Some user-level processes need nonblocking I/O.",
        "One example is a user interface that receives keyboard and mouse input while processing and displaying data on the screen.",
        "When an application issues a blocking system call, the execution of the application is suspended.",
        "The application is moved from the operating system\u2019s run queue to a wait queue.",
        "After the system call completes, the application is moved back to the run queue, where it is eligible to resume execution."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_3_5",
      "title": "13.3.5 Vectored I/O",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 17,
      "definition": "Some operating systems provide another major variation of I/O via their applications interfaces.",
      "key_points": [
        "vectored I/O allows one system call to perform multiple I/Ooperations involving multiple locations.",
        "For example, the UNIXreadv"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_4",
      "title": "13.4 Kernel I/O Subsystem",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 18,
      "definition": "Kernels provide many services related to I/O.",
      "key_points": [
        "The I/O subsystem is also responsible for protecting itself from errant processes and malicious users.",
        "Several services\u2014scheduling, buffering, caching, spooling, device reservation, and error handling\u2014are provided by the kernel\u2019s I/O subsystem and build on the hardware and device- driver infrastructure."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_4_1",
      "title": "13.4.1 I/O Scheduling",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 18,
      "definition": "To schedule a set of I/O requests means to determine a good order in which to execute them.",
      "key_points": [
        "Scheduling can improve overall system performance, can share device access fairly among processes, and can reduce the average waiting time for I/O to complete.",
        "The order in which applications issue system calls rarely is the best choice.",
        "Here is a simple example to illustrate.",
        "Suppose that a disk arm is near the beginning of a disk and that three applications issue blocking read calls to that disk.",
        "Application 1 requests a block near the end of the disk, application 2 requests one near the beginning, and application 3 requests one in the middle of the disk."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_4_2",
      "title": "13.4.2 Buffering",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 19,
      "definition": "A buffer, of course, is a memory area that stores data being transferred between two devices or between a device and an application.",
      "key_points": [
        "Buffering is done for three reasons.",
        "One reasonistocope withaspeed mismatchbetweenthe producer and consumer of a data stream.",
        "Suppose, for example, that a \ufb01le is being received via modem for storage on the hard disk.",
        "The modem is about a thousand times slower than the hard disk.",
        "So a buffer is created in main memory to accumulate the bytes received from the modem."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_4_3",
      "title": "13.4.3 Caching",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 20,
      "definition": "A cacheis aregionoffast memory that holds copies ofdata.",
      "key_points": [
        "Access tothe cached copy is more ef\ufb01cient than access to the original.",
        "For instance, the instructions"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_4_4",
      "title": "13.4.4 Spooling and Device Reservation",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 21,
      "definition": "A spool is a buffer that holds output for a device, such as a printer, that cannot accept interleaved data streams.",
      "key_points": [
        "In some operating systems, spooling is managed by a system daemon process.",
        "Some operating systems (including VMS) provide support for exclusive device access by enabling a process to allocate an idle device and to deallocate that device when it is no longer needed.",
        "Many operating systems provide functions that enable processes to coordinate exclusive access among themselves."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_4_5",
      "title": "13.4.5 Error Handling",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 21,
      "definition": "An operating system that uses protected memory can guard against many kinds of hardware and application errors, so that a complete system failure is",
      "key_points": []
    },
    {
      "id": "CHAP_12_SUB_13_4_6",
      "title": "13.4.6 I/O Protection",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 22,
      "definition": "Errors are closely related to the issue of protection.",
      "key_points": [
        "A user process may accidentally or purposely attempt to disrupt the normal operation of a system by attempting to issue illegal I/O instructions.",
        "Note that a kernel cannot simply deny all user access.",
        "The kernel might in this case provide a locking mechanism to allow a section of graphics memory (representing a window on screen) to be allocated to one process at a time."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_4_7",
      "title": "13.4.7 Kernel Data Structures",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 22,
      "definition": "The kernel needs to keep state information about the use of I/O components.",
      "key_points": [
        "It does so through a variety of in-kernel data structures, such as the open-\ufb01le"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_4_8",
      "title": "13.4.8 Kernel I/O Subsystem Summary",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 24,
      "definition": "In summary, the I/O subsystem coordinates an extensive collection of services that are available to applications and to other parts of the kernel.",
      "key_points": [
        "The I/O subsystem supervises these procedures: \u2022 Management of the name space for \ufb01les and devices \u2022 Access control to \ufb01les and devices \u2022 Operation control (for example, a modem cannot seek()) \u2022 File-system space allocation \u2022 Device allocation \u2022 Buffering, caching, and spooling \u2022 I/O scheduling \u2022 Device-status monitoring, error handling, and failure recovery \u2022 Device-driver con\ufb01guration and initialization The upper levels of the I/O subsystem access devices via the uniform interface provided by the device drivers."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_5",
      "title": "13.5 Transforming I/O Requests to Hardware Operations",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 25,
      "definition": "The application refers to the data by a \ufb01le name.",
      "key_points": [
        "For example, C: is the \ufb01rst part of every \ufb01le name on the primary hard disk.",
        "The fact that C: represents the primary hard disk is built into the operating system; C: is mapped to a speci\ufb01c port address through a device table.",
        "Consider, for example, reading a \ufb01le from disk.",
        "Within a disk, the \ufb01le system maps from the \ufb01le name through the \ufb01le-system directories to obtain the space allocation of the \ufb01le.",
        "For instance, in MS-DOS, the name maps to a number that indicates an entry in the \ufb01le-access table, and that table entry tells which disk blocks are allocated to the \ufb01le."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_6",
      "title": "13.6 STREAMS",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 27,
      "definition": "A stream is a full-duplex connection between a device driver and a user-level process.",
      "key_points": [
        "It consists of a stream head that interfaces with the user process, a driver end that controls the device, and zero or more stream modules between the stream head and the driver end.",
        "Modules provide the functionality of STREAMS processing; they are pushed onto a stream by use of the ioctl() system call.",
        "For example, a process can open a serial-port device via a stream and can push on a module to handle input editing."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_7",
      "title": "13.7 Performance",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 29,
      "definition": "I/O is a major factor in system performance.",
      "key_points": [
        "It places heavy demands on the CPU to execute device-driver code and to schedule processes fairly and ef\ufb01ciently as they block and unblock.",
        "An I/O completion typically unblocks a process, leading to the full overhead of a context switch.",
        "On the local machine, the character is typed; a keyboard interrupt is generated; and the character is passed through the interrupt handler to the device driver, to the kernel, and then to the user process.",
        "The user process issues a network I/O system call to send the character to the remote machine."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_8",
      "title": "13.8 Summary",
      "label": "Topic",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 32,
      "definition": "The kernel module that controls a device is a device driver.",
      "key_points": [
        "The system calls usually block the processes that issue them, but nonblocking and asynchronous calls are used by the kernel itself and by applications that must not sleep while waiting for an I/O operation to complete.",
        "The work of moving data between devices and main memory is performed by the CPU as programmed I/O or is of\ufb02oaded to a DMA controller.",
        "The system-call interface provided to applications is designed to handle several basic categories of hardware, including block devices, character devices, memory-mapped \ufb01les, network sockets, and programmed interval timers.",
        "The kernel\u2019s I/O subsystem provides numerous services.",
        "Among these are I/O scheduling, buffering, caching, spooling, device reservation, and error handling."
      ]
    },
    {
      "id": "CHAP_12_SUB_13_1",
      "title": "13.1 State three advantages of placing functionality in a device controller,",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 33,
      "definition": "rather than in the kernel. State three disadvantages.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_2",
      "title": "13.2 The example of handshaking in Section 13.2 used two bits: a busy bit",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 33,
      "definition": "and a command-ready bit. Is it possible to implement this handshaking with only one bit? If it is, describe the protocol. If it is not, explain why one bit is insuf\ufb01cient.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_3",
      "title": "13.3 Why might a system use interrupt-driven I/O to manage a single serial",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 33,
      "definition": "port and polling I/O to manage a front-end processor, such as a terminal concentrator?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_4",
      "title": "13.4 Polling for an I/O completion can waste a large number of CPU cycles",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 33,
      "definition": "if the processor iterates a busy-waiting loop many times before the I/O completes. But if the I/O device is ready for service, polling can be much more ef\ufb01cient than is catching and dispatching an interrupt. Describe a hybrid strategy that combines polling, sleeping, and interrupts for I/O device service. For each of these three strategies (pure polling, pure interrupts, hybrid), describe a computing environment in which that strategy is more ef\ufb01cient than is either of the others.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_5",
      "title": "13.5 How does DMA increase system concurrency? How does it complicate",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 33,
      "definition": "hardware design?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_6",
      "title": "13.6 Why is it important to scale up system-bus and device speeds as CPU",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 33,
      "definition": "speed increases?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_7",
      "title": "13.7 Distinguish between a STREAMS driver and a STREAMS module.",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 33,
      "definition": "Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_8",
      "title": "13.8 When multiple interrupts from different devices appear at about the",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 33,
      "definition": "same time, a priority scheme could be used to determine the order in which the interrupts would be serviced. Discuss what issues need to be considered in assigning priorities to different interrupts.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_9",
      "title": "13.9 What are the advantages and disadvantages of supporting memory-",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 33,
      "definition": "mapped I/O to device control registers?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_10",
      "title": "13.10 Consider the following I/O scenarios on a single-user PC:",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 34,
      "definition": "a. A mouse used with a graphical user interface b. A tape drive on a multitasking operating system (with no device preallocation available) c. A disk drive containing user \ufb01les d. A graphics card with direct bus connection, accessible through memory-mapped I/O For each of these scenarios, would you design the operating system to use buffering, spooling, caching, or a combination? Would you use polled I/O or interrupt-driven I/O? Give reasons for your choices.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_11",
      "title": "13.11 In most multiprogrammed systems, user programs access memory",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 34,
      "definition": "through virtual addresses, while the operating system uses raw phys- ical addresses to access memory. What are the implications of this design for the initiation of I/O operations by the user program and their execution by the operating system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_12",
      "title": "13.12 What are the various kinds of performance overhead associated with",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 34,
      "definition": "servicing an interrupt?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_13",
      "title": "13.13 Describe three circumstances under which blocking I/O should be used.",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 34,
      "definition": "Describe three circumstances under which nonblocking I/O should be used. Why not just implement nonblocking I/O and have processes busy-wait until their devices are ready?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_14",
      "title": "13.14 Typically, at the completion of a device I/O, a single interrupt is raised",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 34,
      "definition": "and appropriately handled by the host processor. In certain settings, however, the code that is to be executed at the completion of the I/O can be broken into two separate pieces. The \ufb01rst piece executes immediately after the I/O completes and schedules a second interrupt for the remaining piece of code to be executed at a later time. What is the purpose of using this strategy in the design of interrupt handlers?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_15",
      "title": "13.15 Some DMA controllers support direct virtual memory access, where",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 34,
      "definition": "the targets of I/O operations are speci\ufb01ed as virtual addresses and a translation from virtual to physical address is performed during the DMA. How does this design complicate the design of the DMA controller? What are the advantages of providing such functionality?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_16",
      "title": "13.16 UNIX coordinates the activities of the kernel I/O components by",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 34,
      "definition": "manipulating shared in-kernel data structures, whereas Windows uses object-oriented message passing between kernel I/O components. Discuss three pros and three cons of each approach.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_17",
      "title": "13.17 Write (in pseudocode) an implementation of virtual clocks, including",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 34,
      "definition": "the queueing and management of timer requests for the kernel and applications. Assume that the hardware provides three timer channels.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12_SUB_13_18",
      "title": "13.18 Discuss the advantages and disadvantages of guaranteeing reliable",
      "label": "Exercise",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 34,
      "definition": "transfer of data between modules in the STREAMS abstraction.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_12",
      "title": "Chapter 13 IO Systems",
      "label": "Chapter",
      "file_source": "13_Chapter 13 IO Systems.pdf",
      "page": 1,
      "definition": "13 C H A P T E R I/O Systems The two main jobs of a computer are I/O and processing.",
      "key_points": [
        "In many cases, the main job is I/O, and the processing is merely incidental.",
        "For instance, when we browse a web page or edit a \ufb01le, our immediate interest is to read or enter some information, not to compute an answer.",
        "The role of the operating system in computer I/O is to manage and control I/O operations and I/O devices.",
        "13.1 Overview: The control of devices connected to the computer is a major concern of operating...",
        "13.2 I/O Hardware: Computers operate a great many kinds of devices....",
        "13.2.1 Polling: (Recall that to set a bit means to write a 1 into the bit and to clear a bit mea...",
        "13.2.2 Interrupts: The basic interrupt mechanism works as follows....",
        "13.2.3 Direct Memory Access: For a device that does large transfers, such as a disk drive, it seems wasteful ..."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_1",
      "title": "14.1 Goals of Protection",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 1,
      "definition": "As computer systems have become more sophisticated and pervasive in their applications, the need to protect their integrity has also grown.",
      "key_points": [
        "Protection was originally conceived as an adjunct to multiprogramming operating systems, so that untrustworthy users might safely share a common logical name space, such as a directory of \ufb01les, or share a common physical name space, such as memory.",
        "Modern protection concepts have evolved to increase the reliability of any complex system that makes use of shared resources.",
        "We need to provide protection for several reasons.",
        "The most obvious is the need to prevent the mischievous, intentional violation of an access restriction"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_2",
      "title": "14.2 Principles of Protection",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 2,
      "definition": "Frequently, a guiding principle can be used throughout a project, such as the design of an operating system.",
      "key_points": [
        "A key, time-tested guiding principle for protection is the principle of least privilege.",
        "Consider the analogy of a security guard with a passkey.",
        "If this key allows the guard into just the public areas that she guards, then misuse of the key will result in minimal damage.",
        "If, however, the passkey allows access to all areas, then damage from its being lost, stolen, misused, copied, or otherwise compromised will be much greater.",
        "An operating system following the principle of least privilege implements its features, programs, system calls, and data structures so that failure or compromise of a component does the minimum damage and allows the minimum damage to be done."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_3",
      "title": "14.3 Domain of Protection",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 3,
      "definition": "A computer system is a collection of processes and objects.",
      "key_points": [
        "A process should be allowed to access only those resources for which it has authorization.",
        "Furthermore, at any time, a process should be able to access only those resources that it currently requires to complete its task.",
        "This second requirement, commonly referred to as the need-to-know principle, is useful in limiting the amount of damage a faulty process can cause in the system."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_3_1",
      "title": "14.3.1 Domain Structure",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 4,
      "definition": "A domain is a collection of access rights, each of which is an ordered pair <object-name, rights-set>.",
      "key_points": [
        "To facilitate the scheme just described, a process operates within a protection domain, which speci\ufb01es the resources that the process may access.",
        "For example, if domain D has the access right <file F, {read,write}>, then a process executing in domain D can both read and write \ufb01le F.",
        "The access right <O4, {print}> is shared by D2 and D3, implying that a process executing in either of these two domains can print object O4.",
        "Note that a process must be executing in domain D1 to read and write object O1, while only processes in domain D3 may execute object O1.",
        "The association between a process and a domain may be either static, if the set of resources available to the process is \ufb01xed throughout the process\u2019s lifetime, or dynamic."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_3_2",
      "title": "14.3.2 An Example: UNIX",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 5,
      "definition": "In the UNIX operating system, a domain is associated with the user.",
      "key_points": [
        "For example, when a user A (that is, a user with userID = A) starts executing a \ufb01le owned by B, whose associated domain bit is off, the userID of the process is set to A.",
        "Switching the domain corresponds to changing the user identi\ufb01cation temporarily.",
        "This change is accomplished through the \ufb01le system as follows.",
        "An owner identi\ufb01cation and a domain bit (known as the setuid bit) are associated with each \ufb01le.",
        "When the setuid bit is on, and a user executes that \ufb01le, the userID is set to that of the owner of the \ufb01le."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_3_3",
      "title": "14.3.3 An Example: MULTICS",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 6,
      "definition": "If j < i, then Di is a subset of Dj. That is, a process executing in domain Dj has more privileges than does a process executing in domain Di. A process executing in domain D0 has the most privileges.",
      "key_points": [
        "Each ring corresponds to a single domain (Figure 14.2).",
        "The rings are numbered from 0 to 7.",
        "Let Di and Dj be any two domain rings.",
        "If only two rings exist, this scheme is equivalent to the monitor\u2013user mode of execution, where monitor mode corresponds to D0 and user mode corresponds to D1.",
        "MULTICS has a segmented address space; each segment is a \ufb01le, and each segment is associated with one of the rings."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_4",
      "title": "14.4 Access Matrix",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 8,
      "definition": "Each entry in the matrix consists of a set of access rights.",
      "key_points": [
        "The entry access(i,j) de\ufb01nes the set of operations that a process executing in domain Di can invoke on object Oj. To illustrate these concepts, we consider the access matrix shown in Figure 14.3. There are four domains and four objects\u2014three \ufb01les (F1, F2, F3) and one laser printer.",
        "A process executing in domain D1 can read \ufb01les F1 and F3.",
        "A process executing in domain D4 has the same privileges as one executing in object printer read read execute read write read write read print F1 D1 D2 D3 D4 F2 F3 domain Figure 14.3 Access matrix."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_5",
      "title": "14.5 Implementation of the Access Matrix",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 12,
      "definition": "How can the access matrix be implemented effectively?",
      "key_points": [
        "In general, the matrix will be sparse; that is, most of the entries will be empty.",
        "Although data- structure techniques are available for representing sparse matrices, they are not particularly useful for this application, because of the way in which the protection facility is used.",
        "Here, we \ufb01rst describe several methods of implementing the access matrix and then compare the methods."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_5_1",
      "title": "14.5.1 Global Table",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 12,
      "definition": "The simplest implementation of the access matrix is a global table consisting of a set of ordered triples <domain, object, rights-set>.",
      "key_points": [
        "In addition, it is dif\ufb01cult to take advantage of special groupings of objects or domains.",
        "Whenever an operation M is executed on an object Oj within domain Di, the global table is searched for a triple <Di, Oj, Rk>, with M \u2208Rk. If this triple is found, the operation is allowed to continue; otherwise, an exception (or error) condition is raised.",
        "This implementation suffers from several drawbacks.",
        "The table is usually large and thus cannot be kept in main memory, so additional I/O is needed.",
        "Virtual memory techniques are often used for managing this table."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_5_2",
      "title": "14.5.2 Access Lists for Objects",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 12,
      "definition": "The resulting list for each object consists of ordered pairs <domain, rights-set>, which de\ufb01ne all domains with a nonempty set of access rights for that object.",
      "key_points": [
        "This approach can be extended easily to de\ufb01ne a list plus a default set of access rights.",
        "When an operation M on an object Oj is attempted in domain"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_5_3",
      "title": "14.5.3 Capability Lists for Domains",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 13,
      "definition": "A capability list for a domain is a list of objects together with the operations allowed on those objects.",
      "key_points": [
        "To execute operation M on object Oj, the process executes the operation M, specifying the capability (or pointer) for object Oj as a parameter.",
        "The capability list is associated with a domain, but it is never directly accessible to a process executing in that domain.",
        "Capability-based protection relies on the fact that the capabilities are never allowed to migrate into any address space directly accessible by a user process (where they could be modi\ufb01ed).",
        "Capabilities are usually distinguished from other data in one of two ways: \u2022 Each object has a tag to denote whether it is a capability or accessible data."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_5_4",
      "title": "14.5.4 A Lock\u2013Key Mechanism",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 14,
      "definition": "The lock\u2013key scheme is a compromise between access lists and capability lists.",
      "key_points": [
        "Similarly, each domain has a list of unique bit patterns, called keys.",
        "A process executing in a domain can access an object only if that domain has a key that matches one of the locks of the object.",
        "As with capability lists, the list of keys for a domain must be managed by the operating system on behalf of the domain.",
        "Users are not allowed to examine or modify the list of keys (or locks) directly."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_5_5",
      "title": "14.5.5 Comparison",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 14,
      "definition": "As you might expect, choosing a technique for implementing an access matrix involves various trade-offs.",
      "key_points": [
        "Using a global table is simple; however, the table can be quite large and often cannot take advantage of special groupings of objects or domains.",
        "Capability lists do not correspond directly to the needs of users, but they are useful for localizing information for a given process.",
        "The process attempting access must present a capability for that access.",
        "The lock\u2013key mechanism, as mentioned, is a compromise between access lists and capability lists.",
        "The mechanism can be both effective and \ufb02exible, depending on the length of the keys."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_6",
      "title": "14.6 Access Control",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 15,
      "definition": "In Section 11.6.2, we described how access controls can be used on \ufb01les within a \ufb01le system.",
      "key_points": [
        "Privileges can be assigned to processes, limiting them to exactly the access they need to perform their work.",
        "user 1 role 1 privileges 1 executes with role 1 privileges privileges 2 process Figure 14.8 Role-based access control in Solaris 10.",
        "Each \ufb01le and directory is assigned an owner, a group, or possibly a list of users, and for each of those entities, access-control information is assigned.",
        "A similar function can be added to other aspects of a computer system.",
        "A good example of this is found in Solaris 10."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_7",
      "title": "14.7 Revocation of Access Rights",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 16,
      "definition": "In a dynamic protection system, we may sometimes need to revoke access rights to objects shared by different users.",
      "key_points": [
        "If a process wants to use a capability, it may \ufb01nd that that capability has been deleted.",
        "The process may then try to reacquire the capability.",
        "If access has been revoked, the process will not be able to reacquire the capability."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_8",
      "title": "14.8 Capability-Based Systems",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 17,
      "definition": "In this section, we survey two capability-based protection systems.",
      "key_points": [
        "These systems differ in their complexity and in the types of policies that can be implemented on them.",
        "Neither system is widely used, but both provide interesting proving grounds for protection theories."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_8_1",
      "title": "14.8.1 An Example: Hydra",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 17,
      "definition": "Hydra is a capability-based protection system that provides considerable \ufb02exibility.",
      "key_points": [
        "The system implements a \ufb01xed set of possible access rights, including such basic forms of access as the right to read, write, or execute a memory segment.",
        "In addition, a user (of the protection system) can declare other rights.",
        "The interpretation of user-de\ufb01ned rights is performed solely by the user\u2019s program, but the system provides access protection for the use of these rights, as well as for the use of system-de\ufb01ned rights.",
        "These facilities constitute a signi\ufb01cant development in protection technology.",
        "Operations on objects are de\ufb01ned procedurally."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_8_2",
      "title": "14.8.2 An Example: Cambridge CAP System",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 19,
      "definition": "A different approach to capability-based protection has been taken in the design of the Cambridge CAP system.",
      "key_points": [
        "When executing the code body of such a procedure, a process temporarily acquires the right to read or write the contents of a software capability itself.",
        "(See the bibliographical notes at the end of the chapter for references.) The interpretation of a software capability is left completely to the sub- system, through the protected procedures it contains.",
        "CAP\u2019s capability system is simpler and super\ufb01cially less powerful than that of Hydra.",
        "However, closer examination shows that it, too, can be used to provide secure protection of user-de\ufb01ned objects.",
        "CAP has two kinds of capabilities."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_9",
      "title": "14.9 Language-Based Protection",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 20,
      "definition": "To the degree that protection is provided in existing computer systems, it is usually achieved through an operating-system kernel, which acts as a security agent to inspect and validate each attempt to access a protected resource.",
      "key_points": [
        "Since comprehensive access validation may be a source of considerable overhead, either we must give it hardware support to reduce the cost of each validation, or we must allow the system designer to compromise the goals of protection.",
        "Satisfying all these goals is dif\ufb01cult if the \ufb02exibility to implement protection policies is restricted by the support mechanisms provided or if protection environments are made larger than necessary to secure greater operational ef\ufb01ciency.",
        "As operating systems have become more complex, and particularly as they have attempted to provide higher-level user interfaces, the goals of protection have become much more re\ufb01ned.",
        "The designers of protection systems have drawn heavily on ideas that originated in programming languages and especially on the concepts of abstract data types and objects.",
        "Protection systems are now concerned not only with the identity of a resource to which access is attempted but also with the functional nature of that access."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_9_1",
      "title": "14.9.1 Compiler-Based Enforcement",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 20,
      "definition": "At this point, programming languages enter the picture.",
      "key_points": [
        "This approach has several signi\ufb01cant advantages:",
        "Specifying the desired control of access to a shared resource in a system is making a declarative statement about the resource.",
        "This kind of statement can be integrated into a language by an extension of its typing facility.",
        "When protection is declared along with data typing, the designer of each subsystem can specify its requirements for protection, as well as its need for use of other resources in a system.",
        "Such a speci\ufb01cation should be given directly as a program is composed, and in the language in which the program itself is stated."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_9_2",
      "title": "14.9.2 Protection in Java",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 23,
      "definition": "Java programs are composed of classes, each of which is a collection of data \ufb01elds and functions (called methods) that operate on those \ufb01elds.",
      "key_points": [
        "One of the most novel and useful features of Java is its support for dynamically loading untrusted classes over a network and for executing mutually distrusting classes within the same JVM.",
        "As a result, enforcing protection at the granularity of the JVM process is insuf\ufb01cient.",
        "The JVM loads a class in response to a request to create instances (or objects) of that class.",
        "Because of these capabilities, protection is a paramount concern.",
        "Classes running in the same JVM may be from different sources and may not be equally trusted."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_10",
      "title": "14.10 Summary",
      "label": "Topic",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 25,
      "definition": "A domain is a set of access rights.",
      "key_points": [
        "Processes execute in domains and may use any of the access rights in the domain to access and manipulate objects.",
        "During its lifetime, a process may be either bound to a protection domain or allowed to switch from one domain to another.",
        "Objects may be hardware (such as memory, CPU time, and I/O devices) or software (such as \ufb01les, programs, and semaphores).",
        "An access right is permission to perform an operation on an object."
      ]
    },
    {
      "id": "CHAP_13_SUB_14_1",
      "title": "14.1 What are the main differences between capability lists and access lists?",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 26,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_2",
      "title": "14.2 A Burroughs B7000/B6000 MCP \ufb01le can be tagged as sensitive data.",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 26,
      "definition": "When such a \ufb01le is deleted, its storage area is overwritten by some random bits. For what purpose would such a scheme be useful?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_3",
      "title": "14.3 In a ring-protection system, level 0 has the greatest access to objects,",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 26,
      "definition": "and level n (where n > 0) has fewer access rights. The access rights of a program at a particular level in the ring structure are considered a set of capabilities. What is the relationship between the capabilities of a domain at level j and a domain at level i to an object (for j > i)?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_4",
      "title": "14.4 The RC 4000 system, among others, has de\ufb01ned a tree of processes",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 26,
      "definition": "(called a process tree) such that all the descendants of a process can be given resources (objects) and access rights by their ancestors only. Thus, a descendant can never have the ability to do anything that its ancestors cannot do. The root of the tree is the operating system, which has the ability to do anything. Assume that the set of access rights is represented by an access matrix, A. A(x,y) de\ufb01nes the access rights of process x to object y. If x is a descendant of z, what is the relations",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_5",
      "title": "14.5 What protection problems may arise if a shared stack is used for",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 26,
      "definition": "parameter passing?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_6",
      "title": "14.6 Consider a computing environment where a unique number is associ-",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "ated with each process and each object in the system. Suppose that we allow a process with number n to access an object with number m only if n > m. What type of protection structure do we have?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_7",
      "title": "14.7 Consider a computing environment where a process is given the",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "privilege of accessing an object only n times. Suggest a scheme for implementing this policy.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_8",
      "title": "14.8 If all the access rights to an object are deleted, the object can no longer",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "be accessed. At this point, the object should also be deleted, and the space it occupies should be returned to the system. Suggest an ef\ufb01cient implementation of this scheme.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_9",
      "title": "14.9 Why is it dif\ufb01cult to protect a system in which users are allowed to do",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "their own I/O?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_10",
      "title": "14.10 Capability lists are usually kept within the address space of the user.",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "How does the system ensure that the user cannot modify the contents of the list? Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_11",
      "title": "14.11 Consider the ring-protection scheme in MULTICS. If we were to imple-",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "ment the system calls of a typical operating system and store them in a segment associated with ring 0, what should be the values stored in the ring \ufb01eld of the segment descriptor? What happens during a system call when a process executing in a higher-numbered ring invokes a procedure in ring 0?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_12",
      "title": "14.12 The access-control matrix can be used to determine whether a process",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "can switch from, say, domain A to domain B and enjoy the access privileges of domain B. Is this approach equivalent to including the access privileges of domain B in those of domain A?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_13",
      "title": "14.13 Consider a computer system in which computer games can be played",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "by students only between 10 P.M. and 6 A.M., by faculty members between 5 P.M. and 8 A.M., and by the computer center staff at all times. Suggest a scheme for implementing this policy ef\ufb01ciently.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_14",
      "title": "14.14 What hardware features does a computer system need for ef\ufb01cient",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "capability manipulation? Can these features be used for memory protection?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_15",
      "title": "14.15 Discuss the strengths and weaknesses of implementing an access matrix",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "using access lists that are associated with objects.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_16",
      "title": "14.16 Discuss the strengths and weaknesses of implementing an access matrix",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "using capabilities that are associated with domains.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_17",
      "title": "14.17 Explain why a capability-based system such as Hydra provides greater",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 27,
      "definition": "\ufb02exibility than the ring-protection scheme in enforcing protection policies.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_18",
      "title": "14.18 Discuss the need for rights ampli\ufb01cation in Hydra. How does this",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 28,
      "definition": "practice compare with the cross-ring calls in a ring-protection scheme?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_19",
      "title": "14.19 What is the need-to-know principle? Why is it important for a protec-",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 28,
      "definition": "tion system to adhere to this principle?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_20",
      "title": "14.20 Discuss which of the following systems allow module designers to",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 28,
      "definition": "enforce the need-to-know principle. a. The MULTICS ring-protection scheme b. Hydra\u2019s capabilities c. JVM\u2019s stack-inspection scheme",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_21",
      "title": "14.21 Describe how the Java protection model would be compromised if a",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 28,
      "definition": "Java program were allowed to directly alter the annotations of its stack frame.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_22",
      "title": "14.22 How are the access-matrix facility and the role-based access-control",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 28,
      "definition": "facility similar? How do they differ?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_23",
      "title": "14.23 How does the principle of least privilege aid in the creation of protection",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 28,
      "definition": "systems?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13_SUB_14_24",
      "title": "14.24 How can systems that implement the principle of least privilege still",
      "label": "Exercise",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 28,
      "definition": "have protection failures that lead to security violations? Bibliographical Notes The access-matrix model of protection between domains and objects was developed by [Lampson (1969)] and [Lampson (1971)]. [Popek (1974)] and [Saltzer and Schroeder (1975)] provided excellent surveys on the subject of protection. [Harrison et al. (1976)] used a formal version of the access- matrix model to enable them to prove properties of a protection system mathematically. The concept of a capability evolved from ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_13",
      "title": "Chapter 14 Protection",
      "label": "Chapter",
      "file_source": "14_Chapter 14 Protection.pdf",
      "page": 1,
      "definition": "Protection refers to a mechanism for controlling the access of programs, processes, or users to the resources de\ufb01ned by a computer system.",
      "key_points": [
        "14 C H A P T E R Protection The processes in an operating system must be protected from one another\u2019s activities.",
        "To provide such protection, we can use various mechanisms to ensure that only processes that have gained proper authorization from the operating system can operate on the \ufb01les, memory segments, CPU, and other resources of a system.",
        "\u2022 To explain how protection domains, combined with an access matrix, are used to specify the resources a process may access.",
        "14.1 Goals of Protection: As computer systems have become more sophisticated and pervasive in their applic...",
        "14.2 Principles of Protection: Frequently, a guiding principle can be used throughout a project, such as the de...",
        "14.3 Domain of Protection: A computer system is a collection of processes and objects....",
        "14.3.1 Domain Structure: A domain is a collection of access rights, each of which is an ordered pair <obj...",
        "14.3.2 An Example: UNIX: In the UNIX operating system, a domain is associated with the user...."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_1",
      "title": "15.1 The Security Problem",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 1,
      "definition": "In many applications, ensuring the security of the computer system is worth considerable effort.",
      "key_points": [
        "Large commercial systems containing payroll or other \ufb01nancial data are inviting targets to thieves.",
        "Systems that contain data pertain- ing to corporate operations may be of interest to unscrupulous competitors.",
        "Furthermore, loss of such data, whether by accident or fraud, can seriously impair the ability of the corporation to function.",
        "In Chapter 14, we discussed mechanisms that the operating system can provide (with appropriate aid from the hardware) that allow users to protect"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_2",
      "title": "15.2 Program Threats",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 5,
      "definition": "Processes, along with the kernel, are the only means of accomplishing work on a computer.",
      "key_points": [
        "Therefore, writing a program that creates a breach of security, or causing a normal process to change its behavior and create a breach, is a common goal of crackers.",
        "Note that there is considerable variation in the naming conventions for security holes and that we use the most common or descriptive terms.",
        "In fact, even most nonprogram security events have as their goal causing a program threat.",
        "For example, while it is useful to log in to a system without authorization, it is quite a lot more useful to leave behind a back-door daemon that provides information or allows easy access even if the original exploit is blocked.",
        "In this section, we describe common methods by which programs cause security breaches."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_2_1",
      "title": "15.2.1 Trojan Horse",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 5,
      "definition": "Many systems have mechanisms for allowing programs written by users to be executed by other users.",
      "key_points": [
        "A text-editor program, for example, may include code to search the \ufb01le to be edited for certain keywords.",
        "What has happened is that his authentication key and password have been stolen by the login emulator, which was left running on the terminal by the thief.",
        "This type of attack can be defeated by having the operating system print a usage message at the end of an interactive session or by a nontrappable key sequence,"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_2_2",
      "title": "15.2.2 Trap Door",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 6,
      "definition": "The designer of a program or system might leave a hole in the software that only she is capable of using.",
      "key_points": [
        "This type of security breach (or trap door) was shown in the movie War Games.",
        "For instance, the code might check for a speci\ufb01c user ID or password, and it might circumvent normal security procedures.",
        "Programmers have been arrested for embezzling from banks by including rounding errors in their code and having the occasional half-cent credited to their accounts.",
        "This account crediting can add up to a large amount of money, considering the number of transactions that a large bank executes.",
        "A clever trap door could be included in a compiler."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_2_3",
      "title": "15.2.3 Logic Bomb",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 7,
      "definition": "Consider a program that initiates a security incident only under certain circumstances.",
      "key_points": [
        "It would be hard to detect because under normal operations, there would be no security hole.",
        "However, when a prede\ufb01ned set of parameters was met, the security hole would be created.",
        "This scenario is known as a logic bomb.",
        "A programmer, for example, might write code to detect whether he was still employed; if that check failed, a daemon could be spawned to allow remote access, or code could be launched to cause damage to the site."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_2_4",
      "title": "15.2.4 Stack and Buffer Over\ufb02ow",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 7,
      "definition": "The stack- or buffer-over\ufb02ow attack is the most common way for an attacker outside the system, on a network or dial-up connection, to gain unauthorized access to the target system.",
      "key_points": [
        "Overwrite the current return address on the stack with the address of the exploit code loaded in step 3.",
        "An authorized user of the system may also use this exploit for privilege escalation.",
        "Essentially, the attack exploits a bug in a program.",
        "The bug can be a simple case of poor programming, in which the programmer neglected to code bounds checking on an input \ufb01eld.",
        "In this case, the attacker sends more data than the program was expecting."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_2_5",
      "title": "15.2.5 Viruses",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 10,
      "definition": "Another form of program threat is a virus.",
      "key_points": [
        "A virus is a fragment of code embed- ded in a legitimate program.",
        "Viruses are self-replicating and are designed to \u201cinfect\u201d other programs.",
        "They can wreak havoc in a system by modifying or destroying \ufb01les and causing system crashes and program malfunctions.",
        "As with most penetration attacks, viruses are very speci\ufb01c to architectures, oper- ating systems, and applications.",
        "Viruses are a particular problem for users of"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_3",
      "title": "15.3 System and Network Threats",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 13,
      "definition": "Program threats typically use a breakdown in the protection mechanisms of a system to attack programs.",
      "key_points": [
        "In contrast, system and network threats involve the abuse of services and network connections.",
        "System and network threats create a situation in which operating-system resources and user \ufb01les are misused.",
        "Sometimes, a system and network attack is used to launch a program attack, and vice versa.",
        "The more open an operating system is\u2014the more services it has enabled and the more functions it allows\u2014the more likely it is that a bug is available to exploit.",
        "Increasingly, operating systems strive to be secure by default."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_3_1",
      "title": "15.3.1 Worms",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 14,
      "definition": "A worm is a process that uses the spawn mechanism to duplicate itself.",
      "key_points": [
        "The worm spawns copies of itself, using up system resources and perhaps locking out all other processes.",
        "Although Morris designed the self-replicating program for rapid reproduc- tion and distribution, some of the features of the UNIX networking environment provided the means to propagate the worm throughout the system.",
        "From there, the worm program exploited \ufb02aws in the UNIX operating system\u2019s security routines and took advantage of UNIX utilities that simplify resource sharing in local-area networks to gain unauthorized access to thousands of other connected sites."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_3_2",
      "title": "15.3.2 Port Scanning",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 17,
      "definition": "Port scanning is not an attack but rather a means for a cracker to detect a system\u2019s vulnerabilities to attack.",
      "key_points": [
        "Port scanning typically is automated, involving a tool that attempts to create a TCP/IP connection to a speci\ufb01c port or a range of ports.",
        "For example, suppose there is a known vulnerability (or bug) in sendmail.",
        "A cracker could launch a port scanner to try to connect, say, to port 25 of a particular system or to a range of systems.",
        "If the connection was successful, the cracker (or tool) could attempt to communicate with the answering service to determine if the service was indeed sendmail and, if so, if it was the version with the bug.",
        "Now imagine a tool in which each bug of every service of every operating system was encoded."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_3_3",
      "title": "15.3.3 Denial of Service",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 17,
      "definition": "As mentioned earlier, denial-of-service attacks are aimed not at gaining information or stealing resources but rather at disrupting legitimate use of a system or facility.",
      "key_points": [
        "Most such attacks involve systems that the attacker has"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_4",
      "title": "15.4 Cryptography as a Security Tool",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 18,
      "definition": "There are many defenses against computer attacks, running the gamut from methodology to technology.",
      "key_points": [
        "Note that the cryptography discussed here has been simpli\ufb01ed for educational purposes; readers are cautioned against using any",
        "The broadest tool available to system designers and users is cryptography.",
        "In this section, we discuss cryptography and its use in computer security."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_4_1",
      "title": "15.4.1 Encryption",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 19,
      "definition": "Because it solves a wide variety of communication security problems, encryp- tion is used frequently in many aspects of modern computing.",
      "key_points": [
        "It is used to send messages securely across across a network, as well as to protect database data, \ufb01les, and even entire disks from having their contents read by unauthorized entities.",
        "An encryption algorithm enables the sender of a message to ensure that"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_4_2",
      "title": "15.4.2 Implementation of Cryptography",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 25,
      "definition": "Network protocols are typically organized in layers, like an onion or a parfait, with each layer acting as a client of the one below it.",
      "key_points": [
        "That is, when one protocol generates a message to send to its protocol peer on another machine, it hands its message to the protocol below it in the network-protocol stack for delivery to its peer on that machine.",
        "For example, in an IP network, TCP (a transport- layer protocol) acts as a client of IP (a network-layer protocol): TCP packets are passed down to IP for delivery to the IP peer at the other end of the connection.",
        "IP encapsulates the TCP packet in an IP packet, which it similarly passes down to the data-link layer to be transmitted across the network to its peer on the"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_4_3",
      "title": "15.4.3 An Example: SSL",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 27,
      "definition": "SSL 3.0 is a cryptographic protocol that enables two computers to communicate securely\u2014that is, so that each can limit the sender and receiver of messages to the other.",
      "key_points": [
        "For completeness, we should note that SSL was designed by Netscape and that it evolved into the industry- standard TLS protocol.",
        "What we are about to see is a complex dance in which asymmetric cryptography is used so that a client and a server can establish a secure session key that can be used for symmetric encryption of the session between the two\u2014all of this while avoiding man-in-the-middle and replay attacks.",
        "For added cryptographic strength, the session keys are forgotten once a session is completed.",
        "Another communication between the two will require generation of new session keys.",
        "Prior to the protocol\u2019s use, the server s is assumed to have obtained a certi\ufb01cate, denoted certs, from certi\ufb01cation authority CA."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_5",
      "title": "15.5 User Authentication",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 29,
      "definition": "Our earlier discussion of authentication involves messages and sessions.",
      "key_points": [
        "The protection system depends on the ability to identify the programs and processes currently executing, which in turn depends on the ability to identify each user of the system.",
        "Generally, user authentication is based on one or more of three things: the user\u2019s possession of something (a key or card), the user\u2019s knowledge of something (a user identi\ufb01er and password), or an attribute of the user (\ufb01ngerprint, retina pattern, or signature).",
        "But what about users?",
        "If a system cannot authenticate a user, then authenticating that a message came from that user is pointless.",
        "Thus, a major security problem for operating systems is user authentication."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_5_1",
      "title": "15.5.1 Passwords",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 29,
      "definition": "The most common approach to authenticating a user identity is the use of passwords.",
      "key_points": [
        "They can be considered a special case of either keys or capabilities.",
        "When the user identi\ufb01es herself by user ID or account name, she is asked for a password.",
        "If the user-supplied password matches the password stored in the system, the system assumes that the account is being accessed by the owner of that account.",
        "Passwords are often used to protect objects in the computer system, in the absence of more complete protection schemes.",
        "For instance, a password may be associated with each resource (such as a \ufb01le)."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_5_2",
      "title": "15.5.2 Password Vulnerabilities",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 29,
      "definition": "Passwords are extremely common because they are easy to understand and use.",
      "key_points": [
        "Unfortunately, passwords can often be guessed, accidentally exposed, sniffed (read by an eavesdropper), or illegally transferred from an authorized user to an unauthorized one, as we show next."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_5_3",
      "title": "15.5.3 Securing Passwords",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 31,
      "definition": "One problem with all these approaches is the dif\ufb01culty of keeping the password secret within the computer.",
      "key_points": [
        "How can the system store a password securely yet allow its use for authentication when the user presents her password?",
        "The UNIX system uses secure hashing to avoid the necessity of keeping its password list secret.",
        "Because the list is hashed rather than encrypted, it is impossible for the system to decrypt the stored value and determine the original password.",
        "Here\u2019s how this system works.",
        "Each user has a password."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_5_4",
      "title": "15.5.4 One-Time Passwords",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 32,
      "definition": "To avoid the problems of password snif\ufb01ng and shoulder sur\ufb01ng, a system can use a set of paired passwords.",
      "key_points": [
        "The next time the user needs to be authenticated, another ch is generated, and the same steps ensue.",
        "Commer- cial implementations use hardware calculators with a display or a display and numeric keypad.",
        "These calculators generally take the shape of a credit card, a key-chain dongle, or a USB device."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_5_5",
      "title": "15.5.5 Biometrics",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 33,
      "definition": "Yet another variation on the use of passwords for authentication involves the use of biometric measures.",
      "key_points": [
        "Software can then scan a \ufb01nger on the pad and compare its features with these stored sequences to determine if they match.",
        "Palm- or hand-readers are commonly used to secure physical access\u2014for example, access to a data center.",
        "These readers match stored parameters against what is being read from hand-reader pads.",
        "The parameters can include a temperature map, as well as \ufb01nger length, \ufb01nger width, and line patterns.",
        "These devices are currently too large and expensive to be used for normal computer authentication."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_6",
      "title": "15.6 Implementing Security Defenses",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 33,
      "definition": "Just as there are myriad threats to system and network security, there are many security solutions.",
      "key_points": [
        "The solutions range from improved user education, through technology, to writing bug-free software.",
        "Most security professionals subscribe to the theory of defense in depth, which states that more layers of defense are better than fewer layers.",
        "Of course, this theory applies to any kind of security.",
        "Consider the security of a house without a door lock, with a door lock, and with a lock and an alarm.",
        "In this section, we look at the major methods, tools, and techniques that can be used to improve resistance to threats."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_6_1",
      "title": "15.6.1 Security Policy",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 33,
      "definition": "The \ufb01rst step toward improving the security of any aspect of computing is to have a security policy.",
      "key_points": [
        "Policies vary widely but generally include a statement"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_6_2",
      "title": "15.6.2 Vulnerability Assessment",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 34,
      "definition": "How can we determine whether a security policy has been correctly imple- mented?",
      "key_points": [
        "A scan within an individual system can check a variety of aspects of the system: \u2022 Short or easy-to-guess passwords \u2022 Unauthorized privileged programs, such as setuid programs \u2022 Unauthorized programs in system directories \u2022 Unexpectedly long-running processes \u2022 Improper directory protections on user and system directories \u2022 Improper protections on system data \ufb01les, such as the password \ufb01le, device drivers, or the operating-system kernel itself \u2022 Dangerous entries in the program search path (for example, the Trojan horse discussed in Section 15.2.1) \u2022 Changes to system programs detected with checksum values \u2022 Unexpected or hidden network daemons Any problems found by a security scan can be either \ufb01xed automatically or reported to the managers of the system.",
        "The best way is to execute a vulnerability assessment.",
        "Such assess- ments can cover broad ground, from social engineering through risk assess- ment to port scans.",
        "Risk assessment, for example, attempts to value the assets of the entity in question (a program, a management team, a system, or a facility) and determine the odds that a security incident will affect the entity and decrease its value.",
        "When the odds of suffering a loss and the amount of the potential loss are known, a value can be placed on trying to secure the entity."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_6_3",
      "title": "15.6.3 Intrusion Detection",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 35,
      "definition": "Securing systems and facilities is intimately linked to intrusion detection.",
      "key_points": [
        "Intru- sion detection, as its name suggests, strives to detect attempted or successful"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_6_4",
      "title": "15.6.4 Virus Protection",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 38,
      "definition": "As we have seen, viruses can and do wreak havoc on systems.",
      "key_points": [
        "Protection from viruses thus is an important security concern.",
        "Some also look for process anomalies.",
        "A process opening an executable \ufb01le for writing is suspicious, for example, unless it is a compiler.",
        "For example, in 2000, the love bug virus became very widespread by traveling in e-mail messages that pretended to be love notes sent by friends of the receivers."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_6_5",
      "title": "15.6.5 Auditing, Accounting, and Logging",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 40,
      "definition": "Auditing, accounting, and logging can decrease system performance, but they are useful in several areas, including security.",
      "key_points": [
        "Logging can be general or speci\ufb01c.",
        "All system-call executions can be logged for analysis of program behavior (or misbehavior).",
        "More typically, suspicious events are logged.",
        "Authentication failures and authorization failures can tell us quite a lot about break-in attempts.",
        "Accounting is another potential tool in a security administrator\u2019s kit."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_7",
      "title": "15.7 Firewalling to Protect Systems and Networks",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 40,
      "definition": "A \ufb01rewall is a computer, appliance, or router that sits between the trusted and the untrusted.",
      "key_points": [
        "One solution is the use of a \ufb01rewall to separate trusted and untrusted systems.",
        "A network \ufb01rewall limits network access between the two security domains and monitors and logs all connections.",
        "It can also limit connections based on source or destination address, source or destination port, or direction of the connection.",
        "For instance, web servers use HTTP to communicate with web browsers.",
        "A \ufb01rewall therefore may allow only HTTP to pass from all hosts outside the \ufb01rewall to the web server within the \ufb01rewall."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_8",
      "title": "15.8 Computer-Security Classi\ufb01cations",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 42,
      "definition": "The U.S. Department of Defense Trusted Computer System Evaluation Criteria specify four security classi\ufb01cations in systems: A, B, C, and D.",
      "key_points": [
        "The TCB also denotes the sensitivity level at the top and bottom of each",
        "This speci\ufb01cation is widely used to determine the security of a facility and to model security solutions, so we explore it here.",
        "The lowest-level classi\ufb01cation is division D, or minimal protection.",
        "Division D includes only one class and is used for systems that have failed to meet the requirements of any of the other security classes.",
        "For instance, MS-DOS and Windows 3.1 are in division D."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_9",
      "title": "15.9 An Example: Windows 7",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 43,
      "definition": "Microsoft Windows 7 is a general-purpose operating system designed to support a variety of security features and methods.",
      "key_points": [
        "In this section, we examine features that Windows 7 uses to perform security functions.",
        "For more information and background on Windows 7, see Chapter 19.",
        "The Windows 7 security model is based on the notion of user accounts.",
        "Windows 7 allows the creation of any number of user accounts, which can be grouped in any manner.",
        "Access to system objects can then be permitted or denied as desired."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_10",
      "title": "15.10 Summary",
      "label": "Topic",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 45,
      "definition": "Protection is an internal problem.",
      "key_points": [
        "Security, in contrast, must consider both the computer system and the environment\u2014people, buildings, businesses, valuable objects, and threats\u2014within which the system is used."
      ]
    },
    {
      "id": "CHAP_14_SUB_15_1",
      "title": "15.1 Buffer-over\ufb02ow attacks can be avoided by adopting a better program-",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 46,
      "definition": "ming methodology or by using special hardware support. Discuss these solutions.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_2",
      "title": "15.2 A password may become known to other users in a variety of ways. Is",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 46,
      "definition": "there a simple method for detecting that such an event has occurred? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_3",
      "title": "15.3 What is the purpose of using a \u201csalt\u201d along with the user-provided",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 46,
      "definition": "password? Where should the \u201csalt\u201d be stored, and how should it be used?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_4",
      "title": "15.4 The list of all passwords is kept within the operating system. Thus,",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 46,
      "definition": "if a user manages to read this list, password protection is no longer provided. Suggest a scheme that will avoid this problem. (Hint: Use different internal and external representations.)",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_5",
      "title": "15.5 An experimental addition to UNIX allows a user to connect a watchdog",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 46,
      "definition": "program to a \ufb01le. The watchdog is invoked whenever a program",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_6",
      "title": "15.6 The UNIX program COPS scans a given system for possible security",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 47,
      "definition": "holes and alerts the user to possible problems. What are two potential hazards of using such a system for security? How can these problems be limited or eliminated?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_7",
      "title": "15.7 Discuss a means by which managers of systems connected to the",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 47,
      "definition": "Internet could design their systems to limit or eliminate the damage done by worms. What are the drawbacks of making the change that you suggest?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_8",
      "title": "15.8 Argue for or against the judicial sentence handed down against Robert",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 47,
      "definition": "Morris, Jr., for his creation and execution of the Internet worm discussed in Section 15.3.1.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_9",
      "title": "15.9 Make a list of six security concerns for a bank\u2019s computer system. For",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 47,
      "definition": "each item on your list, state whether this concern relates to physical, human, or operating-system security.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_10",
      "title": "15.10 What are two advantages of encrypting data stored in the computer",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 47,
      "definition": "system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_11",
      "title": "15.11 What commonly used computer programs are prone to man-in-the-",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 47,
      "definition": "middle attacks? Discuss solutions for preventing this form of attack.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_12",
      "title": "15.12 Compare symmetric and asymmetric encryption schemes, and discuss",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 47,
      "definition": "the circumstances under which a distributed system would use one or the other.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_13",
      "title": "15.13 Why doesn\u2019t Dkd,N(Eke,N(m)) provide authentication of the sender? To",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 47,
      "definition": "what uses can such an encryption be put?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_14",
      "title": "15.14 Discuss how the asymmetric encryption algorithm can be used to",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 47,
      "definition": "achieve the following goals. a. Authentication: the receiver knows that only the sender could have generated the message. b. Secrecy: only the receiver can decrypt the message. c. Authentication and secrecy: only the receiver can decrypt the message, and the receiver knows that only the sender could have generated the message.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14_SUB_15_15",
      "title": "15.15 Consider a system that generates 10 million audit records per day.",
      "label": "Exercise",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 47,
      "definition": "Assume that, on average, there are 10 attacks per day on this system and each attack is re\ufb02ected in 20 records. If the intrusion-detection system has a true-alarm rate of 0.6 and a false-alarm rate of 0.0005, what percentage of alarms generated by the system correspond to real intrusions?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_14",
      "title": "Chapter 15 Security",
      "label": "Chapter",
      "file_source": "15_Chapter 15 Security.pdf",
      "page": 1,
      "definition": "15 C H A P T E R Security Protection, as we discussed in Chapter 14, is strictly an internal problem: How do we provide controlled access to programs and data stored in a computer system?",
      "key_points": [
        "We then explore a key security enabler \u2014cryptography.",
        "Security, on the other hand, requires not only an adequate protection system but also consideration of the external environment within which the system operates.",
        "A protection system is ineffective if user authentication is compromised or a program is run by an unauthorized user.",
        "15.1 The Security Problem: In many applications, ensuring the security of the computer system is worth cons...",
        "15.2 Program Threats: Processes, along with the kernel, are the only means of accomplishing work on a ...",
        "15.2.1 Trojan Horse: Many systems have mechanisms for allowing programs written by users to be execut...",
        "15.2.2 Trap Door: The designer of a program or system might leave a hole in the software that only...",
        "15.2.3 Logic Bomb: Consider a program that initiates a security incident only under certain circums..."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_1",
      "title": "16.1 Overview",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 1,
      "definition": "In the case of virtualization, there is a layer that creates a virtual system on which operating systems or applications can run.",
      "key_points": [
        "This concept may seem similar to the layered approach of operating system implementation (see Section 2.7.2), and in some ways it is."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_2",
      "title": "16.2 History",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 3,
      "definition": "Virtual machines \ufb01rst appeared commercially on IBM mainframes in 1972.",
      "key_points": [
        "Virtualization was provided by the IBM VM operating system.",
        "This system has evolved and is still available.",
        "In addition, many of its original concepts are found in other systems, making it worth exploring.",
        "IBM VM370 divided a mainframe into multiple virtual machines, each running its own operating system.",
        "A major dif\ufb01culty with the VM approach involved disk systems."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_3",
      "title": "16.3 Bene\ufb01ts and Features",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 4,
      "definition": "Several advantages make virtualization attractive.",
      "key_points": [
        "One important advantage of virtualization is that the host system is protected from the virtual machines, just as the virtual machines are protected from each other.",
        "A potential disadvantage of isolation is that it can prevent sharing of resources.",
        "Most of them are fundamen- tally related to the ability to share the same hardware yet run several different execution environments (that is, different operating systems) concurrently.",
        "A virus inside a guest operating system might damage that operating system but is unlikely to affect the host or the other guests.",
        "Because each virtual machine is almost completely isolated from all other virtual machines, there are almost no protection problems."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_4",
      "title": "16.4 Building Blocks",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 7,
      "definition": "Although the virtual machine concept is useful, it is dif\ufb01cult to implement.",
      "key_points": [
        "Note that these building blocks are not required by type 0 hypervisors, as discussed in Section 16.5.2. The ability to virtualize depends on the features provided by the CPU.",
        "If the features are suf\ufb01cient, then it is possible to write a VMM that provides a guest environment.",
        "One important concept found in most virtualization options is the imple- mentation of a virtual CPU (VCPU)."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_4_1",
      "title": "16.4.1 Trap-and-Emulate",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 7,
      "definition": "On a typical dual-mode system, the virtual machine guest can execute only in user mode (unless extra hardware support is provided).",
      "key_points": [
        "The kernel, of course, runs in kernel mode, and it is not safe to allow user-level code to run in kernel mode.",
        "Just as the physical machine has two modes, however, so must the virtual machine.",
        "Consequently, we must have a virtual user mode and a virtual kernel mode, both of which run in physical user mode.",
        "Those actions that cause a transfer from user mode to kernel mode on a real machine (such as a system call, an interrupt, or an attempt to execute a privileged instruction) must also cause a transfer from virtual user mode to virtual kernel mode in the virtual machine.",
        "How can such a transfer be accomplished?"
      ]
    },
    {
      "id": "CHAP_15_SUB_16_4_2",
      "title": "16.4.2 Binary Translation",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 8,
      "definition": "Some CPUs do not have a clean separation of privileged and nonprivileged instructions.",
      "key_points": [
        "Unfortunately for virtualization implementers, the Intel x86 CPU line is one of them.",
        "No thought was given to running virtualization on the x86 when it was designed.",
        "(In fact, the \ufb01rst CPU in the family\u2014the Intel 4004, released in 1971\u2014was designed to be the core of a calculator.) The chip has maintained backward compatibility throughout its lifetime, preventing changes that would have made virtualization easier through many generations.",
        "Let\u2019s consider an example of the problem.",
        "The command popf loads the \ufb02ag register from the contents of the stack."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_4_3",
      "title": "16.4.3 Hardware Assistance",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 10,
      "definition": "Without some level of hardware support, virtualization would be impossible.",
      "key_points": [
        "The more hardware support available within a system, the more feature-rich and stable the virtual machines can be and the better they can perform.",
        "For example,AMD virtualization tech- nology (AMD-V) has appeared in several AMD processors starting in 2006.",
        "It de\ufb01nes two new modes of operation\u2014host and guest\u2014thus moving from a dual-mode to a multimode processor."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_5",
      "title": "16.5 Types of Virtual Machines and Their Implementations",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 11,
      "definition": "We\u2019ve now looked at some of the techniques used to implement virtualization.",
      "key_points": [
        "Next, we consider the major types of virtual machines, their implementation, their functionality, and how they use the building blocks just described to"
      ]
    },
    {
      "id": "CHAP_15_SUB_16_5_1",
      "title": "16.5.1 The Virtual Machine Life Cycle",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 12,
      "definition": "Let\u2019s begin with the virtual machine life cycle.",
      "key_points": [
        "Whatever the hypervisor type, at the time a virtual machine is created, its creator gives the VMM certain parameters.",
        "These parameters usually include the number of CPUs, amount of memory, networking details, and storage details that the VMM will take into account when creating the guest.",
        "For example, a user might want to create a new guest with two virtual CPUs, 4 GB of memory, 10 GB of disk space, one network interface that gets its IP address via DHCP, and access to the DVD drive.",
        "The VMM then creates the virtual machine with those parameters.",
        "In the case of a type 0 hypervisor, the resources are usually dedicated."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_5_2",
      "title": "16.5.2 Type 0 Hypervisor",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 13,
      "definition": "Type 0 hypervisors have existed for many years under many names, including \u201cpartitions\u201d and \u201cdomains\u201d.",
      "key_points": [
        "They are a hardware feature, and that brings its own positives and negatives.",
        "Operating systems need do nothing special to take advantage of their features.",
        "The feature set of a type 0 hypervisor tends to be smaller than those of the other types because it is implemented in hardware."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_5_3",
      "title": "16.5.3 Type 1 Hypervisor",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 14,
      "definition": "Type 1 hypervisors are commonly found in company data centers and are in a sense becoming \u201cthe data-center operating system.\u201d They are special-purpose operating systems that run natively on the hardware, but rather than providing system calls and other interfaces for running programs, they create, run, and manage guest operating systems.",
      "key_points": [
        "Type 1 hypervisors run in kernel mode, taking advantage of hardware protection.",
        "Frequently, they provide APIs, but those APIs support applications in guests or external applications that supply features like backups, monitoring, and security.",
        "An important bene\ufb01t is the ability to consolidate more operating systems and applications onto fewer systems."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_5_4",
      "title": "16.5.4 Type 2 Hypervisor",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 15,
      "definition": "Type 2 hypervisors are less interesting to us as operating-system explorers, because there is very little operating-system involvement in these application- level virtual machine managers.",
      "key_points": [
        "This type of VMM is simply another process run and managed by the host, and even the host does not know virtualization is happening within the VMM.",
        "For example, a user needs administrative privileges to access many of the hardware assistance features of modern CPUs. If the VMM is being run by a standard user without additional privileges, the VMM cannot take advantage of these features.",
        "Type 2 hypervisors have limits not associated with some of the other types.",
        "Due to this limitation, as well as the extra overhead of running a general-purpose operating system as well as guest operating systems, type 2 hypervisors tend to have poorer overall performance than type 0 or 1.",
        "As is often the case, the limitations of type 2 hypervisors also provide some bene\ufb01ts."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_5_5",
      "title": "16.5.5 Paravirtualization",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 15,
      "definition": "As we\u2019ve seen, paravirtualization takes a different tack than the other types of virtualization.",
      "key_points": [
        "Rather than try to trick a guest operating system into believing it has a system to itself, paravirtualization presents the guest with a system that is similar but not identical to the guest\u2019s preferred system.",
        "The guest must be modi\ufb01ed to run on the paravirtualized virtual hardware.",
        "The gain for this extra work is more ef\ufb01cient use of resources and a smaller virtualization layer.",
        "The Xen VMM, which is the leader in paravirtualization, has implemented several techniques to optimize the performance of guests as well as of the host system.",
        "For example, as we have seen, some VMMs present virtual devices to guests that appear to be real devices."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_5_6",
      "title": "16.5.6 Programming-Environment Virtualization",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 16,
      "definition": "Another kind of virtualization, based on a different execution model, is the virtualization of programming environments.",
      "key_points": [
        "For example, Oracle\u2019s Java has many features that depend on its running in the Java virtual machine (JVM), including speci\ufb01c methods for security and memory management.",
        "Instead, we can de\ufb01ne a virtual environment, based on APIs, that provides a set of features that we want to have available for a particular language and programs written in that language.",
        "Here, a programming language is designed to run within a custom-built virtualized environment.",
        "If we de\ufb01ne virtualization as including only duplication of hardware, this is not really virtualization at all.",
        "But we need not limit ourselves to that de\ufb01nition."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_5_7",
      "title": "16.5.7 Emulation",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 17,
      "definition": "Virtualization is probably the most common method for running applications designed for one operating system on a different operating system, but on the same CPU.",
      "key_points": [
        "For example, suppose a company has replaced its outdated computer system with a new system but would like to continue to run certain important programs that were compiled for the old system.",
        "This method works relatively ef\ufb01ciently because the applications were compiled for the same instruction set as the target system uses.",
        "But what if an application or operating system needs to run on a different CPU?",
        "Here, it is necessary to translate all of the source CPU\u2019s instructions so that they are turned into the equivalent instructions of the target CPU.",
        "Such an environment is no longer virtualized but rather is fully emulated."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_5_8",
      "title": "16.5.8 Application Containment",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 17,
      "definition": "The goal of virtualization in some instances is to provide a method to segregate applications, manage their performance and resource use, and create an easy way to start, stop, move, and manage them.",
      "key_points": [
        "If the applications are all compiled for the same operating system, then we do not need complete virtualization to provide these features.",
        "In such cases, perhaps full-\ufb02edged virtualization is not needed.",
        "We can instead use application containment."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_6",
      "title": "16.6 Virtualization and Operating-System Components",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 18,
      "definition": "Thus far, we have explored the building blocks of virtualization and the various types of virtualization.",
      "key_points": [
        "In this section, we take a deeper dive into the operating- system aspects of virtualization, including how the VMM provides core operating-system functions like scheduling, I/O, and memory management.",
        "Here, we answer questions such as these: How do VMMs schedule CPU use when guest operating systems believe they have dedicated CPUs?",
        "How can memory management work when many guests require large amounts of memory?"
      ]
    },
    {
      "id": "CHAP_15_SUB_16_6_1",
      "title": "16.6.1 CPU Scheduling",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 19,
      "definition": "A system with virtualization, even a single-CPU system, frequently acts like a multiprocessor system.",
      "key_points": [
        "The virtualization software presents one or more virtual CPUs to each of the virtual machines running on the system and then schedules the use of the physical CPUs among the virtual machines.",
        "The signi\ufb01cant variations among virtualization technologies make it dif\ufb01- cult to summarize the effect of virtualization on scheduling.",
        "First, let\u2019s consider the general case of VMM scheduling.",
        "The VMM has a number of physical CPUs available and a number of threads to run on those CPUs. The threads can be VMM threads or guest threads.",
        "Guests are con\ufb01gured with a certain number of virtual CPUs at creation time, and that number can be adjusted throughout the life of the VM."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_6_2",
      "title": "16.6.2 Memory Management",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 20,
      "definition": "Ef\ufb01cient memory use in general-purpose operating systems is one of the major keys to performance.",
      "key_points": [
        "In virtualized environments, there are more users of memory (the guests and their applications, as well as the VMM), leading to more pressure on memory use.",
        "Further adding to this pressure is that VMMs typically overcommit memory, so that the total memory with which guests are con\ufb01gured exceeds the amount of memory that physically exists in the system.",
        "The extra need for ef\ufb01cient memory use is not lost on the implementers of VMMs, who take great measures to ensure the optimal use of memory.",
        "For example, VMware ESX uses at least three methods of memory manage- ment.",
        "Before memory optimization can occur, the VMM must establish how much real memory each guest should use."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_6_3",
      "title": "16.6.3 I/O",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 21,
      "definition": "In the area of I/O, hypervisors have some leeway and can be less concerned with exactly representing the underlying hardware to their guests.",
      "key_points": [
        "Virtualization takes advantage of such built-in \ufb02exibility by providing speci\ufb01c virtualized devices to guest operating systems.",
        "Because of all the variation in I/O devices, operating systems are used to dealing with varying and \ufb02exible I/O mechanisms.",
        "For example, operating systems have a device-driver mechanism that provides a uniform interface to the operating system whatever the I/O device.",
        "Device-driver interfaces are designed to allow third-party hardware manufacturers to provide device drivers connecting their devices to the operating system.",
        "Usually, device drivers can be dynamically loaded and unloaded."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_6_4",
      "title": "16.6.4 Storage Management",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 22,
      "definition": "An important question in determining how virtualization works is this: If multiple operating systems have been installed, what and where is the boot disk?",
      "key_points": [
        "Clearly, virtualized environments need to approach the area of storage management differently from native operating systems.",
        "Even the standard multiboot method of slicing the root disk into partitions, installing a boot manager in one partition, and installing each other operating system in another partition is not suf\ufb01cient, because partitioning has limits that would prevent it from working for tens or hundreds of virtual machines.",
        "Once again, the solution to this problem depends on the type of hypervisor.",
        "Type 0 hypervisors do tend to allow root disk partitioning, partly because these systems tend to run fewer guests than other systems.",
        "Alternatively, they may have a disk manager as part of the control partition, and that disk manager provides disk space (including boot disks) to the other partitions."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_6_5",
      "title": "16.6.5 Live Migration",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 23,
      "definition": "One feature not found in general-purpose operating systems but found in type and type 1 hypervisors is the live migration of a running guest from one system to another.",
      "key_points": [
        "After all, compare it with the steps necessary without virtu- alization: warning users, shutting down the processes, possibly moving the",
        "We mentioned this capability earlier.",
        "Here, we explore the details of how live migration works and why VMMs have a relatively easy time implementing it while general-purpose operating systems, in spite of some research attempts, do not.",
        "First, consider how live migration works.",
        "A running guest on one system is copied to another system running the same VMM."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_7",
      "title": "16.7 Examples",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 25,
      "definition": "Today, however, virtual machines are coming into fashion as a means of solving system compatibility problems.",
      "key_points": [
        "Despite the advantages of virtual machines, they received little attention for a number of years after they were \ufb01rst developed.",
        "In this section, we explore two popular contemporary virtual machines: the VMware Workstation and the Java virtual machine.",
        "As you will see, these virtual machines can typically run on top of operating systems of any of the design types discussed in earlier chapters.",
        "Thus, operating-system design methods\u2014simple layers, microkernels, modules, and virtual machines \u2014are not mutually exclusive."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_7_1",
      "title": "16.7.1 VMware",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 25,
      "definition": "VMware Workstation is a popular commercial application that abstracts Intel X86 and compatible hardware into isolated virtual machines.",
      "key_points": [
        "VMware Workstation is a prime example of a Type 2 hypervisor.",
        "It runs as an application on a host operating system such as Windows or Linux and allows this host system to run several different guest operating systems concurrently as independent virtual machines.",
        "The architecture of such a system is shown in Figure 16.9. In this scenario, Linux is running as the host operating system, and FreeBSD, Windows NT, and"
      ]
    },
    {
      "id": "CHAP_15_SUB_16_7_2",
      "title": "16.7.2 The Java Virtual Machine",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 26,
      "definition": "Java is a popular object-oriented programming language introduced by Sun Microsystems in 1995.",
      "key_points": [
        "In addition to a language speci\ufb01cation and a large API library, Java provides a speci\ufb01cation for a Java virtual machine, or JVM.",
        "Java therefore is an example of programming-environment virtualization, as discussed in Section 16.5.6. Java objects are speci\ufb01ed with the class construct; a Java program consists of one or more classes.",
        "For each Java class, the compiler produces an architecture-neutral bytecode output (.class) \ufb01le that will run on any implementation of the JVM.",
        "The JVM is a speci\ufb01cation for an abstract computer.",
        "It consists of a class loader and a Java interpreter that executes the architecture-neutral bytecodes, as diagrammed in Figure 16.10."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_8",
      "title": "16.8 Summary",
      "label": "Topic",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 27,
      "definition": "Virtualization is a method of providing a guest with a duplicate of a system\u2019s underlying hardware.",
      "key_points": [
        "Since then, with improvements in system and CPU performance and through innovative software techniques, virtualization has become a common feature in data centers and even on personal computers.",
        "Because of the popularity of virtualization, CPU designers have added features to support virtualization.",
        "Multiple guests can run on a given system, each believing it is the native operating system in full control of the system.",
        "Virtualization started as a method to allow IBM to segregate users and provide them with their own execution environments on IBM mainframes.",
        "This snowball effect is likely to continue, with virtualization and its hardware support increasing over time."
      ]
    },
    {
      "id": "CHAP_15_SUB_16_1",
      "title": "16.1 Describe the three types of traditional virtualization.",
      "label": "Exercise",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 28,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_15_SUB_16_2",
      "title": "16.2 Describe the four virtualization-like execution environments and why",
      "label": "Exercise",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 28,
      "definition": "they are not \u201ctrue\u201d virtualization.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_15_SUB_16_3",
      "title": "16.3 Describe four bene\ufb01ts of virtualization.",
      "label": "Exercise",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 28,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_15_SUB_16_4",
      "title": "16.4 Why can VMMs not implement trap-and-emulate-based virtualization",
      "label": "Exercise",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 28,
      "definition": "on some CPUs? Lacking the ability to trap-and-emulate, what method can a VMM use to implement virtualization?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_15_SUB_16_5",
      "title": "16.5 What hardware assistance for virtualization can be provided by modern",
      "label": "Exercise",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 28,
      "definition": "CPUs?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_15_SUB_16_6",
      "title": "16.6 Why is live migration possible in virtual environments but much less",
      "label": "Exercise",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 28,
      "definition": "possible for a native operating system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_15",
      "title": "Chapter 16 Virtual Machines",
      "label": "Chapter",
      "file_source": "16_Chapter 16 Virtual Machines.pdf",
      "page": 1,
      "definition": "16 C H A P T E R Virtual Machines The term virtualization has many meanings, and aspects of virtualization permeate all aspects of computing.",
      "key_points": [
        "This chapter delves into the uses, features, and implementation of virtual machines.",
        "Additionally, hardware features provided by the CPU and even by I/O devices can support virtual machine implementation, so we discuss how those features are used by the appropriate kernel modules.",
        "\u2022 To show the most common hardware features that support virtualization and explain how they are used by operating-system modules.",
        "16.1 Overview: In the case of virtualization, there is a layer that creates a virtual system on...",
        "16.2 History: Virtual machines \ufb01rst appeared commercially on IBM mainframes in 1972....",
        "16.3 Bene\ufb01ts and Features: Several advantages make virtualization attractive....",
        "16.4 Building Blocks: Although the virtual machine concept is useful, it is dif\ufb01cult to implement....",
        "16.4.1 Trap-and-Emulate: On a typical dual-mode system, the virtual machine guest can execute only in use..."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_1",
      "title": "17.1 Advantages of Distributed Systems",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 1,
      "definition": "A distributed system is a collection of loosely coupled nodes interconnected by a communication network.",
      "key_points": [
        "They may include small microprocessors, personal computers, and large general-purpose computer systems.",
        "These processors are referred to by a number of names, such as processors, sites, machines, and hosts, depending on the context in which they are mentioned.",
        "From the point of view of a speci\ufb01c node in a distributed system, the rest of the nodes and their respective resources are remote, whereas its own resources are local.",
        "The nodes in a distributed system may vary in size and function.",
        "We mainly use site to indicate the location of a machine and node to refer to a speci\ufb01c system at a site."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_1_1",
      "title": "17.1.1 Resource Sharing",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 2,
      "definition": "If a number of different sites (with different capabilities) are connected to one another, then a user at one site may be able to use the resources available at another.",
      "key_points": [
        "In general, resource sharing in a distributed system provides mechanisms for sharing \ufb01les at remote sites, processing information in a distributed database, printing \ufb01les at remote sites, using remote specialized hardware devices (such as a supercomputer), and performing other operations.",
        "For example, a user at site A may be using a laser printer located at site B.",
        "Meanwhile, a user at B may access a \ufb01le that resides at A."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_1_2",
      "title": "17.1.2 Computation Speedup",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 2,
      "definition": "If a particular computation can be partitioned into subcomputations that can run concurrently, then a distributed system allows us to distribute the subcomputations among the various sites.",
      "key_points": [
        "The subcomputations can be run concurrently and thus provide computation speedup.",
        "In addition, if a particular site is currently overloaded with jobs, some of them can be moved to other, lightly loaded sites.",
        "This movement of jobs is called load sharing or job migration.",
        "Automated load sharing, in which the distributed operating system automatically moves jobs, is not yet common in commercial systems."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_1_3",
      "title": "17.1.3 Reliability",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 2,
      "definition": "If one site fails in a distributed system, the remaining sites can continue operating, giving the system better reliability.",
      "key_points": [
        "If the system is composed of multiple large autonomous installations (that is, general-purpose computers), the failure of one of them should not affect the rest.",
        "If, however, the system is composed of small machines, each of which is responsible for some crucial system function (such as the web server or the \ufb01le system), then a single failure may halt the operation of the whole system.",
        "In general, with enough"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_1_4",
      "title": "17.1.4 Communication",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 3,
      "definition": "When several sites are connected to one another by a communication network, users at the various sites have the opportunity to exchange information.",
      "key_points": [
        "At a low level, messages are passed between systems, much as messages are passed between processes in the single-computer message system discussed in Section 3.4. Given message passing, all the higher-level functionality found in standalone systems can be expanded to encompass the distributed system.",
        "The advantage of a distributed system is that these functions can be carried out over great distances.",
        "The advantages of distributed systems have resulted in an industry-wide trend toward downsizing."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_2",
      "title": "17.2 Types of Network-based Operating Systems",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 3,
      "definition": "In this section, we describe the two general categories of network-oriented operating systems: network operating systems and distributed operating systems.",
      "key_points": [
        "Network operating systems are simpler to implement but generally more dif\ufb01cult for users to access and utilize than are distributed operating systems, which provide more features."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_2_1",
      "title": "17.2.1 Network Operating Systems",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 3,
      "definition": "A network operating system provides an environment in which users, who are aware of the multiplicity of machines, can access remote resources by either logging in to the appropriate remote machine or transferring data from the remote machine to their own machines.",
      "key_points": [
        "Currently, all general-purpose operating systems, and even embedded operating systems such as Android and iOS, are network operating systems."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_2_2",
      "title": "17.2.2 Distributed Operating Systems",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 5,
      "definition": "In a distributed operating system, users access remote resources in the same way they access local resources.",
      "key_points": [
        "Data and process migration from one site to another is under the control of the distributed operating system.",
        "17.2.2.1 Data Migration Suppose a user on site A wants to access data (such as a \ufb01le) that reside at site B.",
        "The system can transfer the data by one of two basic methods."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_3",
      "title": "17.3 Network Structure",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 7,
      "definition": "There are basically two types of networks: local-area networks (LAN) and wide-area networks (WAN).",
      "key_points": [
        "The main difference between the two is the way in which they are geographically distributed.",
        "Local-area networks are composed"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_3_1",
      "title": "17.3.1 Local-Area Networks",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 8,
      "definition": "Local-area networks emerged in the early 1970s as a substitute for large mainframe computer systems.",
      "key_points": [
        "Because each small computer is likely to need a full complement of peripheral devices (such as disks and printers), and because some form of data sharing is likely to occur in a single enterprise, it was a natural step to connect these small systems into a network.",
        "A typical LAN may consist of a number of different computers (from mainframes to laptops or other mobile devices), various shared peripheral devices (such as laser printers and storage arrays), and one or more routers (specialized network communication processors) that provide access to other networks (Figure 17.2).",
        "A disadvantage of wireless networks concerns their speed."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_3_2",
      "title": "17.3.2 Wide-Area Networks",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 9,
      "definition": "Wide-area networks emerged in the late 1960s, mainly as an academic research project to provide ef\ufb01cient communication among sites, allowing hardware and software to be shared conveniently and economically by a wide community of users.",
      "key_points": [
        "These communication links are controlled by special communication processors (Figure 17.3), com- monly known as gateway routers or simply routers, that are responsible for de\ufb01ning the interface through which the sites communicate over the network, as well as for transferring information among the various sites.",
        "The \ufb01rst WAN to be designed and developed was the Arpanet.",
        "Begun in 1968, the Arpanet has grown from a four-site experimental network to a worldwide network of networks, the Internet, comprising millions of computer systems.",
        "Because the sites in a WANare physically distributed over a large geographi- cal area, the communication links are, by default, relatively slow and unreliable.",
        "Typical links are telephone lines, leased (dedicated data) lines, optical cable, microwave links, radio waves, and satellite channels."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_4",
      "title": "17.4 Communication Structure",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 11,
      "definition": "Now that we have discussed the physical aspects of networking, we turn to the internal workings.",
      "key_points": [
        "How do two processes locate each other to communicate?",
        "How do two processes send a sequence of mes- sages?",
        "The designer of a communication network must address \ufb01ve basic issues: \u2022 Naming and name resolution.",
        "\u2022 Routing strategies.",
        "How are messages sent through the network?"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_4_1",
      "title": "17.4.1 Naming and Name Resolution",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 11,
      "definition": "To solve this problem, processes on remote systems are generally identi\ufb01ed by the pair <host name, identi\ufb01er>, where host name is a name unique within the network and identi\ufb01er is a process identi\ufb01er or other unique number within that host.",
      "key_points": [
        "For a process at site A to exchange information with a process at site B, each must be able to specify the other.",
        "Within a computer system, each process has a process identi\ufb01er, and messages may be addressed with the process identi\ufb01er.",
        "Because networked systems share no memory, however, a host within the system initially has no knowledge about the processes on other hosts."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_4_2",
      "title": "17.4.2 Routing Strategies",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 13,
      "definition": "When a process at site A wants to communicate with a process at site B, how is the message sent?",
      "key_points": [
        "If there is only one physical path from A to B, the message must be sent through that path.",
        "However, if there are multiple physical paths from A to B, then several routing options exist.",
        "Each site has a routing table indicating the alternative paths that can be used to send a message to other sites.",
        "The table may include information about the speed and cost of the various communication paths, and it may be updated as necessary, either manually or via programs that exchange routing information.",
        "The three most common routing schemes are \ufb01xed routing, virtual routing, and dynamic routing."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_4_3",
      "title": "17.4.3 Packet Strategies",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 15,
      "definition": "Messages generally vary in length.",
      "key_points": [
        "To simplify the system design, we com- monly implement communication with \ufb01xed-length messages called packets, frames, or datagrams.",
        "A communication implemented in one packet can be sent to its destination in a connectionless message.",
        "A connectionless message can be unreliable, in which case the sender has no guarantee that, and cannot tell whether, the packet reached its destination.",
        "Alternatively, the packet can be reliable.",
        "Usually, in this case, an acknowledgement packet is returned from the destination indicating that the original packet arrived."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_4_4",
      "title": "17.4.4 Connection Strategies",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 15,
      "definition": "Once messages are able to reach their destinations, processes can institute communications sessions to exchange information.",
      "key_points": [
        "Pairs of processes that want to communicate over the network can be connected in a number of ways.",
        "If two processes want to communicate, a permanent physical link is established between them.",
        "This link is allocated for the duration of the communication session, and no other process can use that link during this period (even if the two processes are not actively communicating for a while).",
        "If two processes want to communicate, a temporary link is established for the duration of one message transfer.",
        "Note that it is not harmful for data to be broken into packets, possibly routed separately, and reassembled at the destination."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_5",
      "title": "17.5 Communication Protocols",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 16,
      "definition": "When we are designing a communication network, we must deal with the inherent complexity of coordinating asynchronous operations communicating in a potentially slow and error-prone environment.",
      "key_points": [
        "In addition, the systems on the network must agree on a protocol or a set of protocols for determining host names, locating hosts on the network, establishing connections, and so on.",
        "We can simplify the design problem (and related implementation) by partitioning the problem into multiple layers.",
        "Each layer on one system communicates with the equivalent layer on other systems.",
        "Typically, each layer has its own protocols, and communication takes place between peer layers using a speci\ufb01c protocol.",
        "The protocols may be implemented in hardware or software."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_6",
      "title": "17.6 An Example: TCP/IP",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 20,
      "definition": "We now return to the name-resolution issue raised in Section 17.4.1 and examine its operation with respect to the TCP/IP protocol stack on the Internet.",
      "key_points": [
        "Then we consider the processing needed to transfer a packet between hosts on different Ethernet networks.",
        "The packet may be a complete message, or it may just be a component of a message, with more packets needed before the message can be reassembled and passed to the TCP/UDP layer for transmission to the destination process.",
        "A broadcast uses a special network address (usually, the maximum address) to signal that all hosts should receive and process the packet."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_7",
      "title": "17.7 Robustness",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 22,
      "definition": "A distributed system may suffer from various types of hardware failure.",
      "key_points": [
        "The failure of a link, the failure of a site, and the loss of a message are the most common types.",
        "To ensure that the system is robust, we must detect any of these failures, recon\ufb01gure the system so that computation can continue, and recover when a site or a link is repaired."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_7_1",
      "title": "17.7.1 Failure Detection",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 22,
      "definition": "In an environment with no shared memory, we are generally unable to differentiate among link failure, site failure, and message loss.",
      "key_points": [
        "We can usually detect only that one of these failures has occurred.",
        "Once a failure has been detected, appropriate action must be taken.",
        "What action is appropriate depends on the particular application.",
        "To detect link and site failure, we use a heartbeat procedure.",
        "Suppose that sites A and B have a direct physical link between them."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_7_2",
      "title": "17.7.2 Recon\ufb01guration",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 22,
      "definition": "Suppose that site A has discovered, through the mechanism just described, that a failure has occurred.",
      "key_points": [
        "It must then initiate a procedure that will allow the system to recon\ufb01gure and to continue its normal mode of operation."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_7_3",
      "title": "17.7.3 Recovery from Failure",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 23,
      "definition": "When a failed link or site is repaired, it must be integrated into the system gracefully and smoothly.",
      "key_points": [
        "\u2022 Suppose that a link between A and B has failed.",
        "When it is repaired, both A and B must be noti\ufb01ed.",
        "We can accomplish this noti\ufb01cation by continuously repeating the heartbeat procedure described in Section 17.7.1. \u2022 Suppose that site B has failed.",
        "When it recovers, it must notify all other sites that it is up again.",
        "Site B then may have to receive information from the other sites to update its local tables."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_7_4",
      "title": "17.7.4 Fault Tolerance",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 23,
      "definition": "A distributed system must tolerate a certain level of failure and continue to function normally when faced with various types of failures.",
      "key_points": [
        "Making a facility fault tolerant starts at the protocol level, as described above, but continues through all aspects of the system.",
        "We use the term fault tolerance in a broad sense.",
        "Communication faults, certain machine failures, storage-device crashes, and decays of storage media should all be tolerated to some extent.",
        "A fault- tolerant system should continue to function, perhaps in a degraded form, when faced with such failures.",
        "The degradation can affect performance, functionality, or both."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_8",
      "title": "17.8 Design Issues",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 24,
      "definition": "Making the multiplicity of processors and storage devices transparent to the users has been a key challenge to many designers.",
      "key_points": [
        "Ideally, a distributed system should look to its users like a conventional, centralized system.",
        "The user interface of a transparent distributed system should not distinguish between local and remote resources.",
        "That is, users should be able to access remote resources as though these resources were local, and the distributed system should be responsible for locating the resources and for arranging for the appropriate interaction.",
        "Another aspect of transparency is user mobility.",
        "It would be convenient to allow users to log into any machine in the system rather than forcing them to use a speci\ufb01c machine."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_9",
      "title": "17.9 Distributed File Systems",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 25,
      "definition": "Although the World Wide Web is the predominant distributed system in use today, it is not the only one.",
      "key_points": [
        "Another important and popular use of distributed computing is the distributed \ufb01le system, or DFS.",
        "In this section, we discuss"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_9_1",
      "title": "17.9.1 Naming and Transparency",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 27,
      "definition": "Naming is a mapping between logical and physical objects.",
      "key_points": [
        "Going one step further with the concept of treating \ufb01les as abstractions leads to the possibility of \ufb01le replication.",
        "For instance, users deal with logical data objects represented by \ufb01le names, whereas the system manipulates physical blocks of data stored on disk tracks.",
        "Usually, a user refers to a \ufb01le by a textual name.",
        "The latter is mapped to a lower-level numerical identi\ufb01er that in turn is mapped to disk blocks.",
        "This multilevel mapping provides users with an abstraction of a \ufb01le that hides the details of how and where on the disk the \ufb01le is stored."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_9_2",
      "title": "17.9.2 Remote File Access",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 30,
      "definition": "Next, let\u2019s consider a user who requests access to a remote \ufb01le.",
      "key_points": [
        "The server storing the \ufb01le has been located by the naming scheme, and now the actual data transfer must take place.",
        "One way to achieve this transfer is through a remote-service mechanism, whereby requests for accesses are delivered to the server, the server machine performs the accesses, and their results are forwarded back to the user.",
        "One of the most common ways of implementing remote service is the RPC paradigm, which we discussed in Chapter 3.",
        "A direct analogy exists between disk-access methods in conventional \ufb01le systems and the remote-service method in a DFS: using the remote-service method is analogous to performing a disk access for each access request.",
        "To ensure reasonable performance of a remote-service mechanism, we can use a form of caching."
      ]
    },
    {
      "id": "CHAP_16_SUB_1_5",
      "title": "1.5 KB, so larger units of cached data need to be disassembled for delivery and",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 31,
      "definition": "reassembled on reception.",
      "key_points": [
        "Disk caches have one clear advantage over main-memory caches: they are reliable.",
        "Main-memory caches have several advantages of their own, however: \u2022 Main-memory caches permit workstations to be diskless.",
        "The resulting performance speedup is predicted to outweigh the advantages of disk caches."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_10",
      "title": "17.10 Summary",
      "label": "Topic",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 33,
      "definition": "A distributed system is a collection of processors that do not share memory or a clock.",
      "key_points": [
        "Instead, each processor has its own local memory, and the processors communicate with one another through various communication lines, such as high-speed buses and the Internet.",
        "The processors in a distributed system vary in size and function.",
        "They may include small microprocessors, personal computers, and large general-purpose computer systems.",
        "The processors in the system are connected through a communication network."
      ]
    },
    {
      "id": "CHAP_16_SUB_17_1",
      "title": "17.1 Why would it be a bad idea for gateways to pass broadcast packets",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 34,
      "definition": "between networks? What would be the advantages of doing so?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_2",
      "title": "17.2 Discuss the advantages and disadvantages of caching name transla-",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 34,
      "definition": "tions for computers located in remote domains.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_3",
      "title": "17.3 What are the advantages and disadvantages of using circuit switching?",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 34,
      "definition": "For what kinds of applications is circuit switching a viable strategy?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_4",
      "title": "17.4 What are two formidable problems that designers must solve to",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 34,
      "definition": "implement a network system that has the quality of transparency?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_5",
      "title": "17.5 Process migration within a heterogeneous network is usually impos-",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 35,
      "definition": "sible, given the differences in architectures and operating systems. Describe a method for process migration across different architectures running: a. The same operating system b. Different operating systems",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_6",
      "title": "17.6 To build a robust distributed system, you must know what kinds of",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 35,
      "definition": "failures can occur. a. List three possible types of failure in a distributed system. b. Specify which of the entries in your list also are applicable to a centralized system.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_7",
      "title": "17.7 Is it always crucial to know that the message you have sent has arrived",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 35,
      "definition": "at its destination safely? If your answer is \u201cyes,\u201d explain why. If your answer is \u201cno,\u201d give appropriate examples.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_8",
      "title": "17.8 A distributed system has two sites, A and B. Consider whether site A",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 35,
      "definition": "can distinguish among the following: a. B goes down. b. The link between A and B goes down. c. B is extremely overloaded, and its response time is 100 times longer than normal. What implications does your answer have for recovery in distributed systems? Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_9",
      "title": "17.9 What is the difference between computation migration and process",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 35,
      "definition": "migration? Which is easier to implement, and why?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_10",
      "title": "17.10 Even though the OSI model of networking speci\ufb01es seven layers of",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 35,
      "definition": "functionality, most computer systems use fewer layers to implement a network. Why do they use fewer layers? What problems could the use of fewer layers cause?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_11",
      "title": "17.11 Explain why doubling the speed of the systems on an Ethernet segment",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 35,
      "definition": "may result in decreased network performance. What changes could help solve this problem?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_12",
      "title": "17.12 What are the advantages of using dedicated hardware devices for",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 35,
      "definition": "routers and gateways? What are the disadvantages of using these devices compared with using general-purpose computers?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_13",
      "title": "17.13 In what ways is using a name server better than using static host tables?",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 35,
      "definition": "What problems or complications are associated with name servers? What methods could you use to decrease the amount of traf\ufb01c name servers generate to satisfy translation requests?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_14",
      "title": "17.14 Name servers are organized in a hierarchical manner. What is the",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "purpose of using a hierarchical organization?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_15",
      "title": "17.15 The lower layers of the OSI network model provide datagram service,",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "with no delivery guarantees for messages. A transport-layer protocol such as TCP is used to provide reliability. Discuss the advantages and disadvantages of supporting reliable message delivery at the lowest possible layer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_16",
      "title": "17.16 How does using a dynamic routing strategy affect application behav-",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "ior? For what type of applications is it bene\ufb01cial to use virtual routing instead of dynamic routing?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_17",
      "title": "17.17 Run the program shown in Figure 17.4 and determine the IP addresses",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "of the following host names: \u2022 www.wiley.com \u2022 www.cs.yale.edu \u2022 www.apple.com \u2022 www.westminstercollege.edu \u2022 www.ietf.org",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_18",
      "title": "17.18 The original HTTP protocol used TCP/IP as the underlying network",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "protocol. For each page, graphic, or applet, a separate TCP session was constructed, used, and torn down. Because of the overhead of building and destroying TCP/IP connections, performance problems resulted from this implementation method. Would using UDP rather than TCP be a good alternative? What other changes could you make to improve HTTP performance?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_19",
      "title": "17.19 What are the advantages and the disadvantages of making the com-",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "puter network transparent to the user?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_20",
      "title": "17.20 What are the bene\ufb01ts of a DFS compared with a \ufb01le system in a",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "centralized system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_21",
      "title": "17.21 Which of the example DFSs discussed in this chapter would handle a",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "large, multiclient database application most ef\ufb01ciently? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_22",
      "title": "17.22 Discuss whether OpenAFS and NFS provide the following: (a) location",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "transparency and (b) location independence.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_23",
      "title": "17.23 Under",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "what circumstances would a client prefer a location- transparent DFS? Under what circumstances would she prefer a location-independent DFS? Discuss the reasons for these preferences.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_24",
      "title": "17.24 What aspects of a distributed system would you select for a system",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "running on a totally reliable network?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_25",
      "title": "17.25 Consider OpenAFS, which is a stateful distributed \ufb01le system. What",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 36,
      "definition": "actions need to be performed to recover from a server crash in order to preserve the consistency guaranteed by the system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_26",
      "title": "17.26 Compare and contrast the techniques of caching disk blocks locally, on",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 37,
      "definition": "a client system, and remotely, on a server.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_27",
      "title": "17.27 OpenAFS is designed to support a large number of clients. Discuss three",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 37,
      "definition": "techniques used to make OpenAFS a scalable system.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_28",
      "title": "17.28 What are the bene\ufb01ts of mapping objects into virtual memory, as Apollo",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 37,
      "definition": "Domain does? What are the drawbacks?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16_SUB_17_29",
      "title": "17.29 Describe some of the fundamental differences between OpenAFS and",
      "label": "Exercise",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 37,
      "definition": "NFS (see Chapter 12). Bibliographical Notes [Tanenbaum (2010)] and [Kurose and Ross (2013)] provide general overviews of computer networks. The Internet and its protocols are described in [Comer (1999)] and [Comer (2000)]. Coverage of TCP/IP can be found in [Fall and Stevens (2011)] and [Stevens (1995)]. UNIX network programming is described thoroughly in [Steven et al. ()] and [Stevens (1998)]. Load balancing and load sharing are discussed by [Harchol-Balter and Downey (1997)] and [Vee and Hsu ",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_16",
      "title": "Chapter 17 Distributed Systems",
      "label": "Chapter",
      "file_source": "17_Chapter 17 Distributed Systems.pdf",
      "page": 1,
      "definition": "17 C H A P T E R Distributed Systems A distributed system is a collection of processors that do not share memory or a clock.",
      "key_points": [
        "17.1 Advantages of Distributed Systems A distributed system is a collection of loosely coupled nodes interconnected by a communication network.",
        "They may include small microprocessors, personal computers, and large general-purpose computer systems.",
        "These processors are referred to by a number of names, such as processors, sites, machines, and hosts, depending on the context in which they are mentioned.",
        "17.1 Advantages of Distributed Systems: A distributed system is a collection of loosely coupled nodes interconnected by ...",
        "17.1.1 Resource Sharing: If a number of different sites (with different capabilities) are connected to on...",
        "17.1.2 Computation Speedup: If a particular computation can be partitioned into subcomputations that can run...",
        "17.1.3 Reliability: If one site fails in a distributed system, the remaining sites can continue oper...",
        "17.1.4 Communication: When several sites are connected to one another by a communication network, user..."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_1",
      "title": "18.1 Linux History",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 1,
      "definition": "Linux looks and feels much like any other UNIX system; indeed, UNIX compatibility has been a major design goal of the Linux project.",
      "key_points": [
        "Its development began in 1991, when a Finnish university student, Linus Torvalds, began developing a small but self-contained kernel for the 80386 processor, the \ufb01rst true 32-bit processor in Intel\u2019s range of PC-compatible CPUs.",
        "However, Linux is much younger than most UNIX systems."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_1_1",
      "title": "18.1.1 The Linux Kernel",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 2,
      "definition": "The \ufb01rst Linux kernel released to the public was version 0.01, dated May 14, 1991.",
      "key_points": [
        "It had no networking, ran only on 80386-compatible Intel processors and PC hardware, and had extremely limited device-driver support.",
        "Perhaps the single biggest new feature was networking: 1.0 included support for UNIX\u2019s standard TCP/IP networking protocols, as well as a BSD-compatible socket interface for networking programming.",
        "The virtual memory subsystem was also fairly basic and included no support for memory-mapped \ufb01les; however, even this early incarnation supported shared pages with copy-on-write and protected address spaces.",
        "The only \ufb01le system supported was the Minix \ufb01le system, as the \ufb01rst Linux kernels were cross-developed on a Minix platform.",
        "The next milestone, Linux 1.0, was released on March 14, 1994."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_1_2",
      "title": "18.1.2 The Linux System",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 4,
      "definition": "As we noted earlier, the Linux kernel forms the core of the Linux project, but other components make up a complete Linux operating system.",
      "key_points": [
        "Whereas the Linux kernel is composed entirely of code written from scratch speci\ufb01cally for the Linux project, much of the supporting software that makes up the Linux system is not exclusive to Linux but is common to a number of UNIX-like operating systems.",
        "In particular, Linux uses many tools developed as part of Berkeley\u2019s BSD operating system, MIT\u2019s X Window System, and the Free Software Foundation\u2019s GNU project.",
        "This sharing of tools has worked in both directions.",
        "The main system libraries of Linux were originated by the GNU project, but the Linux community greatly improved the libraries by addressing omissions, inef\ufb01ciencies, and bugs.",
        "Other components, such as the GNU C compiler (gcc), were already of suf\ufb01ciently high quality to be used directly in Linux."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_1_3",
      "title": "18.1.3 Linux Distributions",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 5,
      "definition": "In theory, anybody can install a Linux system by fetching the latest revisions of the necessary system components from the FTP sites and compiling them.",
      "key_points": [
        "They typically include extra system-installation and management utilities, as well as precompiled and ready-to-install packages of many of the common UNIX tools, such as news servers, web browsers, text-processing and editing tools, and even games.",
        "One of the important contributions of modern distributions, however, is advanced package management.",
        "In Linux\u2019s early days, this is precisely what a Linux user had to do.",
        "As Linux has matured, however, various individuals and groups have attempted to make this job less painful by providing standard, precompiled sets of packages for easy installation.",
        "These collections, or distributions, include much more than just the basic Linux system."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_1_4",
      "title": "18.1.4 Linux Licensing",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 5,
      "definition": "The Linux kernel is distributed under version 2.0 of the GNU General Public License (GPL), the terms of which are set out by the Free Software Foundation.",
      "key_points": [
        "Linux is not public-domain software.",
        "Public domain implies that the authors have waived copyright rights in the software, but copyright rights in Linux code are still held by the code\u2019s various authors.",
        "Linux is free software, however, in the sense that people can copy it, modify it, use it in any manner they want, and give away (or sell) their own copies.",
        "The main implication of Linux\u2019s licensing terms is that nobody using Linux, or creating a derivative of Linux (a legitimate exercise), can distribute the derivative without including the source code.",
        "Software released under the GPL cannot be redistributed as a binary-only product."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_2",
      "title": "18.2 Design Principles",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 6,
      "definition": "It is a multiuser, preemptively multitasking system with a full set of UNIX-compatible tools.",
      "key_points": [
        "Today, Linux can run happily on a multiprocessor machine with many gigabytes of main memory and many terabytes of disk space, but it is still capable of operating usefully in under 16 MB of RAM.",
        "Speed and ef\ufb01ciency are still important design goals, but much recent and current work on Linux has concentrated on a third major design goal: standardization.",
        "There are POSIX documents for common operating-system functionality and for extensions such as process threads and real-time operations.",
        "However, supporting a wide base of applications is important for any operating system, so implementation of standards is a major goal for Linux development, even if the implementation is not formally certi\ufb01ed."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_2_1",
      "title": "18.2.1 Components of a Linux System",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 7,
      "definition": "The Linux system is composed of three main bodies of code, in line with most traditional UNIX implementations: 1.",
      "key_points": [
        "The kernel is responsible for maintaining all the important abstractions of the operating system, including such things as virtual memory and processes.",
        "The most important system library is the C library, known as libc.",
        "The most important distinction here is between the kernel and everything else.",
        "All the kernel code executes in the processor\u2019s privileged mode with full access to all the physical resources of the computer.",
        "system shared libraries Linux kernel loadable kernel modules system- management programs user processes user utility programs compilers Figure 18.1 Components of the Linux system."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_3",
      "title": "18.3 Kernel Modules",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 9,
      "definition": "The Linux kernel has the ability to load and unload arbitrary sections of kernel code on demand.",
      "key_points": [
        "These loadable kernel modules run in privileged kernel mode and as a consequence have full access to all the hardware capabilities of the machine on which they run.",
        "In theory, there is no restriction on what a kernel module is allowed to do.",
        "Among other things, a kernel module can implement a device driver, a \ufb01le system, or a networking protocol.",
        "Kernel modules are convenient for several reasons.",
        "Linux\u2019s source code is free, so anybody wanting to write kernel code is able to compile a modi\ufb01ed kernel and to reboot into that new functionality."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_3_1",
      "title": "18.3.1 Module Management",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 9,
      "definition": "Loading a module requires more than just loading its binary contents into kernel memory.",
      "key_points": [
        "The system must also make sure that any references the"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_3_2",
      "title": "18.3.2 Driver Registration",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 10,
      "definition": "Once a module is loaded, it remains no more than an isolated region of memory until it lets the rest of the kernel know what new functionality it provides.",
      "key_points": [
        "The kernel maintains dynamic tables of all known drivers and provides a set of routines to allow drivers to be added to or removed from these tables at any time.",
        "The kernel makes sure that it calls a module\u2019s startup routine when that module is loaded and calls the module\u2019s cleanup routine before"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_3_3",
      "title": "18.3.3 Con\ufb02ict Resolution",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 11,
      "definition": "Commercial UNIX implementations are usually sold to run on a vendor\u2019s own hardware.",
      "key_points": [
        "One advantage of a single-supplier solution is that the software vendor has a good idea about what hardware con\ufb01gurations are possible.",
        "PC hardware, however, comes in a vast number of con\ufb01gurations, with large numbers of possible drivers for devices such as network cards and video display adapters.",
        "The problem of managing the hardware con\ufb01guration becomes more severe when modular device drivers are supported, since the currently active set of devices becomes dynamically variable.",
        "Linux provides a central con\ufb02ict-resolution mechanism to help arbitrate access to certain hardware resources.",
        "Its aims are as follows: \u2022 To prevent modules from clashing over access to hardware resources \u2022 To prevent autoprobes\u2014device-driver probes that auto-detect device con\ufb01guration\u2014from interfering with existing device drivers \u2022 To resolve con\ufb02icts among multiple drivers trying to access the same hardware\u2014as, for example, when both the parallel printer driver and the parallel line IP (PLIP) network driver try to talk to the parallel port To these ends, the kernel maintains lists of allocated hardware resources."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_4",
      "title": "18.4 Process Management",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 12,
      "definition": "A process is the basic context in which all user-requested activity is serviced within the operating system.",
      "key_points": [
        "To be compatible with other UNIX systems, Linux must use a process model similar to those of other versions of UNIX.",
        "Linux operates differently from UNIX in a few key places, however.",
        "In this section, we review the traditional UNIX process model (Section A.3.2) and introduce Linux\u2019s threading model."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_4_1",
      "title": "18.4.1 The fork() and exec() Process Model",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 12,
      "definition": "The basic principle of UNIX process management is to separate into two steps two operations that are usually combined into one: the creation of a new process and the running of a new program.",
      "key_points": [
        "A new process is created by the fork() system call, and a new program is run after a call to exec().",
        "We can create a new process with fork() without running a new program\u2014the new subprocess simply continues to execute exactly the same program, at exactly the same point, that the \ufb01rst (parent) process was running.",
        "In the same way, running a new program does not require that a new process be created \ufb01rst.",
        "Any process may call exec() at any time.",
        "A new binary object is loaded into the process\u2019s address space and the new executable starts executing in the context of the existing process."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_4_2",
      "title": "18.4.2 Processes and Threads",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 15,
      "definition": "Linux provides the fork() system call, which duplicates a process without loading a new executable image.",
      "key_points": [
        "Linux does not distinguish between processes and threads, however.",
        "In fact, Linux generally uses the term task \u2014rather than process or thread\u2014when referring to a \ufb02ow of control within a program.",
        "The clone() system call behaves identically to fork(), except that it accepts as arguments a set of \ufb02ags that dictate what resources are shared between the parent and child (whereas a process created with fork() shares no resources with its parent).",
        "The lack of distinction between processes and threads is possible because Linux does not hold a process\u2019s entire context within the main process data structure.",
        "Thus, a process\u2019s \ufb01le-system context, \ufb01le-descriptor table, signal-handler table, and virtual memory context are held in separate data structures."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_5",
      "title": "18.5 Scheduling",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 15,
      "definition": "Scheduling is the job of allocating CPU time to different tasks within an operat- ing system.",
      "key_points": [
        "In such a system, the process scheduler decides which process runs and when.",
        "Linux, like all UNIX systems, supports preemptive multitasking."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_5_1",
      "title": "18.5.1 Process Scheduling",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 16,
      "definition": "One is a time-sharing algorithm for fair, preemptive scheduling among multiple processes.",
      "key_points": [
        "Linux has two separate process-scheduling algorithms.",
        "The other is designed for real-time tasks, where absolute priorities are more important than fairness.",
        "The process scheduler was \ufb01rst overhauled with version 2.5 of the kernel.",
        "Version 2.5 implemented a scheduling algorithm that selects which task to run in constant time\u2014known as O(1)\u2014regardless of the number of tasks or processors in the system.",
        "The new scheduler also provided increased support for SMP, including processor af\ufb01nity and load balancing."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_5_2",
      "title": "18.5.2 Real-Time Scheduling",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 17,
      "definition": "Linux\u2019s real-time scheduling algorithm is signi\ufb01cantly simpler than the fair scheduling employed for standard time-sharing processes.",
      "key_points": [
        "In both cases, each process has a priority in addition to its scheduling class.",
        "The scheduler always runs the process with the highest priority.",
        "Among processes of equal priority, it runs the process that has been waiting longest."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_5_3",
      "title": "18.5.3 Kernel Synchronization",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 18,
      "definition": "The way the kernel schedules its own operations is fundamentally different from the way it schedules processes.",
      "key_points": [
        "As a result, kernel synchronization involves much more than just process scheduling.",
        "Prior to version 2.6, Linux was a nonpreemptive kernel, meaning that a process running in kernel mode could not be preempted\u2014even if a higher- priority process became available to run.",
        "On single-processor machines, spinlocks are not appropriate for use and are replaced by enabling and disabling kernel preemption.",
        "This pattern is summarized below: single processor multiple processors Acquire spin lock."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_5_4",
      "title": "18.5.4 Symmetric Multiprocessing",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 20,
      "definition": "The Linux 2.0 kernel was the \ufb01rst stable Linux kernel to support symmetric multiprocessor (SMP) hardware, allowing separate processes to execute in parallel on separate processors.",
      "key_points": [
        "The original implementation of SMP imposed the restriction that only one processor at a time could be executing kernel code.",
        "In version 2.2 of the kernel, a single kernel spinlock (sometimes termed BKL for \u201cbig kernel lock\u201d) was created to allow multiple processes (running on different processors) to be active in the kernel concurrently.",
        "However, the BKL provided a very coarse level of locking granularity, resulting in poor scalability to machines with many processors and processes.",
        "Such spinlocks are described in Section 18.5.3. The 3.0 kernel provides additional SMP enhancements, including ever-\ufb01ner locking, processor af\ufb01nity, and load-balancing algorithms."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_6",
      "title": "18.6 Memory Management",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 20,
      "definition": "Memory management under Linux has two components.",
      "key_points": [
        "The second handles virtual memory, which is memory-mapped into the address space of running processes.",
        "In this section, we describe these two components and then examine the mechanisms by which the loadable components of a new program are brought into a process\u2019s virtual memory in response to an exec() system call.",
        "The \ufb01rst deals with allocating and freeing physical memory\u2014pages, groups of pages, and small blocks of RAM."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_6_1",
      "title": "18.6.1 Management of Physical Memory",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 21,
      "definition": "Due to speci\ufb01c hardware constraints, Linux separates physical memory into four different zones, or regions: \u2022 ZONE DMA \u2022 ZONE DMA32 \u2022 ZONE NORMAL \u2022 ZONE HIGHMEM These zones are architecture speci\ufb01c.",
      "key_points": [
        "The primary physical-memory manager in the Linux kernel is the page allocator.",
        "For example, on the Intel x86-32 architec- ture, certain ISA (industry standard architecture) devices can only access the lower 16 MB of physical memory using DMA.",
        "On these systems, the \ufb01rst 16 MB of physical memory comprise ZONE DMA.",
        "On other systems, certain devices can only access the \ufb01rst 4 GB of physical memory, despite supporting 64- bit addresses.",
        "On such systems, the \ufb01rst 4 GB of physical memory comprise ZONE DMA32."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_6_2",
      "title": "18.6.2 Virtual Memory",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 24,
      "definition": "The Linux virtual memory system is responsible for maintaining the address space accessible to each process.",
      "key_points": [
        "Under Linux, the virtual memory manager maintains two separate views of a process\u2019s address space: as a set of separate regions and as a set of pages.",
        "Each region is described internally by a single vm area struct structure that de\ufb01nes the properties of the region, including the process\u2019s read, write, and execute permissions in the region as well as information about any \ufb01les associated with the region.",
        "This view is stored in the hardware page tables for the process.",
        "The physical view is managed by a set of routines, which are invoked from the kernel\u2019s software-interrupt handlers whenever a process tries to access a page that is not currently present in the page tables.",
        "Each vm area struct in the address-space description contains a \ufb01eld pointing to a table of functions that implement the key page-management functionality for any given virtual memory region."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_6_3",
      "title": "18.6.3 Execution and Loading of User Programs",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 27,
      "definition": "The Linux kernel\u2019s execution of user programs is triggered by a call to the exec() system call.",
      "key_points": [
        "This exec() call commands the kernel to run a new program within the current process, completely overwriting the current execution context with the initial context of the new program.",
        "The \ufb01rst job of this system service is to verify that the calling process has permission rights to the \ufb01le being executed.",
        "ELF has a number of advantages over a.out, including \ufb02exibility and extendability."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_7",
      "title": "18.7 File Systems",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 29,
      "definition": "Linux retains UNIX\u2019s standard \ufb01le-system model.",
      "key_points": [
        "Device drivers can appear as \ufb01les, and interprocess- communication channels or network connections also look like \ufb01les to the user.",
        "In UNIX, a \ufb01le does not have to be an object stored on disk or fetched over a network from a remote \ufb01le server.",
        "Rather, UNIX \ufb01les can be anything capable of handling the input or output of a stream of data.",
        "The Linux kernel handles all these types of \ufb01les by hiding the implemen- tation details of any single \ufb01le type behind a layer of software, the virtual \ufb01le system (VFS).",
        "Here, we \ufb01rst cover the virtual \ufb01le system and then discuss the standard Linux \ufb01le system\u2014ext3."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_7_1",
      "title": "18.7.1 The Virtual File System",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 29,
      "definition": "The Linux VFS is designed around object-oriented principles.",
      "key_points": [
        "It has two components: a set of de\ufb01nitions that specify what \ufb01le-system objects are allowed to look like and a layer of software to manipulate the objects.",
        "The VFS de\ufb01nes four main object types: \u2022 An inode object represents an individual \ufb01le.",
        "\u2022 A \ufb01le object represents an open \ufb01le.",
        "\u2022 A superblock object represents an entire \ufb01le system.",
        "\u2022 A dentry object represents an individual directory entry."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_7_2",
      "title": "18.7.2 The Linux ext3 File System",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 31,
      "definition": "The standard on-disk \ufb01le system used by Linux is called ext3, for historical reasons.",
      "key_points": [
        "A later redesign to improve performance and scalability and to add a few missing features led to the second extended \ufb01le system (ext2).",
        "Linux kernel developers are working on augmenting ext3 with modern \ufb01le-system features such as extents.",
        "Linux was originally programmed with a Minix-compatible \ufb01le system, to ease exchanging data with the Minix development system, but that \ufb01le system was severely restricted by 14-character \ufb01le-name limits and a maximum \ufb01le-system size of 64 MB.",
        "The Minix \ufb01le system was superseded by a new \ufb01le system, which was christened the extended \ufb01le system (extfs).",
        "Further development added journaling capabilities, and the system was renamed the third extended \ufb01le system (ext3)."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_7_3",
      "title": "18.7.3 Journaling",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 33,
      "definition": "A set of operations that performs a speci\ufb01c task is a transaction.",
      "key_points": [
        "The ext3 \ufb01le system supports a popular feature called journaling, whereby modi\ufb01cations to the \ufb01le system are written sequentially to a journal.",
        "Once a transaction is written to the journal, it is considered to be committed.",
        "Meanwhile, the journal entries relating to the transaction are replayed across the actual \ufb01le- system structures.",
        "As the changes are made, a pointer is updated to indicate which actions have completed and which are still incomplete.",
        "When an entire committed transaction is completed, it is removed from the journal."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_7_4",
      "title": "18.7.4 The Linux Process File System",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 34,
      "definition": "The \ufb02exibility of the Linux VFS enables us to implement a \ufb01le system that does not store data persistently at all but rather provides an interface to some other functionality.",
      "key_points": [
        "The Linux process \ufb01le system, known as the /proc \ufb01le system, is an example of a \ufb01le system whose contents are not actually stored anywhere but are computed on demand according to user \ufb01le I/O requests.",
        "SVR4 UNIX introduced a /proc \ufb01le system as an ef\ufb01cient interface to the kernel\u2019s process debugging support.",
        "Each subdirectory of the \ufb01le system corresponded not to a directory on any disk but rather to an active process on the current system.",
        "A listing of the \ufb01le system reveals one directory per process, with the directory name being the ASCII decimal representation of the process\u2019s unique process identi\ufb01er (PID).",
        "The /proc \ufb01le system provides a way for programs to access this information as plain text \ufb01les; the standard UNIX user environment provides powerful tools to process such \ufb01les."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_8",
      "title": "18.8 Input and Output",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 35,
      "definition": "To the user, the I/O system in Linux looks much like that in any UNIX system.",
      "key_points": [
        "That is, to the extent possible, all device drivers appear as normal \ufb01les.",
        "Users can open an access channel to a device in the same way they open any other \ufb01le\u2014devices can appear as objects within the \ufb01le system.",
        "The system administrator can create special \ufb01les within a \ufb01le system that contain references to a speci\ufb01c device driver, and a user opening such a \ufb01le will be able to read from and write to the device referenced.",
        "By using the normal \ufb01le-protection system, which determines who can access which \ufb01le, the administrator can set access permissions for each device.",
        "Linux splits all devices into three classes: block devices, character devices, and network devices."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_8_1",
      "title": "18.8.1 Block Devices",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 36,
      "definition": "Block devices provide the main interface to all disk devices in a system.",
      "key_points": [
        "Performance is particularly important for disks, and the block-device system must provide functionality to ensure that disk access is as fast as possible.",
        "When a request is accepted for processing by a block-device driver, it is not removed from the list.",
        "This functionality is achieved through the scheduling of I/O operations.",
        "In the context of block devices, a block represents the unit with which the kernel performs I/O.",
        "When a block is read into memory, it is stored in a buffer."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_8_2",
      "title": "18.8.2 Character Devices",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 37,
      "definition": "A character-device driver can be almost any device driver that does not offer random access to \ufb01xed blocks of data.",
      "key_points": [
        "The kernel performs almost no preprocessing of a \ufb01le read or write request to a character device.",
        "The most common line discipline is the tty discipline, which glues the terminal\u2019s data stream onto the standard input and output streams of a user\u2019s running processes, allowing those processes to communicate directly with the user\u2019s terminal.",
        "This job is complicated by the fact that several such processes may be running simultaneously, and the tty line discipline is responsible for attaching and detaching the terminal\u2019s input and output from the various processes connected to it as those processes are suspended or awakened by the user.",
        "Other line disciplines also are implemented that have nothing to do with I/O to a user process."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_9",
      "title": "18.9 Interprocess Communication",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 38,
      "definition": "Linux provides a rich environment for processes to communicate with each other.",
      "key_points": [
        "Communication may be just a matter of letting another process know that some event has occurred, or it may involve transferring data from one process to another."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_9_1",
      "title": "18.9.1 Synchronization and Signals",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 38,
      "definition": "The standard Linux mechanism for informing a process that an event has occurred is the signal.",
      "key_points": [
        "Signals can be sent from any process to any other process, with restrictions on signals sent to processes owned by another user.",
        "Only the fact that a signal has occurred is available to a process.",
        "Signals are not generated only by processes.",
        "For example, it can send a signal to a server process when data arrive on a network channel, to a parent process when a child terminates, or to a waiting process when a timer expires.",
        "Internally, the Linux kernel does not use signals to communicate with processes running in kernel mode."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_9_2",
      "title": "18.9.2 Passing of Data among Processes",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 38,
      "definition": "Linux offers several mechanisms for passing data among processes.",
      "key_points": [
        "The stan- dard UNIX pipe mechanism allows a child process to inherit a communication channel from its parent; data written to one end of the pipe can be read at the other.",
        "UNIX also de\ufb01nes a set of networking facilities that can send streams of data to both local and remote processes.",
        "Under Linux, pipes appear as just another type of inode to virtual \ufb01le system software, and each pipe has a pair of wait queues to synchronize the reader and writer.",
        "Networking is covered in Section 18.10."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_10",
      "title": "18.10 Network Structure",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 39,
      "definition": "Networking is a key area of functionality for Linux.",
      "key_points": [
        "Not only does Linux support the standard Internet protocols used for most UNIX-to-UNIX com- munications, but it also implements a number of protocols native to other, non-UNIX operating systems.",
        "In particular, since Linux was originally imple- mented primarily on PCs, rather than on large workstations or on server-class systems, it supports many of the protocols typically used on PC networks, such as AppleTalk and IPX.",
        "Internally, networking in the Linux kernel is implemented by three layers of software: 1.",
        "The socket interface 2.",
        "Network-device drivers User applications perform all networking requests through the socket interface."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_11",
      "title": "18.11 Security",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 41,
      "definition": "Linux\u2019s security model is closely related to typical UNIX security mechanisms.",
      "key_points": [
        "The security concerns can be classi\ufb01ed in two groups: 1.",
        "Making sure that nobody can access the system without \ufb01rst proving that she has entry rights 2.",
        "Providing a mechanism for checking whether a user has the right to access a certain object and preventing access to objects as required"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_11_1",
      "title": "18.11.1 Authentication",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 42,
      "definition": "The use of the one-way function means that the original password cannot be deduced from the password \ufb01le except by trial and error.",
      "key_points": [
        "If a new authentication mechanism is added at a later date, it can be added to the con\ufb01guration \ufb01le, and all system components will immediately be able to take advantage of it.",
        "A user\u2019s password is combined with a random \u201csalt\u201d value, and the result is encoded with a one-way transformation function and stored in the password \ufb01le.",
        "When a user presents a password to the system, the password is recombined with the salt value stored in the password \ufb01le and passed through the same one-way transformation.",
        "If the result matches the contents of the password \ufb01le, then the password is accepted.",
        "Historically, UNIX implementations of this mechanism have had several drawbacks."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_11_2",
      "title": "18.11.2 Access Control",
      "label": "Topic",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 42,
      "definition": "Access control under UNIX systems, including Linux, is performed through the use of unique numeric identi\ufb01ers.",
      "key_points": [
        "User processes also have a single UID, but they may have more than one GID.",
        "If a process\u2019s UID matches the UID of an object, then the process has user rights or owner rights to that object.",
        "A user identi\ufb01er (UID) identi\ufb01es a single user or a single set of access rights.",
        "A group identi\ufb01er (GID) is an extra identi\ufb01er that can be used to identify rights belonging to more than one user.",
        "Access control is applied to various objects in the system."
      ]
    },
    {
      "id": "CHAP_17_SUB_18_12",
      "title": "18.12 Summary",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 44,
      "definition": "Linux is a modern, free operating system based on UNIX standards. It has been designed to run ef\ufb01ciently and reliably on common PC hardware; it also runs on a variety of other platforms, such as mobile phones. It provides a programming interface and user interface compatible with standard UNIX systems and can run a large number of UNIX applications, including an increasing number of commercially supported applications. Linux has not evolved in a vacuum. A complete Linux system includes many comp",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_1",
      "title": "18.1 Dynamically loadable kernel modules give \ufb02exibility when drivers are",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 44,
      "definition": "added to a system, but do they have disadvantages too? Under what circumstances would a kernel be compiled into a single binary \ufb01le, and when would it be better to keep it split into modules? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_2",
      "title": "18.2 Multithreading is a commonly used programming technique. Describe",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "three different ways to implement threads, and compare these three methods with the Linux clone() mechanism. When might using each alternative mechanism be better or worse than using clones?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_3",
      "title": "18.3 The Linux kernel does not allow paging out of kernel memory. What",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "effect does this restriction have on the kernel\u2019s design? What are two advantages and two disadvantages of this design decision?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_4",
      "title": "18.4 Discuss three advantages of dynamic (shared) linkage of libraries",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "compared with static linkage. Describe two cases in which static linkage is preferable.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_5",
      "title": "18.5 Compare the use of networking sockets with the use of shared memory",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "as a mechanism for communicating data between processes on a single computer. What are the advantages of each method? When might each be preferred?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_6",
      "title": "18.6 At one time, UNIX systems used disk-layout optimizations based",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "on the rotation position of disk data, but modern implementations, including Linux, simply optimize for sequential data access. Why do they do so? Of what hardware characteristics does sequential access take advantage? Why is rotational optimization no longer so useful? Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_7",
      "title": "18.7 What are the advantages and disadvantages of writing an operating",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "system in a high-level language, such as C?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_8",
      "title": "18.8 In what circumstances is the system-call sequence fork() exec() most",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "appropriate? When is vfork() preferable?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_9",
      "title": "18.9 What socket type should be used to implement an intercomputer",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "\ufb01le-transfer program? What type should be used for a program that periodically tests to see whether another computer is up on the network? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_10",
      "title": "18.10 Linux runs on a variety of hardware platforms. What steps must",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "Linux developers take to ensure that the system is portable to different processors and memory-management architectures and to minimize the amount of architecture-speci\ufb01c kernel code?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_11",
      "title": "18.11 What are the advantages and disadvantages of making only some of the",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "symbols de\ufb01ned inside a kernel accessible to a loadable kernel module?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_12",
      "title": "18.12 What are the primary goals of the con\ufb02ict-resolution mechanism used",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "by the Linux kernel for loading kernel modules?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_13",
      "title": "18.13 Discuss how the clone() operation supported by Linux is used to",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "support both processes and threads.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_14",
      "title": "18.14 Would youclassifyLinuxthreadsasuser-level threadsor askernel-level",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "threads? Support your answer with the appropriate arguments.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_15",
      "title": "18.15 What extra costs are incurred in the creation and scheduling of a",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 45,
      "definition": "process, compared with the cost of a cloned thread?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_16",
      "title": "18.16 How does Linux\u2019s Completely Fair Scheduler (CFS) provide improved",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 46,
      "definition": "fairness over a traditional UNIX process scheduler? When is the fairness guaranteed?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_17",
      "title": "18.17 What are the two con\ufb01gurable variables of the Completely Fair Sched-",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 46,
      "definition": "uler (CFS)? What are the pros and cons of setting each of them to very small and very large values?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_18",
      "title": "18.18 The Linux scheduler implements \u201csoft\u201d real-time scheduling. What",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 46,
      "definition": "features necessary for certain real-time programming tasks are missing? How might they be added to the kernel? What are the costs (downsides) of such features?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_19",
      "title": "18.19 Under what circumstances would a user process request an operation",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 46,
      "definition": "that results in the allocation of a demand-zero memory region?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_20",
      "title": "18.20 What scenarios would cause a page of memory to be mapped into a user",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 46,
      "definition": "program\u2019s address space with the copy-on-write attribute enabled?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_21",
      "title": "18.21 In Linux, shared libraries perform many operations central to the",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 46,
      "definition": "operating system. What is the advantage of keeping this functionality out of the kernel? Are there any drawbacks? Explain your answer.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_22",
      "title": "18.22 What are the bene\ufb01ts of a journaling \ufb01le system such as Linux\u2019s ext3?",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 46,
      "definition": "What are the costs? Why does ext3 provide the option to journal only metadata?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_23",
      "title": "18.23 The directory structure of a Linux operating system could include \ufb01les",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 46,
      "definition": "corresponding to several different \ufb01le systems, including the Linux /proc \ufb01le system. How might the need to support different \ufb01le-system types affect the structure of the Linux kernel?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_24",
      "title": "18.24 In what ways does the Linux setuid feature differ from the setuid",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 46,
      "definition": "feature SVR4?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17_SUB_18_25",
      "title": "18.25 The Linux source code is freely and widely available over the Inter-",
      "label": "Exercise",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 46,
      "definition": "net and from CD-ROM vendors. What are three implications of this availability for the security of the Linux system? Bibliographical Notes The Linux system is a product of the Internet; as a result, much of the available documentation on Linux is available in some form on the Internet. The following key sites reference most of the useful information available: \u2022 The Linux Cross-Reference Page (LXR) (http://lxr.linux.no) maintains current listings of the Linux kernel, browsable via the Web and ful",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_17",
      "title": "Chapter 18 The Linux System",
      "label": "Chapter",
      "file_source": "18_Chapter 18 The Linux System.pdf",
      "page": 1,
      "definition": "Linux is a variant of UNIX that has gained popularity over the last several decades, powering devices as small as mobile phones and as large as room- \ufb01lling supercomputers.",
      "key_points": [
        "\u2022 To examine the Linux process model and illustrate how Linux schedules processes and provides interprocess communication.",
        "Its development began in 1991, when a Finnish university student, Linus Torvalds, began developing a small but self-contained kernel for the 80386 processor, the \ufb01rst true 32-bit processor in Intel\u2019s range of PC-compatible CPUs.",
        "By examining a complete, real system, we can see how the concepts we have discussed relate both to one another and to practice.",
        "18.1 Linux History: Linux looks and feels much like any other UNIX system; indeed, UNIX compatibilit...",
        "18.1.1 The Linux Kernel: The \ufb01rst Linux kernel released to the public was version 0.01, dated May 14, 199...",
        "18.1.2 The Linux System: As we noted earlier, the Linux kernel forms the core of the Linux project, but o...",
        "18.1.3 Linux Distributions: In theory, anybody can install a Linux system by fetching the latest revisions o...",
        "18.1.4 Linux Licensing: The Linux kernel is distributed under version 2.0 of the GNU General Public Lice..."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_1",
      "title": "19.1 History",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 1,
      "definition": "In the mid-1980s, Microsoft and IBM cooperated to develop the OS/2 operating system, which was written in assembly language for single-processor Intel systems.",
      "key_points": [
        "In 1988, Microsoft decided to end the joint effort with IBM and develop its own \u201cnew technology\u201d (or NT) portable operating system to support both the OS/2 and POSIX application-programming interfaces (APIs)."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_2",
      "title": "19.2 Design Principles",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 3,
      "definition": "Microsoft\u2019s design goals for Windows included security, reliability, Windows and POSIX application compatibility, high performance, extensibility, porta- bility, and international support.",
      "key_points": [
        "Some additional goals, energy ef\ufb01ciency and dynamic device support, have recently been added to this list.",
        "Next, we discuss each of these goals and how it is achieved in Windows 7."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_2_1",
      "title": "19.2.1 Security",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 3,
      "definition": "Windows 7 security goals required more than just adherence to the design standards that had enabled Windows NT 4.0 to receive a C2 security classi\ufb01ca-",
      "key_points": []
    },
    {
      "id": "CHAP_18_SUB_19_2_2",
      "title": "19.2.2 Reliability",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 4,
      "definition": "Windows matured greatly as an operating system in its \ufb01rst ten years, leading to Windows 2000.",
      "key_points": [
        "At the same time, its reliability increased due to such factors as maturity in the source code, extensive stress testing of the system, improved CPU architectures, and automatic detection of many serious errors in drivers"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_2_3",
      "title": "19.2.3 Windows and POSIX Application Compatibility",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 5,
      "definition": "As mentioned, Windows XP was both an update of Windows 2000 and a replacement for Windows 95/98.",
      "key_points": [
        "Windows 2000 focused primarily on compatibility for business applications.",
        "The requirements for Windows XP included a much higher compatibility with the consumer applications that ran on Windows 95/98.",
        "Application compatibility is dif\ufb01cult to achieve because many applications check for a particular version of Windows, may depend to some extent on the quirks of the implementation of APIs, may have latent application bugs that were masked in the previous system, and so"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_2_4",
      "title": "19.2.4 High Performance",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 6,
      "definition": "Windows was designed to provide high performance on desktop systems (which are largely constrained by I/O performance), server systems (where the CPU is often the bottleneck), and large multithreaded and multiprocessor environments (where locking performance and cache-line management are keys to scalability).",
      "key_points": [
        "The memory-management and synchronization algorithms were designed with an awareness of the performance considerations related to cache lines and multiprocessors.",
        "Windows NT was designed for symmetrical multiprocessing (SMP); on a multiprocessor computer, several threads can run at the same time, even in the kernel.",
        "Except while executing in the kernel dispatcher or at interrupt level, threads in any process running in Windows can be preempted by higher-priority threads.",
        "When a thread requests a synchronous service from another process through an LPC, the servicing thread is marked ready, and its priority is temporarily boosted to avoid the scheduling delays that would occur if it had to wait for threads already in the queue.",
        "Windows XP further improved performance by reducing the code-path length in critical functions, using better algorithms and per-processor data structures, using memory coloring for non-uniform memory access (NUMA) machines, and implementing more scalable locking protocols, such as queued spinlocks."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_2_5",
      "title": "19.2.5 Extensibility",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 8,
      "definition": "Extensibility refers to the capacity of an operating system to keep up with advances in computing technology.",
      "key_points": [
        "Windows uses a client\u2013server model like the Mach operating system and supports distributed processing by remote procedure calls (RPCs) as de\ufb01ned by the Open Software Foundation.",
        "To facilitate change over time, the devel- opers implemented Windows using a layered architecture.",
        "The Windows executive runs in kernel mode and provides the basic system services and abstractions that support shared use of the system.",
        "On top of the executive, several server subsystems operate in user mode.",
        "Among them are environ- mental subsystems that emulate different operating systems."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_2_6",
      "title": "19.2.6 Portability",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 8,
      "definition": "An operating system is portable if it can be moved from one CPU architecture to another with relatively few changes.",
      "key_points": [
        "Windows was designed to be portable.",
        "Like the UNIX operating system, Windows is written primarily in C and C++.",
        "The architecture-speci\ufb01c source code is relatively small, and there is very little use of assembly code.",
        "Porting Windows to a new architecture mostly affects the Windows kernel, since the user-mode code in Windows is almost exclusively written to be architecture independent.",
        "To port Windows, the kernel\u2019s architecture-speci\ufb01c code must be ported, and sometimes conditional compilation is needed in other parts of the kernel because of changes in major data structures, such as the page-table format."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_2_7",
      "title": "19.2.7 International Support",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 9,
      "definition": "Windows was designed for international and multinational use.",
      "key_points": [
        "Multiple locales can be used concurrently, which is important to multilingual individuals and businesses.",
        "It provides support for different locales via the national-language-support (NLS) API.",
        "The NLS API provides specialized routines to format dates, time, and money in accordance with national customs.",
        "String comparisons are specialized to account for varying character sets.",
        "UNICODE is Windows\u2019s native character code."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_2_8",
      "title": "19.2.8 Energy Ef\ufb01ciency",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 9,
      "definition": "Increasing energy ef\ufb01ciency for computers causes batteries to last longer for laptops and netbooks, saves signi\ufb01cant operating costs for power and cooling of data centers, and contributes to green initiatives aimed at lowering energy consumption by businesses and consumers.",
      "key_points": [
        "For some time, Windows has implemented several strategies for decreasing energy use.",
        "The CPUs are moved to lower power states\u2014for example, by lowering clock frequency\u2014whenever possible.",
        "In addition, when a computer is not being actively used, Windows may put the entire computer into a low-power state (sleep) or may even save all of memory to disk and shut the computer off (hibernation).",
        "When the user returns, the computer powers up and continues from its previous state, so the user does not need to reboot and restart applications.",
        "Windows 7 added some new strategies for saving energy."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_2_9",
      "title": "19.2.9 Dynamic Device Support",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 9,
      "definition": "Early in the history of the PC industry, computer con\ufb01gurations were fairly static.",
      "key_points": [
        "The next steps toward dynamic con\ufb01guration of PCs were laptop docks and PCMIA cards.",
        "Occasionally, new devices might be plugged into the serial, printer, or game ports on the back of a computer, but that was it.",
        "A PC could suddenly be connected to or disconnected from a whole set of peripherals.",
        "In a contemporary PC, the situation has completely changed.",
        "PCs are designed to enable users to plug and unplug a huge host of peripherals all the time; external disks, thumb drives, cameras, and the like are constantly coming and going."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_3",
      "title": "19.3 System Components",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 10,
      "definition": "The architecture of Windows is a layered system of modules, as shown in Figure 19.1. The main layers are the HAL, the kernel, and the executive, all of which run in kernel mode, and a collection of subsystems and services that run in user mode.",
      "key_points": [
        "One of the chief advantages of this type of architecture is that interactions between modules are kept simple.",
        "The user-mode subsystems fall into two categories: the environmental subsystems, which emulate different operating systems, and the protection subsystems, which provide security functions.",
        "The remainder of this section describes these layers and subsystems."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_3_1",
      "title": "19.3.1 Hardware-Abstraction Layer",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 10,
      "definition": "The HAL is the layer of software that hides hardware chipset differences from upper levels of the operating system.",
      "key_points": [
        "The HAL exports a virtual hardware"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_3_2",
      "title": "19.3.2 Kernel",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 11,
      "definition": "An object type in Windows is a system-de\ufb01ned data type that has a set of attributes (data values) and a set of methods (for example, functions or operations).",
      "key_points": [
        "The kernel layer of Windows has four main responsibilities: thread scheduling, low-level processor synchronization, interrupt and exception handling, and switching between user mode and kernel mode.",
        "19.3.2.2 Threads and Scheduling Like many other modern operating systems, Windows uses processes and threads for executable code.",
        "Each process has one or more threads, and each thread has its own scheduling state, including actual priority, processor af\ufb01nity, and CPU usage information.",
        "In a multiprocessor system, each processor keeps one thread in a standby state.",
        "A thread is running when it is executing on a processor."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_3_3",
      "title": "19.3.3 Executive",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 16,
      "definition": "The Windows executive provides a set of services that all environmental subsystems use.",
      "key_points": [
        "The services are grouped as follows: object manager, virtual memory manager, process manager, advanced local procedure call facility, I/O manager, cache manager, security reference monitor, plug-and-play and power managers, registry, and booting.",
        "Examples of objects are semaphores, mutexes, events, processes, and threads; all these are dispatcher objects.",
        "The process, thread, and virtual memory APIs use process and thread handles to identify the process or thread to be operated on.",
        "User-mode code accesses these objects using an opaque value called a handle, which is returned by many APIs. Each process has a handle table containing entries that track the objects used by the process.",
        "The system process, which contains the kernel, has its own handle table, which is protected from user code."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_4",
      "title": "19.4 Terminal Services and Fast User Switching",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 34,
      "definition": "Windows supports a GUI-based console that interfaces with the user via keyboard, mouse, and display.",
      "key_points": [
        "Each user that is logged on using the GUI has a session created to represent the GUI environment he will be using and to contain all the processes created to run his applications.",
        "However, Windows only supports a single console, consisting of all the monitors, keyboards, and mice connected to the PC.",
        "Most systems also support audio and video.",
        "Audio input is used by Windows voice-recognition software; voice recognition makes the system more convenient and increases its accessibility for users with disabilities.",
        "Windows 7 added support for multi-touch hardware, allowing users to input data by touching the screen and making gestures with one or more \ufb01ngers."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_5",
      "title": "19.5 File System",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 35,
      "definition": "FAT is a much older \ufb01le-system format that is understood by many systems besides Windows, such as the software running on cameras.",
      "key_points": [
        "A disadvantage is that the FAT \ufb01le system does not restrict \ufb01le access to authorized users.",
        "In contrast, NTFS uses ACLs to control access to individual \ufb01les and supports implicit encryption of individual \ufb01les or entire volumes (using Windows BitLocker feature).",
        "NTFS implements many other features as well, including data recovery, fault tolerance, very large \ufb01les and \ufb01le systems, multiple data streams, UNICODE names, sparse \ufb01les, journaling, volume shadow copies, and \ufb01le compression."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_5_1",
      "title": "19.5.1 NTFS Internal Layout",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 35,
      "definition": "The fundamental entity in NTFS is a volume.",
      "key_points": [
        "A volume is created by the Windows logical disk management utility and is based on a logical disk partition.",
        "A volume may occupy a portion of a disk or an entire disk, or may span several disks.",
        "NTFS does not deal with individual sectors of a disk but instead uses clusters as the units of disk allocation.",
        "A cluster is a number of disk sectors that is a power of 2.",
        "The cluster size is con\ufb01gured when an NTFS \ufb01le system is formatted."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_5_2",
      "title": "19.5.2 Recovery",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 37,
      "definition": "In many simple \ufb01le systems, a power failure at the wrong time can damage the \ufb01le-system data structures so severely that the entire volume is scrambled.",
      "key_points": [
        "This checking can be a slow process and can cause the loss of signi\ufb01cant amounts of data.",
        "After a crash, the system can restore the \ufb01le-system data structures to a consistent state by processing the log records, \ufb01rst redoing the operations for committed transactions and then undoing the operations for transactions",
        "Many UNIX \ufb01le systems, including UFS but not ZFS, store redundant metadata on the disk, and they recover from crashes by using the fsck program to check all the \ufb01le-system data structures and restore them forcibly to a consistent state.",
        "Restoring them often involves deleting damaged \ufb01les and freeing data clusters that had been written with user data but not properly recorded in the \ufb01le system\u2019s metadata structures.",
        "NTFS takes a different approach to \ufb01le-system robustness."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_5_3",
      "title": "19.5.3 Security",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 38,
      "definition": "The security of an NTFS volume is derived from the Windows object model.",
      "key_points": [
        "The pre\ufb01x-matching cache allows path-name traversal to begin much deeper in the tree, saving many steps.",
        "Each NTFS \ufb01le references a security descriptor, which speci\ufb01es the owner of the \ufb01le, and an access-control list, which contains the access permissions granted or denied to each user or group listed.",
        "Early versions of NTFS used a separate security descriptor as an attribute of each \ufb01le.",
        "Beginning with Windows 2000, the security-descriptors attribute points to a shared copy, with a signi\ufb01cant savings in disk and caching space; many, many \ufb01les have identical security descriptors.",
        "In normal operation, NTFS does not enforce permissions on traversal of directories in \ufb01le path names."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_5_4",
      "title": "19.5.4 Volume Management and Fault Tolerance",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 39,
      "definition": "FtDisk is the fault-tolerant disk driver for Windows.",
      "key_points": [
        "When installed, it provides several ways to combine multiple disk drives into one logical volume so as to improve performance, capacity, or reliability.",
        "19.5.4.1 Volume Sets and RAID Sets One way to combine multiple disks is to concatenate them logically to form a large logical volume, as shown in Figure 19.7. In Windows, this logical volume, called a volume set, can consist of up to 32 physical partitions.",
        "A volume set that contains an NTFS volume can be extended without disturbance of the data already stored in the \ufb01le system.",
        "The bitmap metadata on the NTFS volume are simply extended to cover the newly added space.",
        "NTFS continues to use the same LCN mechanism that it uses for a single physical disk, and the FtDisk driver supplies the mapping from a logical-volume offset to the offset on one particular disk."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_5_5",
      "title": "19.5.5 Compression",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 40,
      "definition": "NTFS can perform data compression on individual \ufb01les or on all data \ufb01les in a directory.",
      "key_points": [
        "To compress a \ufb01le, NTFS divides the \ufb01le\u2019s data into compression units, which are blocks of 16 contiguous clusters.",
        "When a compression unit is written, a data-compression algorithm is applied.",
        "If the result \ufb01ts into fewer than 16 clusters, the compressed version is stored.",
        "When reading, NTFS can determine whether data have been compressed: if they have been, the length of the stored compression unit is less than 16 clusters.",
        "To improve performance when reading contiguous compression units, NTFS prefetches and decompresses ahead of the application requests."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_5_6",
      "title": "19.5.6 Mount Points, Symbolic Links, and Hard Links",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 40,
      "definition": "Mount points are a form of symbolic link speci\ufb01c to directories on NTFS that were introduced in Windows 2000.",
      "key_points": [
        "They provide a mechanism for organizing disk volumes that is more \ufb02exible than the use of global names (like drive letters).",
        "A mount point is implemented as a symbolic link with associated data that contains the true volume name.",
        "Ultimately, mount points will supplant drive letters completely, but there will be a long transition due to the dependence of many applications on the drive-letter scheme.",
        "Windows Vista introduced support for a more general form of symbolic links, similar to those found in UNIX.",
        "The links can be absolute or relative, can point to objects that do not exist, and can point to both \ufb01les and directories"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_5_7",
      "title": "19.5.7 Change Journal",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 41,
      "definition": "NTFS keeps a journal describing all changes that have been made to the \ufb01le system.",
      "key_points": [
        "User-mode services can receive noti\ufb01cations of changes to the journal and then identify what \ufb01les have changed by reading from the journal.",
        "The search indexer service uses the change journal to identify \ufb01les that need to be re-indexed.",
        "The \ufb01le-replication service uses it to identify \ufb01les that need to be replicated across the network."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_5_8",
      "title": "19.5.8 Volume Shadow Copies",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 41,
      "definition": "Making a shadow copy of a volume is a form of copy-on-write, where blocks modi\ufb01ed after the shadow copy is created are stored in their original form in the copy.",
      "key_points": [
        "The user can use this feature to recover \ufb01les that were accidentally deleted or simply to look at a previous version of the \ufb01le, all without pulling out backup media.",
        "This technique is known as snapshots in some other \ufb01le systems.",
        "To achieve a consistent state for the volume requires the cooperation of applications, since the system cannot know when the data used by the application are in a stable state from which the application could be safely restarted.",
        "The server version of Windows uses shadow copies to ef\ufb01ciently maintain old versions of \ufb01les stored on \ufb01le servers.",
        "This allows users to see documents stored on \ufb01le servers as they existed at earlier points in time."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_6",
      "title": "19.6 Networking",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 41,
      "definition": "Windows supports both peer-to-peer and client\u2013server networking.",
      "key_points": [
        "The networking components in Windows provide data transport, interprocess communication, \ufb01le sharing across a network, and the ability to send print jobs to remote printers.",
        "It also has facilities for network management."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_6_1",
      "title": "19.6.1 Network Interfaces",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 41,
      "definition": "To describe networking in Windows, we must \ufb01rst mention two of the internal networking interfaces: the network device interface speci\ufb01cation (NDIS) and the transport driver interface (TDI).",
      "key_points": [
        "The NDIS interface was developed in 1989 by Microsoft and 3Com to separate network adapters from transport protocols so that either could be changed without affecting the other.",
        "NDIS resides at the interface between the data-link and network layers in the ISO model and enables many protocols to operate over many different network adapters.",
        "In terms of the ISO model, the TDI is the interface between the transport layer (layer 4) and the session layer (layer 5).",
        "This interface enables any session-layer component to use any available transport mechanism.",
        "(Similar reasoning led to the streams mechanism in UNIX.) The TDI supports both connection-based and connectionless transport and has functions to send any type of data."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_6_2",
      "title": "19.6.2 Protocols",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 42,
      "definition": "Windows implements transport protocols as drivers.",
      "key_points": [
        "Network \ufb01rewalls are commonly implemented in routers and are a very important security measure.",
        "These drivers can be loaded and unloaded from the system dynamically, although in practice the system typically has to be rebooted after a change.",
        "Windows comes with several networking protocols.",
        "Next, we discuss a number of these protocols.",
        "19.6.2.1 Server-Message Block The server-message-block (SMB) protocol was \ufb01rst introduced in MS-DOS 3.1. The system uses the protocol to send I/O requests over the network."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_6_3",
      "title": "19.6.3 Redirectors and Servers",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 44,
      "definition": "In Windows, an application can use the Windows I/O API to access \ufb01les from a remote computer as though they were local, provided that the remote computer is running a CIFS server such as those provided by Windows.",
      "key_points": [
        "A similar process occurs for applications that use the Win32 network API, rather than the UNC services, except that a module called a multi-provider router is used instead of a MUP.",
        "A redirector is the client-side object that forwards I/O requests to a remote system, where they are satis\ufb01ed by a server.",
        "For performance and security, the redirectors and servers run in kernel mode.",
        "In more detail, access to a remote \ufb01le occurs as follows: 1.",
        "The application calls the I/O manager to request that a \ufb01le be opened with a \ufb01le name in the standard UNC format."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_6_4",
      "title": "19.6.4 Domains",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 45,
      "definition": "Many networked environments have natural groups of users, such as students in a computer laboratory at school or employees in one department in a business.",
      "key_points": [
        "Frequently, we want all the members of the group to be able to access shared resources on their various computers in the group.",
        "To manage the global access rights within such groups, Windows uses the concept of a domain.",
        "Previously, these domains had no relationship whatsoever to the domain-name system (DNS) that maps Internet host names to IP addresses.",
        "Now, however, they are closely related.",
        "Speci\ufb01cally, a Windows domain is a group of Windows workstations and servers that share a common security policy and user database."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_6_5",
      "title": "19.6.5 Active Directory",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 46,
      "definition": "Active Directory is the Windows implementation of lightweight directory- access protocol (LDAP) services.",
      "key_points": [
        "Active Directory stores the topology infor- mation about the domain, keeps the domain-based user and group accounts and passwords, and provides a domain-based store for Windows features that need it, such as Windows group policy.",
        "Administrators use group policies to establish uniform standards for desktop preferences and software.",
        "For many corporate information-technology groups, uniformity drastically reduces the cost of computing."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_7",
      "title": "19.7 Programmer Interface",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 46,
      "definition": "The Win32 API is the fundamental interface to the capabilities of Windows.",
      "key_points": [
        "This section describes \ufb01ve main aspects of the Win32 API: access to kernel objects, sharing of objects between processes, process management, interprocess com- munication, and memory management."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_7_1",
      "title": "19.7.1 Access to Kernel Objects",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 46,
      "definition": "The Windows kernel provides many services that application programs can use.",
      "key_points": [
        "A process gains access to a kernel object named XXX by calling the CreateXXX function to open a handle to an instance of XXX.",
        "This handle is unique to the process.",
        "A process can close any handle by calling the CloseHandle() function, and the system may delete the object if the count of handles referencing the object in all processes drops to zero."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_7_2",
      "title": "19.7.2 Sharing Objects between Processes",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 46,
      "definition": "Windows provides three ways to share objects between processes.",
      "key_points": [
        "The \ufb01rst way is for a child process to inherit a handle to the object.",
        "Next, the child process is created, passing a value of TRUE to the CreateProcess() function\u2019s bInheritHandle argument.",
        "Figure 19.8 shows a code sample that creates a semaphore handle inherited by a child process.",
        "Assuming the child process knows which handles are shared, the parent and child can achieve interprocess communication through the shared objects.",
        "In the example in Figure 19.8, the child process gets the value of the handle from the \ufb01rst command-line argument and then shares the semaphore with the parent process."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_7_3",
      "title": "19.7.3 Process Management",
      "label": "Topic",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 47,
      "definition": "In Windows, a process is a loaded instance of an application and a thread is an executable unit of code that can be scheduled by the kernel dispatcher.",
      "key_points": [
        "Thus, a process contains one or more threads.",
        "A process is created when a thread in some other process calls the CreateProcess() API.",
        "This routine loads any dynamic link libraries used by the process and creates an initial thread in the process."
      ]
    },
    {
      "id": "CHAP_18_SUB_19_7_4",
      "title": "19.7.4 Interprocess Communication Using Windows Messaging",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 52,
      "definition": "Win32 applications handle interprocess communication in several ways. One way is by using shared kernel objects. Another is by using the Windows messaging facility, an approach that is particularly popular for Win32 GUI applications. One thread can send a message to another thread or to a window by calling PostMessage(), PostThreadMessage(), SendMessage(), SendThreadMessage(), or SendMessageCallback(). Posting a message and sending a message differ in this way: the post routines are asynchronous",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_7_5",
      "title": "19.7.5 Memory Management",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 53,
      "definition": "The Win32 API provides several ways for an application to use memory: virtual memory, memory-mapped \ufb01les, heaps, and thread-local storage. 19.7.5.1 Virtual Memory An application calls VirtualAlloc() to reserve or commit virtual memory and VirtualFree() to decommit or release the memory. These functions enable the application to specify the virtual address at which the memory is allocated. They operate on multiples of the memory page size. Examples of these functions appear in Figure 19.12. A pro",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_8",
      "title": "19.8 Summary",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 55,
      "definition": "Microsoft designed Windows to be an extensible, portable operating system \u2014one able to take advantage of new techniques and hardware. Windows supports multiple operating environments and symmetric multiprocessing, including both 32-bit and 64-bit processors and NUMA computers. The use of kernel objects to provide basic services, along with support for client\u2013 server computing, enables Windows to support a wide variety of applica- tion environments. Windows provides virtual memory, integrated cac",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_1",
      "title": "19.1 What type of operating system is Windows? Describe two of its major",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 55,
      "definition": "features.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_2",
      "title": "19.2 List the design goals of Windows. Describe two in detail.",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 55,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_3",
      "title": "19.3 Describe the booting process for a Windows system.",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_4",
      "title": "19.4 Describe the three main architectural layers of the Windows kernel.",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_5",
      "title": "19.5 What is the job of the object manager?",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_6",
      "title": "19.6 What types of services does the process manager provide?",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_7",
      "title": "19.7 What is a local procedure call?",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_8",
      "title": "19.8 What are the responsibilities of the I/O manager?",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_9",
      "title": "19.9 What types of networking does Windows support? How does Windows",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "implement transport protocols? Describe two networking protocols.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_10",
      "title": "19.10 How is the NTFS namespace organized?",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_11",
      "title": "19.11 How does NTFS handle data structures? How does NTFS recover from",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "a system crash? What is guaranteed after a recovery takes place? \u2018",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_12",
      "title": "19.12 How does Windows allocate user memory?",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_13",
      "title": "19.13 Describe some of the ways in which an application can use memory",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "via the Win32 API. Exercises",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_14",
      "title": "19.14 Under what circumstances would one use the deferred procedure calls",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "facility in Windows?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_15",
      "title": "19.15 What is a handle, and how does a process obtain a handle?",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_16",
      "title": "19.16 Describe the management scheme of the virtual memory manager. How",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "does the VM manager improve performance?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_17",
      "title": "19.17 Describe a useful application of the no-access page facility provided in",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "Windows.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_18",
      "title": "19.18 Describe the three techniques used for communicating data in a local",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "procedure call. What settings are most conducive to the application of the different message-passing techniques?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_19",
      "title": "19.19 What manages caching in Windows? How is the cache managed?",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_20",
      "title": "19.20 How does the NTFS directory structure differ from the directory",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "structure used in UNIX operating systems?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_21",
      "title": "19.21 What is a process, and how is it managed in Windows?",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_22",
      "title": "19.22 What is the \ufb01ber abstraction provided by Windows? How does it differ",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "from the thread abstraction?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_23",
      "title": "19.23 How does user-mode scheduling (UMS) in Windows 7 differ from",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "\ufb01bers? What are some trade-offs between \ufb01bers and UMS?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_24",
      "title": "19.24 UMS considers a thread to have two parts, a UT and a KT. How might it",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "be useful to allow UTs to continue executing in parallel with their KTs?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_25",
      "title": "19.25 What is the performance trade-off of allowing KTs and UTs to execute",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 56,
      "definition": "on different processors?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_26",
      "title": "19.26 Why does the self-map occupy large amounts of virtual address space",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 57,
      "definition": "but no additional virtual memory?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_27",
      "title": "19.27 How does the self-map make it easy for the VM manager to move the",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 57,
      "definition": "page-table pages to and from disk? Where are the page-table pages kept on disk?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_28",
      "title": "19.28 When a Windows system hibernates, the system is powered off.",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 57,
      "definition": "Suppose you changed the CPU or the amount of RAM on a hibernating system. Do you think that would work? Why or why not?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18_SUB_19_29",
      "title": "19.29 Give an example showing how the use of a suspend count is helpful in",
      "label": "Exercise",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 57,
      "definition": "suspending and resuming threads in Windows. Bibliographical Notes [Russinovich and Solomon (2009)] give an overview of Windows 7 and considerable technical detail about system internals and components. [Brown (2000)] presents details of the security architecture of Windows. The Microsoft Developer Network Library (http://msdn.microsoft.com) supplies a wealth of information on Windows and other Microsoft products, including documentation of all the published APIs. [Iseminger (2000)] provides a go",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_18",
      "title": "Chapter 19 Windows 7",
      "label": "Chapter",
      "file_source": "19_Chapter 19 Windows 7.pdf",
      "page": 1,
      "definition": "19 C H A P T E R Windows 7 Updated by Dave Probert The Microsoft Windows 7 operating system is a 32-/64-bit preemptive mul- titasking client operating system for microprocessors implementing the Intel IA-32 and AMD64 instruction set architectures (ISAs).",
      "key_points": [
        "In this chapter, we discuss the key goals of Windows 7, the layered architecture of the system that has made it so easy to use, the \ufb01le system, the networking features, and the programming interface.",
        "\u2022 To describe the important algorithms implemented with Windows 7.",
        "19.1 History In the mid-1980s, Microsoft and IBM cooperated to develop the OS/2 operating system, which was written in assembly language for single-processor Intel systems.",
        "19.1 History: In the mid-1980s, Microsoft and IBM cooperated to develop the OS/2 operating sys...",
        "19.2 Design Principles: Microsoft\u2019s design goals for Windows included security, reliability, Windows and...",
        "19.2.1 Security: Windows 7 security goals required more than just adherence to the design standar...",
        "19.2.2 Reliability: Windows matured greatly as an operating system in its \ufb01rst ten years, leading to...",
        "19.2.3 Windows and POSIX Application Compatibility: As mentioned, Windows XP was both an update of Windows 2000 and a replacement fo..."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_1",
      "title": "20.1 Feature Migration",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 1,
      "definition": "One reason to study early architectures and operating systems is that a feature that once ran only on huge systems may eventually make its way into very small systems.",
      "key_points": [
        "Indeed, an examination of operating systems for mainframes and microcomputers shows that many features once available only on main- frames have been adopted for microcomputers.",
        "To understand modern oper- ating systems, then, you need to recognize the theme of feature migration and the long history of many operating-system features, as shown in Figure 20.1. A good example of feature migration started with the Multiplexed Infor- mation and Computing Services (MULTICS) operating system.",
        "The same operating-system concepts are thus appropriate for various classes of computers: mainframes, minicomputers, microcomputers, and handhelds."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_2",
      "title": "20.2 Early Systems",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 2,
      "definition": "We turn our attention now to a historical overview of early computer systems.",
      "key_points": [
        "We should note that the history of computing starts far before \u201ccomputers\u201d with looms and calculators.",
        "We begin our discussion, however, with the computers of the twentieth century.",
        "Before the 1940s, computing devices were designed and implemented to perform speci\ufb01c, \ufb01xed tasks.",
        "Modifying one of those tasks required a great deal of effort and manual labor.",
        "All that changed in the 1940s when Alan Turing and John von Neumann (and colleagues), both separately and together, worked on the idea of a more general-purpose stored program computer."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_2_1",
      "title": "20.2.1 Dedicated Computer Systems",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 3,
      "definition": "As time went on, additional software and hardware were developed.",
      "key_points": [
        "The routines that performed I/O were especially important.",
        "Card readers, line printers, and magnetic tape became commonplace.",
        "Assemblers, loaders, and linkers were designed to ease the programming task.",
        "Libraries of common functions were created.",
        "Common functions could then be copied into a new program without having to be written again, providing software reusability."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_2_2",
      "title": "20.2.2 Shared Computer Systems",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 4,
      "definition": "The solution was twofold.",
      "key_points": [
        "First, a professional computer operator was hired.",
        "The programmer no longer operated the machine.",
        "As soon as one job was \ufb01nished, the operator could start the next.",
        "Since the operator had more experience with mounting tapes than a programmer, setup time was reduced.",
        "The programmer provided whatever cards or tapes were needed, as well as a short description of how the job was to be run."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_2_3",
      "title": "20.2.3 Overlapped I/O",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 7,
      "definition": "One common solution to the I/O problem was to replace slow card readers (input devices) and line printers (output devices) with magnetic-tape units.",
      "key_points": [
        "An obvious advantage of off-line operation was that the main computer was no longer constrained by the speed of the card readers and line printers but was limited only by the speed of the much faster magnetic tape units.",
        "Most computer systems in the late 1950s and early 1960s were batch systems reading from card readers and writing to line printers or card punches.",
        "The CPU did not read directly from cards, however; instead, the cards were \ufb01rst copied onto a magnetic tape via a separate device.",
        "When the tape was suf\ufb01ciently full, it was taken down and carried over to the computer.",
        "When a card was needed for input to a program, the equivalent record was read from the tape."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_3",
      "title": "20.3 Atlas",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 9,
      "definition": "The Atlas operating system was designed at the University of Manchester in England in the late 1950s and early 1960s.",
      "key_points": [
        "Many of its basic features that were novel at the time have become standard parts of modern operating systems.",
        "The most remarkable feature of Atlas, however, was its memory manage- ment.",
        "Many computers, like the IBM 650, used a drum for primary memory."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_4",
      "title": "20.4 XDS-940",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 10,
      "definition": "The XDS-940 operating system was designed at the University of California at Berkeley in the early 1960\u2019s.",
      "key_points": [
        "The virtual memory of any user process was made up of 16-KB words, whereas the physical memory was made up of 64-KB words.",
        "Since physical memory was larger than virtual memory, several user processes could be in memory at the same time.",
        "Processes were kept on a drum and were swapped in and out of memory as necessary.",
        "The XDS-940 system also provided system calls to allow processes to create, start, suspend, and destroy subprocesses.",
        "A programmer could construct a system of processes."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_5",
      "title": "20.5 THE",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 11,
      "definition": "The THE operating system was designed at the Technische Hogeschool in Eindhoven in the Netherlands in the mid-1960\u2019s.",
      "key_points": [
        "The system was mainly noted for its clean design, particularly its layer structure, and its use of a set of concurrent processes employing semaphores for synchronization.",
        "Unlike the processes in the XDS-940 system, the set of processes in the THE system was static.",
        "The operating system itself was designed as a set of cooperating processes.",
        "In addition, \ufb01ve user processes were created that served as the active agents to compile, execute, and print user programs.",
        "When one job was \ufb01nished, the process would return to the input queue to select another job."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_6",
      "title": "20.6 RC 4000",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 11,
      "definition": "The RC 4000 system, like the THE system, was notable primarily for its design concepts.",
      "key_points": [
        "The kernel supported a collection of concurrent processes.",
        "Although processes could share memory, the primary communication and synchronization mechanism was the message system provided by the kernel.",
        "Processes could communicate with each other by exchanging \ufb01xed-sized messages of eight words in length."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_7",
      "title": "20.7 CTSS",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 12,
      "definition": "The Compatible Time-Sharing System (CTSS) was designed at MIT as an experi- mental time-sharing system and \ufb01rst appeared in 1961.",
      "key_points": [
        "It was implemented on an IBM 7090 and eventually supported up to 32 interactive users.",
        "The users were provided with a set of interactive commands that allowed them to manipulate \ufb01les and to compile and run programs through a terminal.",
        "The 7090 had a 32-KB memory made up of 36-bit words.",
        "The monitor used KB words, leaving 27 KB for the users.",
        "User memory images were swapped between memory and a fast drum."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_8",
      "title": "20.8 MULTICS",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 13,
      "definition": "The MULTICS operating system was designed from 1965 to 1970 at MIT as a natural extension of CTSS.",
      "key_points": [
        "Protection was accomplished through an access list associated with each \ufb01le and a set of protection rings for executing processes.",
        "It was extended to a multiprocessor system, allowing a CPU to be taken out of service for maintenance while the system continued running.",
        "CTSS and other early time-sharing systems were so successful that they created an immediate desire to proceed quickly to bigger and better systems.",
        "As larger computers became available, the designers of CTSS set out to create a time-sharing utility.",
        "Computing service would be provided like electrical power."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_9",
      "title": "20.9 IBM OS/360",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 13,
      "definition": "The longest line of operating-system development is undoubtedly that of IBM computers.",
      "key_points": [
        "The early IBM computers, such as the IBM 7090 and the IBM 7094, are prime examples of the development of common I/O subroutines, followed by developmentofaresidentmonitor, privileged instructions, memory protection, and simple batch processing.",
        "These systems were developed separately, often at independent sites.",
        "As a result, IBM was faced with many different computers, with different languages and different system software.",
        "The IBM/360 \u2014which \ufb01rst appeared in the mid 1960\u2019s \u2014 was designed to alter this situation.",
        "The IBM/360 ([Mealy et al."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_10",
      "title": "20.10 TOPS-20",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 15,
      "definition": "DEC created many in\ufb02uential computer systems during its history.",
      "key_points": [
        "BBN took the business-oriented DEC PDP-10 computer running TOPS-10, added a hardware memory-paging system to implement virtual memory, and wrote a new operating system for that computer to take advantage of the new hardware features.",
        "Probably the most famous operating system associated with DEC is VMS, a popular business-oriented system that is still in use today as OpenVMS, a product of Hewlett-Packard.",
        "But perhaps the most in\ufb02uential of DEC\u2019s operating systems was TOPS-20.",
        "TOPS-20 started life as a research project at Bolt, Beranek, and Newman (BBN) around 1970.",
        "The result was TENEX, a general- purpose timesharing system."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_11",
      "title": "20.11 CP/M and MS/DOS",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 15,
      "definition": "Early hobbyist computers were typically built from kits and ran a single program at a time.",
      "key_points": [
        "It lacked fundamental current operating-system features, however, especially protected memory.",
        "The systems evolved into more advanced systems as computer components improved.",
        "An early \u201cstandard\u201d operating system for these computers of the 1970s was CP/M, short for Control Program/Monitor, written by Gary Kindall of Digital Research, Inc.",
        "CP/M ran primarily on the \ufb01rst \u201cpersonal computer\u201d CPU, the 8-bit Intel 8080.",
        "CP/M originally supported only 64 KB of memory and ran only one program at a time."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_12",
      "title": "20.12 Macintosh Operating System and Windows",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 16,
      "definition": "With the advent of 16-bit CPUs, operating systems for personal computers could become more advanced, feature rich, and usable.",
      "key_points": [
        "It used a mouse for screen pointing and selecting and came with many utility programs that took advantage of the new user interface.",
        "As microprocessor CPUs evolved to 32-bit chips with advanced features, such as protected memory and context switching, these operating systems added features that had previously been found only on mainframes and minicomputers.",
        "The desktop rivalry between Apple and Microsoft continues today, with new versions of Windows and Mac OS trying to outdo each other in features, usability, and application functionality."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_13",
      "title": "20.13 Mach",
      "label": "Topic",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 16,
      "definition": "The Mach operating system traces its ancestry to the Accent operating system developed at Carnegie Mellon University (CMU).",
      "key_points": [
        "Mach\u2019s communication system and philosophy are derived from Accent, but many other signi\ufb01cant portions of the system (for example, the virtual memory system and task and thread management) were developed from scratch.",
        "Work on Mach began in the mid 1980\u2019s and the operating system was designed with the following three critical goals in mind: 1.",
        "Emulate 4.3 BSD UNIX so that the executable \ufb01les from a UNIX system can run correctly under Mach.",
        "Be a modern operating system that supports many memory models, as well as parallel and distributed computing.",
        "Have a kernel that is simpler and easier to modify than 4.3 BSD."
      ]
    },
    {
      "id": "CHAP_19_SUB_20_14",
      "title": "20.14 Other Systems",
      "label": "Exercise",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 18,
      "definition": "There are, of course, other operating systems, and most of them have interesting properties. The MCP operating system for the Burroughs computer family was the \ufb01rst to be written in a system programming language. It supported segmentation and multiple CPUs. The SCOPE operating system for the CDC was also a multi-CPU system. The coordination and synchronization of the multiple processes were surprisingly well designed. History is littered with operating systems that suited a purpose for a time (b",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_19_SUB_20_1",
      "title": "20.1 Discuss what considerations the computer operator took into account",
      "label": "Exercise",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 18,
      "definition": "in deciding on the sequences in which programs would be run on early computer systems that were manually operated.",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_19_SUB_20_2",
      "title": "20.2 What optimizations were used to minimize the discrepancy between",
      "label": "Exercise",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 18,
      "definition": "CPU and I/O speeds on early computer systems?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_19_SUB_20_3",
      "title": "20.3 Consider the page-replacement algorithm used by Atlas. In what ways",
      "label": "Exercise",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 18,
      "definition": "is it different from the clock algorithm discussed in Section 9.4.5.2?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_19_SUB_20_4",
      "title": "20.4 Consider the multilevel feedback queue used by CTSS and MULTICS.",
      "label": "Exercise",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 18,
      "definition": "Suppose a program consistently uses seven time units every time it is scheduled before it performs an I/O operation and blocks. How many time units are allocated to this program when it is scheduled for execution at different points in time?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_19_SUB_20_5",
      "title": "20.5 What are the implications of supporting BSD functionality in user-mode",
      "label": "Exercise",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 18,
      "definition": "servers within the Mach operating system?",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_19_SUB_20_6",
      "title": "20.6 What conclusions can be drawn about the evolution of operating",
      "label": "Exercise",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 18,
      "definition": "systems? What causes some operating systems to gain in popularity and others to fade? Bibliographical Notes Looms and calculators are described in [Frah (2001)] and shown graphically in [Frauenfelder (2005)]. The Manchester Mark 1 is discussed by [Rojas and Hashagen (2000)], and its offspring, the Ferranti Mark 1, is described by [Ceruzzi (1998)].",
      "key_points": [
        "Practice Question"
      ]
    },
    {
      "id": "CHAP_19",
      "title": "Chapter 20 Influential Operating Systems",
      "label": "Chapter",
      "file_source": "20_Chapter 20 Influential Operating Systems.pdf",
      "page": 1,
      "definition": "20 C H A P T E R Influential Operating Systems Now that you understand the fundamental concepts of operating systems (CPU scheduling, memory management, processes, and so on), we are in a position to examine how these concepts have been applied in several older and highly in\ufb02uential operating systems.",
      "key_points": [
        "In the bibliographical notes at the end of the chapter, we include references to further reading about these early systems.",
        "The papers, written by the designers of the systems, are important both for their technical content and for their style and \ufb02avor.",
        "CHAPTER OBJECTIVES \u2022 To explain how operating-system features migrate over time from large computer systems to smaller ones.",
        "20.1 Feature Migration: One reason to study early architectures and operating systems is that a feature ...",
        "20.2 Early Systems: We turn our attention now to a historical overview of early computer systems....",
        "20.2.1 Dedicated Computer Systems: As time went on, additional software and hardware were developed....",
        "20.2.2 Shared Computer Systems: The solution was twofold....",
        "20.2.3 Overlapped I/O: One common solution to the I/O problem was to replace slow card readers (input d..."
      ]
    }
  ],
  "relationships": [
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_1_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_8_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_8_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_8_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_8_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_10_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_10_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_10_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_10_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_11_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_11_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_11_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_11_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_11_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_11_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_11_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_11_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_12_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_12_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_12_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_12_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_12_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_27",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_28",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_29",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_00_SUB_1_30",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_4_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_4_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_4_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_7_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_7_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_8_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_8_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_8_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_01_SUB_2_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_00",
      "target": "CHAP_01",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_1_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_1_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_02_SUB_3_27",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_01",
      "target": "CHAP_02",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_6_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_6_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_03_SUB_4_27",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_02",
      "target": "CHAP_03",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_6_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_8_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_8_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_8_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_8_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_9_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_9_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_9_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_9_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_10_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_10_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_10_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_27",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_28",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_29",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_30",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_31",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_32",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_33",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_34",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_35",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_36",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_37",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_38",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_39",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_40",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_04_SUB_5_41",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_03",
      "target": "CHAP_04",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_1_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_1_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_3_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_3_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_3_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_6_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_6_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_6_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_8_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_8_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_8_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_8_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_27",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_28",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_29",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_30",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_31",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_05_SUB_6_32",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_04",
      "target": "CHAP_05",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_4_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_06_SUB_7_27",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_05",
      "target": "CHAP_06",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_1_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_1_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_1_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_6_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_27",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_28",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_29",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_30",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_31",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_32",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_07_SUB_8_33",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_06",
      "target": "CHAP_07",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_4_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_4_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_4_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_4_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_4_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_6_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_8_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_8_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_9_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_9_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_9_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_9_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_9_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_9_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_10_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_10_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_27",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_28",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_29",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_30",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_31",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_32",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_33",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_34",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_35",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_36",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_37",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_38",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_39",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_08_SUB_9_40",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_07",
      "target": "CHAP_08",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_1_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_4_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_4_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_4_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_7_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_7_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_7_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_09_SUB_10_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_08",
      "target": "CHAP_09",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_1_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_1_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_1_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_3_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_3_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_3_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_3_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_10_SUB_11_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_09",
      "target": "CHAP_10",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_4_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_5_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_7_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_8_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_8_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_8_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_8_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_8_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_11_SUB_12_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_10",
      "target": "CHAP_11",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_2_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_3_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_3_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_4_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_4_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_4_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_4_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_4_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_12_SUB_13_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_11",
      "target": "CHAP_12",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_5_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_8_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_8_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_9_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_9_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_13_SUB_14_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_12",
      "target": "CHAP_13",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_2_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_2_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_5_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_6_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_6_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_14_SUB_15_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_13",
      "target": "CHAP_14",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_5_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_5_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_5_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_5_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_6_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_6_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_15_SUB_16_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_14",
      "target": "CHAP_15",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_1_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_1_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_4_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_4_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_7_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_9_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_9_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_1_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_27",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_28",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_16_SUB_17_29",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_15",
      "target": "CHAP_16",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_1_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_1_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_1_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_1_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_4_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_4_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_7_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_8_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_8_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_9_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_9_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_11_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_11_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_17_SUB_18_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_16",
      "target": "CHAP_17",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_3_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_3_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_3_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_5_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_5_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_5_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_5_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_5_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_5_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_5_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_5_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_6_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_6_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_6_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_6_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_6_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_7_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_7_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_7_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_7_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_7_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_15",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_16",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_17",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_18",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_19",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_20",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_21",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_22",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_23",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_24",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_25",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_26",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_27",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_28",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_18_SUB_19_29",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_17",
      "target": "CHAP_18",
      "relation": "REQUIRES"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_2_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_2_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_2_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_7",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_8",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_9",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_10",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_11",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_12",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_13",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_14",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_1",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_2",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_3",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_4",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_5",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_19",
      "target": "CHAP_19_SUB_20_6",
      "relation": "HAS_PART"
    },
    {
      "source": "CHAP_18",
      "target": "CHAP_19",
      "relation": "REQUIRES"
    }
  ]
}